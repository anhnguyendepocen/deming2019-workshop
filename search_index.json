[
["index.html", "Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the tlverse Software Ecosystem Software Workshops at Deming Conference on Applied Statistics (4-6 December 2019) Preface Important links Abstract Contents About the instructors and authors", " Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the tlverse Software Ecosystem Software Workshops at Deming Conference on Applied Statistics (4-6 December 2019) Rachael Phillips, Nima Hejazi, Jeremy Coyle, Ivana Malenica, Alan Hubbard, Mark van der Laan updated: December 06, 2019 Preface This is an open source and fully-reproducible electronic vignette for the software workshops incorporated in the half-day tutorial (4 December 2019) and 2-day short course (5-6 December 2019) on applying Targeted Learning in practice given at the Deming Conference on Applied Statistics. The Hitchhiker’s Guide to the tlverse, or a Targeted Learning Practitioner’s Handbook is an in-draft book covering the tlverse software topics in greater detail and may serve as a useful accompanying resource to these workshop materials. Important links Software installation Please install the relevant software before the workshop. installation script Code R script files for each section of the workshop are available via the GitHub repository for the short course. https://github.com/tlverse/deming2019-workshop/tree/master/R Abstract Half-Day Tutorial – 9A-12P on December 4, 2019 Targeted Maximum Likelihood Estimation (TMLE) for Machine Learning: A Gentle Introduction During this half-day tutorial, we will delve into the utility of the roadmap of targeted learning for translating real-world data applications to a mathematical and statistical formulation of the relevant research question of interest. Participants will perform hands-on implementation of state-of-the-art targeted maximum likelihood estimators using the tlverse software ecosystem in the R programming language. Participants will actively learn and apply the core principles of the Targeted Learning methodology, which (1) generalizes machine learning to any estimand of interest; (2) obtains an optimal estimator of the given estimand, grounded in theory; (3) integrates modern ensemble machine learning techniques; and (4) provides formal statistical inference in terms of confidence intervals and testing of specified null hypotheses of interest. It is highly recommended for participants to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. 2-Day Short Course – 8A-5P on December 5-6, 2019 Targeted Learning in Data Science: Causal Inference for Observational and Experimental Data This 2-day short course will provide a comprehensive introduction to the field of targeted learning for causal inference and the corresponding tlverse software ecosystem. We will focus on targeted minimum loss-based estimators of causal effects, including those of static, dynamic, optimal dynamic, and stochastic interventions. These multiply robust, efficient plug-in estimators use state-of-the-art ensemble machine learning tools to flexibly adjust for confounding while yielding valid statistical inference. Estimators will be explored under various real-world scenarios: when the outcome is subject to missingness, when mediators are present on the causal pathway, in high dimensions, under two-phase sampling designs, and in right-censored survival settings possibly subject to competing risks. We will discuss the utility of this robust estimation strategy in comparison to conventional techniques, which often rely on restrictive statistical models and may therefore lead to severely biased inference. In addition to discussion, this course will incorporate both interactive activities and hands-on, guided R programming exercises, to allow participants the opportunity to familiarize themselves with methodology and tools that will translate to real-world analyses. It is highly recommended for participants to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. Contents These materials are feature modules centered around distinct causal questions, each motivated by a case study, alongside statistical methodology and software for assessing the causal claim of interest. Topics include Why we need a statistical revolution Introduction to the tlverse software ecosystem Roadmap of statistical learning with causal inference International Stroke Trial (IST), WASH Benefits, and Veterans’ Administration Lung Cancer Trial data Super (ensemble machine) learning with the sl3 tlverse R package Targeted learning for causal inference with the tmle3 tlverse R package Optimal treatment regimes and the tmle3mopttx tlverse R package Stochastic treatment regimes and the tmle3shift tlverse R package One-step TMLE for time-to-event outcomes with the MOSS R package Treatment specific mean outcome or marginal structural model for longitudinal data with the ltmle R package About the instructors and authors While this workshop is delivered by Mark van der Laan and Rachael Phillips, the majority of these materials are based on joint work with a team of six co-authors: Mark van der Laan Mark van der Laan, Ph.D., is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Rachael’s research focuses on narrowing the gap between the theory and application of modern statistics for real-world data science. Specifically, Rachael is motivated by issues arising in healthcare, and she leverages strategies rooted in causal inference and nonparametric estimation to build clinician-tailored, machine-driven solutions. Rachael is also passionate about free, online-mediated education and its corresponding pedagogy. Jeremy Coyle Jeremy Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Alan Hubbard Alan Hubbard, Ph.D., is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Nima Hejazi Nima is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and is a former NIH Biomedical Big Data fellow. He earned is Master’s in Biostatistics (2017) and a Bachelor’s with a triple major in Molecular and Cell Biology (Neurobiology), Psychology, and Public Health (2015) at UC Berkeley. Nima’s interests span nonparametric estimation, high-dimensional inference, targeted learning, statistical computing, survival analysis, and computational biology, with an emphasis on the development of robust and efficient statistical methodologies that draw on the intersection of causal inference and statistical machine learning. For more information, see https://nimahejazi.org. Ivana Malenica Ivana is a Ph.D. candidate in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. "],
["motivation.html", "Motivation", " Motivation “One enemy of robust science is our humanity — our appetite for being right, and our tendency to find patterns in noise, to see supporting evidence for what we already believe is true, and to ignore the facts that do not fit.” — (“Let’s Think About Cognitive Bias” 2015) Scientific research is at a unique point in history. The need to improve rigor and reproducibility in our field is greater than ever; corroboration moves science forward, yet there is a growing alarm about results that cannot be reproduced and that report false discoveries (Baker 2016). Consequences of not meeting this need will result in further decline in the rate of scientific progression, the reputation of the sciences, and the public’s trust in its findings (Munafò et al. 2017; “How Scientists Fool Themselves – and How They Can Stop” 2015). “The key question we want to answer when seeing the results of any scientific study is whether we can trust the data analysis.” — Peng (2015) Unfortunately, at its current state the culture of data analysis and statistics actually enables human bias through improper model selection. All hypothesis tests and estimators are derived from statistical models, so to obtain valid estimates and inference it is critical that the statistical model contains the process that generated the data. Perhaps treatment was randomized or only depended on a small number of baseline covariates; this knowledge should and can be incorporated in the model. Alternatively, maybe the data is observational, and there is no knowledge about the data-generating process (DGP). If this is the case, then the statistical model should contain all data distributions. In practice; however, models are not selected based on knowledge of the DGP, instead models are often selected based on (1) the p-values they yield, (2) their convenience of implementation, and/or (3) an analysts loyalty to a particular model. This practice of “cargo-cult statistics — the ritualistic miming of statistics rather than conscientious practice,” (Stark and Saltelli 2018) is characterized by arbitrary modeling choices, even though these choices often result in different answers to the same research question. That is, “increasingly often, [statistics] is used instead to aid and abet weak science, a role it can perform well when used mechanically or ritually,” as opposed to its original purpose of safeguarding against weak science (Stark and Saltelli 2018). This presents a fundamental drive behind the epidemic of false findings that scientific research is suffering from (van der Laan and Starmans 2014). “We suggest that the weak statistical understanding is probably due to inadequate”statistics lite&quot; education. This approach does not build up appropriate mathematical fundamentals and does not provide scientifically rigorous introduction into statistics. Hence, students’ knowledge may remain imprecise, patchy, and prone to serious misunderstandings. What this approach achieves, however, is providing students with false confidence of being able to use inferential tools whereas they usually only interpret the p-value provided by black box statistical software. While this educational problem remains unaddressed, poor statistical practices will prevail regardless of what procedures and measures may be favored and/or banned by editorials.&quot; — Szucs and Ioannidis (2017) Our team at The University of California, Berkeley, is uniquely positioned to provide such an education. Spearheaded by Professor Mark van der Laan, and spreading rapidly by many of his students and colleagues who have greatly enriched the field, the aptly named “Targeted Learning” methodology targets the scientific question at hand and is counter to the current culture of “convenience statistics” which opens the door to biased estimation, misleading results, and false discoveries. Targeted Learning restores the fundamentals that formalized the field of statistics, such as the that facts that a statistical model represents real knowledge about the experiment that generated the data, and a target parameter represents what we are seeking to learn from the data as a feature of the distribution that generated it (van der Laan and Starmans 2014). In this way, Targeted Learning defines a truth and establishes a principled standard for estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias, confirmation bias, and outcome bias) from infiltrating analysis. “The key for effective classical [statistical] inference is to have well-defined questions and an analysis plan that tests those questions.” — Nosek et al. (2018) Our objective is to provide training to students, researchers, industry professionals, faculty in science, public health, statistics, and other fields to empower them with the necessary knowledge and skills to utilize the sound methodology of Targeted Learning — a technique that provides tailored pre-specified machines for answering queries, so that each data analysis is completely reproducible, and estimators are efficient, minimally biased, and provide formal statistical inference. Just as the conscientious use of modern statistical methodology is necessary to ensure that scientific practice thrives, it remains critical to acknowledge the role that robust software plays in allowing practitioners direct access to published results. We recall that “an article…in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures,” thus making the availability and adoption of robust statistical software key to enhancing the transparency that is an inherent aspect of science (Buckheit and Donoho 1995). For a statistical methodology to be readily accessible in practice, it is crucial that it is accompanied by robust user-friendly software (Pullenayegum et al. 2016; Stromberg and others 2004). The tlverse software ecosystem was developed to fulfill this need for the Targeted Learning methodology. Not only does this software facilitate computationally reproducible and efficient analyses, it is also a tool for Targeted Learning education since its workflow mirrors that of the methodology. In particular, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators. Instead, the focus is on exposing the statistical framework of Targeted Learning itself — all R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of Targeted Learning. What’s more, the tlverse R packages share a core set of design principles centered on extensibility, allowing for them to be used in conjunction with each other and built upon one other in a cohesive fashion. In this workshop, the reader will embark on a journey through the tlverse ecosystem. Guided by R programming exercises, case studies, and intuitive explanation readers will build a toolbox for applying the Targeted Learning statistical methodology, which will translate to real-world causal inference analyses. Participants need not be a fully trained statistician to begin understanding and applying these methods. However, it is highly recommended for participants to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. We also recommend an understanding of introductory causal inference. For introductory materials for learning the R programming language we recommend the following free resources: Software Carpentry’s Programming with R Software Carpentry’s R for Reproducible Scientific Analysis Grolemund and Wickham’s R for Data Science For causal inference learning materials we recommend the following resources: Hernán MA, Robins JM (2019). Causal Inference. Jason A. Roy’s coursera Course A Crash Course in Causality: Inferring Causal Effects from Observational Data References "],
["tlverse.html", "Chapter 1 Welcome to the tlverse 1.1 Learning Objectives 1.2 What is the tlverse? 1.3 tlverse components 1.4 Installation", " Chapter 1 Welcome to the tlverse Jeremy Coyle 1.1 Learning Objectives Understand the tlverse ecosystem conceptually Identify the core components of the tlverse Install tlverse R packages Understand the Targeted Learning roadmap Learn about the WASH Benefits example data 1.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 1.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 1.4 Installation Before installing packages, please update your version of R. The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tlverse/tlverse&quot;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the following error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use GitHub as your user (you’ll need a GitHub user account). Follow these two steps: Type usethis::browse_github_pat() in your R console, which will direct you to GitHub’s page to create a New Personal Access Token. Create a Personal Access Token simply by clicking “Generate token” at the bottom of the page. Copy your Personal Access Token, a long string of lowercase letters and numbers. Type usethis::edit_r_environ() in your R console, which will open your .Renviron file in the source window of RStudio. In your .Renviron file, type GITHUB_PAT= and then paste your Personal Access Token after the equals symbol with no space. In your .Renviron file, press the enter key to ensure that your .Renviron ends with a newline. Save your .Renviron file. Restart R for changes to take effect. You can restart R via the drop-down menu on the “Session” tab. The “Session” tab is at the top of the RStudio interface. After following these steps, you should be able to successfully install the package which threw the error above. This workshop has other dependencies, which you can install using the following linked script: install.R "],
["intro.html", "Chapter 2 The Roadmap of Statistical Learning 2.1 The Observed Data and Statistical Model 2.2 The Causal Model 2.3 The Parameter of Interest 2.4 Identifiability 2.5 Estimation: Targeted Maximum Likelihood Estimation 2.6 Inference", " Chapter 2 The Roadmap of Statistical Learning A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models and to do so with finite-sample robustness and consistent inference. 2.1 The Observed Data and Statistical Model Assume we have an i.i.d. sample of confounders, a binary intervention of interest, and an outcome, or are observed data is \\[ O = (W, A, Y).\\] The distribution of the observed data may be factorized as follows: \\[P(O) = P(W, A, Y) = P(W)P (A \\mid W) P(Y \\mid A, W).\\] To estimate a parameter of interest, a researcher need not necessarily be able to specify these whole or conditional distributions. Rather, each estimator only requires that certain parts of the distribution be known; for example, some may require estimates of \\(\\mathbb{E}(Y \\mid A, W)\\), the mean of \\(Y\\) within subgroups \\((A, W)\\), or the regression of the outcome on the exposure and confounders. At this stage in the roadmap, the researcher must specify a choice of statistical model to be used in estimating \\(\\mathbb{E}(Y \\mid A, W)\\) or other elements of the probability distribution needed to estimate the parameter of interest. Here, statistical model means any constraints on the model form that may be imposed by knowledge about the data-generating process – that is, known aspects of how the data were generated. Typically, the true model is a very large model, placing few constraints, if any, on the data-generating distribution, or a semi-parametric model. With few constraints on the data-generating distribution, and a potentially large number of covariates, data-adaptive, machine-learning approaches remain the only practical option for estimating components of the likelihood. The remainder of this course concerns how to do this as efficiently and robustly as possible, depending on the goal of the analysis. 2.2 The Causal Model The next step in the roadmap is to use a causal framework to formalize the experiment and thereby define the parameter of interest. Causal graphs are one useful tool to express what we know about the causal relations among variables that are relevant to the question under study (Pearl 2009). Ignoring error terms, we will assume the following ordering of the variables in \\(O\\). While directed acyclic graphs (DAGs) like above provide a convenient means by which to visualize causal relations between variables, the causal relations among variables can be represented via a set of structural equations: \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(W, A, U_Y), \\end{align*}\\] where \\(U_W\\), \\(U_A\\), and \\(U_Y\\) represent the unmeasured exogenous background characteristics that influence the value of each variable. In the NPSEM, \\(f_W\\), \\(f_A\\) and \\(f_Y\\) denote that each variable (for \\(W\\), \\(A\\) and \\(Y\\), respectively) is a function of its parents and unmeasured background characteristics, but one typically has little information about particular functional constraints (e.g., linear, logit-linear, only one interaction, etc.). For this reason, they are called non-parametric structural equation models (NPSEMs). The DAG and set of nonparametric structural equations represent exactly the same information and so may be used interchangeably. 2.3 The Parameter of Interest The first hypothetical experiment we will consider is assigning exposure to the whole population and observing the outcome, and then assigning no exposure to the whole population and observing the outcome. On the nonparametric structural equations, this corresponds to a comparison of the outcome distribution in the population under two interventions: \\(A\\) is set to \\(1\\) for all individuals, and \\(A\\) is set to \\(0\\) for all individuals. These interventions imply two new nonparametric structural equation models. For the case \\(A = 1\\), we have \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 1 \\\\ Y(1) &amp;= f_Y(W, 1, U_Y), \\end{align*}\\] and for the case \\(A=0\\), \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 0 \\\\ Y(1) &amp;= f_Y(W, 0, U_Y). \\end{align*}\\] In these equations, \\(A\\) is no longer a function of \\(W\\) because we have intervened on the system, setting \\(A\\) deterministically to either of the values \\(1\\) or \\(0\\). The new symbols \\(Y(1)\\) and \\(Y(0)\\) indicate the outcome variable in our population if it were generated by the respective NPSEMs above; these are often called counterfactuals. The difference between the means of the outcome under these two interventions defines a parameter that is often called the “average treatment effect” (ATE), denoted \\[\\begin{equation}\\label{eqn:ate} ATE = \\mathbb{E}_X(Y(1)-Y(0)), \\end{equation}\\] where \\(\\mathbb{E}_X\\) is the mean under the theoretical (unobserved) full data \\(X = (W, Y(1), Y(0))\\). Note, we can define much more complicated interventions on NPSEM’s, such as interventions based upon rules (themselves based upon covariates), stochastic rules, etc. and each results in a different targeted parameter and entails different identifiability assumptions discussed below. 2.4 Identifiability Because we can never observe both \\(Y(0)\\) (the counterfactual outcome when \\(A=0\\)) and \\(Y(1)\\), we cannot estimate directly. Instead, we have to make assumptions under which this quantity may be estimated from the observed data \\(O \\sim P_0\\) under the data-generating distribution \\(P_0\\). Fortunately, given the causal model specified in the NPSEM above, we can, with a handful of untestable assumptions, estimate the ATE, even from observational data. These assumptions may be summarized as follows The causal graph implies \\(Y(a) \\perp A\\) for all \\(a \\in \\mathcal{A}\\), which is the randomization assumption. In the case of observational data, the analogous assumption is strong ignorability or no unmeasured confounding \\(Y(a) \\perp A \\mid W\\) for all \\(a \\in \\mathcal{A}\\); Although not represented in the causal graph, also required is the assumption of no interference between units, that is, the outcome for unit \\(i\\) \\(Y_i\\) is not affected by exposure for unit \\(j\\) \\(A_j\\) unless \\(i=j\\); Consistency of the treatment mechanism is also required, i.e., the outcome for unit \\(i\\) is \\(Y_i(a)\\) whenever \\(A_i = a\\), an assumption also known as “no other versions of treatment”; It is also necessary that all observed units, across strata defined by \\(W\\), have a bounded (non-deterministic) probability of receiving treatment – that is, \\(0 &lt; P_0(A = a \\mid W) &lt; 1\\) for all \\(a\\) and \\(W\\). This assumption is referred to as positivity. Remark: Together, (2) and (3), the assumptions of no interference and consistency, respectively, are jointly referred to as the stable unit treatment value assumption (SUTVA). Given these assumptions, the ATE may be re-written as a function of \\(P_0\\), specifically \\[\\begin{equation}\\label{eqn:estimand} ATE = \\mathbb{E}_0(Y(1) - Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\right), \\end{equation}\\] or the difference in the predicted outcome values for each subject, under the contrast of treatment conditions (\\(A = 0\\) vs. \\(A = 1\\)), in the population, averaged over all observations. Thus, a parameter of a theoretical “full” data distribution can be represented as an estimand of the observed data distribution. Significantly, there is nothing about the representation in that requires parametric assumptions; thus, the regressions on the right hand side may be estimated freely with machine learning. With different parameters, there will be potentially different identifiability assumptions and the resulting estimands can be functions of different components of \\(P_0\\). We discuss several more complex estimands in later sections of this workshop. 2.5 Estimation: Targeted Maximum Likelihood Estimation Although we will discuss more in later sections, the goals of the estimators we desire should be that, among sensible (asymptotically consistent, regular) estimators, the estimator be asymptotically efficient in the statistical model of interest, and the estimator can be constructed for finite-sample performance improvements, relative to other estimators in the same class. These principles guide our approach to estimation: Super Learning for prediction (more generally density estimation) and TMLE for estimation of our intervention parameters of interest. 2.6 Inference The estimators we discuss are asymptotically linear, meaning that the difference in the estimate \\(\\Psi(P_n)\\) and the true parameter (\\(\\Psi(P_0)\\)) can be represented in first order by a i.i.d. sum: \\[\\begin{equation}\\label{eqn:IC} \\Psi(P_n) - \\Psi(P_0) = \\frac{1}{n} \\sum_{i=1}^n IC(O_i; \\nu) + o_p(1/\\sqrt{n}) \\end{equation}\\] where \\(IC(O_i; \\nu)\\) (the influence curve or function) is a function of the data and possibly other nuisance parameters \\(\\nu\\). Importantly, such estimators have mean-zero Gaussian limiting distributions; thus, in the univariate case, one has that \\[\\begin{equation}\\label{eqn:limit_dist} \\sqrt{n}(\\Psi(P_n) - \\Psi(P_0)) \\xrightarrow[]{D}N(0,\\mathbb{V}IC(O_i;\\nu)), \\end{equation}\\] so that inference for the estimator of interest may be obtained in terms of the influence function. For this simple case, a 95% confidence interval may be derived as: \\[\\begin{equation}\\label{eqn:CI} \\Psi(P^{\\star}_n) \\pm z_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}, \\end{equation}\\] where \\(SE=\\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\\) and \\(\\hat{\\sigma}^2\\) is the sample variance of the estimated IC’s: \\(IC(O; \\hat{\\nu})\\). One can use the functional delta method to derive the influence curve if a parameter of interest may be written as a function of other asymptotically linear estimators. Thus, we can derive robust inference for parameters that are estimated by fitting complex, machine learning algorithms and these methods are computationally quick (do not rely on re-sampling based methods like the bootstrap). References "],
["data.html", "Chapter 3 Datasets 3.1 International Stroke Trial Example Dataset 3.2 WASH Benefits Example Dataset 3.3 Veterans’ Administration Lung Cancer Trial Dataset", " Chapter 3 Datasets 3.1 International Stroke Trial Example Dataset The International Stroke Trial database contains individual patient data from the International Stroke Trial (IST), a multi-national randomized trial conducted between 1991 and 1996 (pilot phase between 1991 and 1993) that aimed to assess whether early administration of aspirin, heparin, both or neither influenced the clinical course of acute ischaemic stroke (Sandercock et al. 1997). The IST dataset includes data on 19,435 patients with acute stroke, with 99% complete follow-up. De-identified data are available for download at https://datashare.is.ed.ac.uk/handle/10283/128. This study is described in more detail at the bottom of this page, and in the corresponding block quote reference. In the example data for this workshop, we consider a sample of 5,000 patients and the binary outcome of recurrent ischemic stroke within 14 days after randomization. Also in our example data, we ensure that we have subjects with a missing outcome. The data dictionary is available in the data folder, ist_variables.pdf. library(tidyverse) # read in data ist &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/ist_sample.csv&quot;) ist # A tibble: 5,000 x 26 RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 46 F F 85 N N N N Y N 150 2 33 F M 71 Y Y Y Y N Y 180 3 6 D M 88 N Y N N N N 140 4 8 F F 68 Y N Y Y N N 118 5 13 F M 60 N N Y N N N 140 6 16 F F 71 Y N Y N N N 160 7 6 F M 71 Y N N N N Y 130 8 15 F M 84 N N Y N Y N 160 9 9 D F 81 N N N N N Y 138 10 20 F F 70 Y N N N N N 170 # … with 4,990 more rows, and 15 more variables: RDEF1 &lt;chr&gt;, RDEF2 &lt;chr&gt;, # RDEF3 &lt;chr&gt;, RDEF4 &lt;chr&gt;, RDEF5 &lt;chr&gt;, RDEF6 &lt;chr&gt;, RDEF7 &lt;chr&gt;, # RDEF8 &lt;chr&gt;, STYPE &lt;chr&gt;, RXHEP &lt;chr&gt;, REGION &lt;chr&gt;, # MISSING_RATRIAL_RASP3 &lt;dbl&gt;, MISSING_RHEP24 &lt;dbl&gt;, RXASP &lt;dbl&gt;, # DRSISC &lt;dbl&gt; For the purposes of this workshop, we we start by treating the data as independent and identically distributed (i.i.d.) random draws from a very large target population. We could, with available options, account for the clustering of the data (within sampled geographic regions), but, for simplification, we avoid these details in these workshop presentations, although modifications of our methodology for biased samples, repeated measures, etc., are available. We have 26 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), indicates recurrent ischemic stroke within 14 days after randomization (DRSISC in ist); the treatment of interest, \\(A\\), is the randomized aspirin vs. no aspirin treatment allocation (RXASP in ist); and the adjustment set, \\(W\\), consists simply of other variable measured at baseline. In this data our outcome is occasionally missing, but we do not need to create a variable indicating this missingness (such as \\(\\Delta\\)) for analyses in the tlverse. If we let \\(\\Delta\\) denote the indicator that the outcome is missing such that \\(\\Delta = 1\\) when the outcome is observed and \\(\\Delta = 0\\) when the outcome is not observed, then we can denote our observed data structure as \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, \\Delta_i, \\Delta Y_i)\\), for \\(i = 1, \\ldots, n\\). Using the skimr package, we can quickly summarize the variables in our data: library(skimr) skim(ist) (#tab:skim_ist_data)Data summary Name ist Number of rows 5000 Number of columns 26 _______________________ Column type frequency: character 19 numeric 7 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace RCONSC 0 1 1 1 0 3 0 SEX 0 1 1 1 0 2 0 RSLEEP 0 1 1 1 0 2 0 RATRIAL 0 1 1 1 0 3 0 RCT 0 1 1 1 0 2 0 RVISINF 0 1 1 1 0 2 0 RHEP24 0 1 1 1 0 3 0 RASP3 0 1 1 1 0 3 0 RDEF1 0 1 1 1 0 3 0 RDEF2 0 1 1 1 0 3 0 RDEF3 0 1 1 1 0 3 0 RDEF4 0 1 1 1 0 3 0 RDEF5 0 1 1 1 0 3 0 RDEF6 0 1 1 1 0 3 0 RDEF7 0 1 1 1 0 3 0 RDEF8 0 1 1 1 0 3 0 STYPE 0 1 3 4 0 5 0 RXHEP 0 1 1 1 0 4 0 REGION 0 1 10 26 0 7 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist RDELAY 0 1 20.14 12.43 1 9 19 29 48 ▇▆▆▃▂ AGE 0 1 71.93 11.65 16 65 74 81 99 ▁▁▃▇▂ RSBP 0 1 160.62 27.84 71 140 160 180 290 ▁▇▇▁▁ MISSING_RATRIAL_RASP3 0 1 0.05 0.22 0 0 0 0 1 ▇▁▁▁▁ MISSING_RHEP24 0 1 0.02 0.13 0 0 0 0 1 ▇▁▁▁▁ RXASP 0 1 0.50 0.50 0 0 0 1 1 ▇▁▁▁▇ DRSISC 10 1 0.02 0.15 0 0 0 0 1 ▇▁▁▁▁ A convenient summary of the relevant variables is given just above. &quot;The study had a prospective, randomised, open treatment, blinded outcome (PROBE) design. The inclusion criteria were: clinical diagnosis of acute ischaemic stroke, with onset within the previous 48 hours and no clear indication for, or clear contraindication to, treatment with aspirin or subcutaneous heparin. Unlike many stroke trials of that era (and subsequently), the study did not set an upper age limit. Patients were to have a CT brain scan to confirm the diagnosis of stroke, and this was to be done before randomisation if at all possible. To enter a patient in the study, the clinician telephoned a central randomisation service (at the Clinical Trial Service Unit, Oxford) during this telephone call, the baseline variables were entered and checked, and once validated, the computer allocated the treatment and the telephonist then informed the clinician. The patients and treating clinicians were not blinded to the treatment given. Early outcome data were collected by the treating physician who completed a follow-up form at 14 days, death or hospital discharge (whichever occurred first). This form recorded data on events in hospital within 14 days, and the doctor’s opinion on the final diagnosis of the initial event that led to randomisation. These unblinded data, may therefore be subject to some degree of bias. The primary outcome was the proportion of patients who were either dead or dependent on other people for activities of daily living at six months after randomisation. This outcome was collected by postal questionnaire mailed directly to the patient, or (in Italy) by telephone interview of the patient by a trained researcher, blinded to treatment allocation. The primary outcome was therefore assessed - as far as practicable - blind to treatment allocation and hence should be free from bias. We re-checked the data set for inaccuracies and inconsistencies and extracted data on the variables assessed at randomisation, and at the two outcome assessment points: at 14-days after randomisation, death or prior hospital discharge (whichever occurred first) and at 6-months. — Sandercock, Niewada, and Członkowska (2011) 3.2 WASH Benefits Example Dataset The data come from a study of the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster-randomised controlled trial (Luby et al. 2018). The study enrolled pregnant women in their first or second trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block-randomised, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; hand-washing with soap; combined water, sanitation, and hand washing; improved nutrition through counseling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the workshop, we concentrate on child growth (size for age) as the outcome of interest. For reference, this trial was registered with ClinicalTrials.gov as NCT01590095. library(tidyverse) # read in data dat &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;) dat # A tibble: 4,695 x 28 whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 0 Cont… N05265 9 268 male 30 Prima… 146. Food S… 3 2 -1.16 Cont… N05265 9 286 male 25 Prima… 149. Modera… 2 3 -1.05 Cont… N08002 9 264 male 25 Prima… 152. Food S… 1 4 -1.26 Cont… N08002 9 252 fema… 28 Prima… 140. Food S… 3 5 -0.59 Cont… N06531 9 336 fema… 19 Secon… 151. Food S… 2 6 -0.51 Cont… N06531 9 304 male 20 Secon… 154. Severe… 0 7 -2.46 Cont… N08002 9 336 fema… 19 Prima… 151. Food S… 2 8 -0.6 Cont… N06528 9 312 fema… 25 No ed… 142. Food S… 2 9 -0.23 Cont… N06528 9 322 male 30 Secon… 153. Food S… 1 10 -0.14 Cont… N06453 9 376 male 30 No ed… 156. Modera… 2 # … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;, # elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;, # asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;, # asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;, # asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt; We have 28 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), is the weight-for-height Z-score (whz in dat); the treatment of interest, \\(A\\), is the randomized treatment group (tr in dat); and the adjustment set, \\(W\\), consists simply of everything else. This results in our observed data structure being \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, Y_i)\\), for \\(i = 1, \\ldots, n\\). Like before, we can summarize the variables measured in the WASH Benefits data set with skimr: skim(dat) (#tab:skim_washb_data)Data summary Name dat Number of rows 4695 Number of columns 28 _______________________ Column type frequency: character 5 numeric 23 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace tr 0 1 3 15 0 7 0 fracode 0 1 2 6 0 20 0 sex 0 1 4 6 0 2 0 momedu 0 1 12 15 0 3 0 hfiacat 0 1 11 24 0 4 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist whz 0 1.00 -0.59 1.03 -4.67 -1.28 -0.6 0.08 4.97 ▁▆▇▁▁ month 0 1.00 6.45 3.33 1.00 4.00 6.0 9.00 12.00 ▇▇▅▇▇ aged 0 1.00 266.32 52.17 42.00 230.00 266.0 303.00 460.00 ▁▂▇▅▁ momage 18 1.00 23.91 5.24 14.00 20.00 23.0 27.00 60.00 ▇▇▁▁▁ momheight 31 0.99 150.50 5.23 120.65 147.05 150.6 154.06 168.00 ▁▁▆▇▁ Nlt18 0 1.00 1.60 1.25 0.00 1.00 1.0 2.00 10.00 ▇▂▁▁▁ Ncomp 0 1.00 11.04 6.35 2.00 6.00 10.0 14.00 52.00 ▇▃▁▁▁ watmin 0 1.00 0.95 9.48 0.00 0.00 0.0 1.00 600.00 ▇▁▁▁▁ elec 0 1.00 0.60 0.49 0.00 0.00 1.0 1.00 1.00 ▆▁▁▁▇ floor 0 1.00 0.11 0.31 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ walls 0 1.00 0.72 0.45 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ roof 0 1.00 0.99 0.12 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ asset_wardrobe 0 1.00 0.17 0.37 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▂ asset_table 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_chair 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_khat 0 1.00 0.61 0.49 0.00 0.00 1.0 1.00 1.00 ▅▁▁▁▇ asset_chouki 0 1.00 0.78 0.41 0.00 1.00 1.0 1.00 1.00 ▂▁▁▁▇ asset_tv 0 1.00 0.30 0.46 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_refrig 0 1.00 0.08 0.27 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_bike 0 1.00 0.32 0.47 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_moto 0 1.00 0.07 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_sewmach 0 1.00 0.06 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_mobile 0 1.00 0.86 0.35 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ Note that the asset variables reflect socio-economic status of the study participants. 3.3 Veterans’ Administration Lung Cancer Trial Dataset This data corresponds to a study conducted by the US Veterans Administration. Male patients with advanced inoperable lung cancer were given either the standard therapy or a test chemotherapy. The primary goal of the study was to assess if the test chemotherapy improved survival. This data set has been published in Kalbfleisch and Prentice (2011) and it is available in the MASS and survival R packages. Time to death was recorded for 128 patients, and 9 patients left the study before death. Various covariates were also documented for each patient. library(tidyverse) # read in data vet &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/veteran.csv&quot;) vet # A tibble: 137 x 9 X1 trt celltype time status karno diagtime age prior &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 1 squamous 72 1 60 7 69 0 2 2 1 squamous 411 1 70 5 64 10 3 3 1 squamous 228 1 60 3 38 0 4 4 1 squamous 126 1 60 9 63 10 5 5 1 squamous 118 1 70 11 65 10 6 6 1 squamous 10 1 20 5 49 0 7 7 1 squamous 82 1 40 10 69 10 8 8 1 squamous 110 1 80 29 68 0 9 9 1 squamous 314 1 50 18 43 0 10 10 1 squamous 100 0 70 6 70 0 # … with 127 more rows A snapshot of the data set in shown below: skim(vet) (#tab:skim_vet_data)Data summary Name vet Number of rows 137 Number of columns 9 _______________________ Column type frequency: character 1 numeric 8 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace celltype 0 1 5 9 0 4 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist X1 0 1 69.00 39.69 1 35 69 103 137 ▇▇▇▇▇ trt 0 1 1.50 0.50 1 1 1 2 2 ▇▁▁▁▇ time 0 1 121.63 157.82 1 25 80 144 999 ▇▁▁▁▁ status 0 1 0.93 0.25 0 1 1 1 1 ▁▁▁▁▇ karno 0 1 58.57 20.04 10 40 60 75 99 ▁▅▇▇▂ diagtime 0 1 8.77 10.61 1 3 5 11 87 ▇▁▁▁▁ age 0 1 58.31 10.54 34 51 62 66 81 ▃▂▅▇▁ prior 0 1 2.92 4.56 0 0 0 10 10 ▇▁▁▁▃ References "],
["super-ensemble-machine-learning.html", "Chapter 4 Super (Ensemble Machine) Learning 4.1 Introduction 4.2 sl3 “Microwave Dinner” Implementation 4.3 Extensions 4.4 Exercise 4.5 Summary", " Chapter 4 Super (Ensemble Machine) Learning Based on the sl3 R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin. Updated: 2019-12-06 4.1 Introduction Once the statistical estimation problem is defined, as described in the The Targeted Learning Roadmap, we are ready to construct the TMLE: an asymptotically efficient substitution estimator of this target quantity. The first step in the estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (van der Laan, Polley, and Hubbard 2007), an important step for creating a robust estimator. 4.1.1 Super Learning A common task in statistical data analysis is estimator selection (e.g., for prediction). There is no universally optimal machine learning algorithm for density estimation or prediction. For some data, one needs learners that can model a complex function. For others, possibly as a result of noise or insufficient sample size, a simple, parametric model might fit best. Super Learner, an ensemble learner, solves this issue, by allowing a combination of learners from the simplest (intercept-only) to most complex (neural nets, random forests, SVM, etc). It works by using cross-validation in a manner which guarantees that the resulting fit will be as good as possible, given the learners provided. Note: even a combination of poor learners can sometimes result in good fit. It is very important to have good candidates in our library, possibly incorporating known knowledge about the system in question. 4.1.1.1 General Overview of the Algorithm What is cross-validation and how does it work? There are many different cross-validation schemes, designed to accommodate different study designs and data structures. The figure below shows an example of 10-fold cross-validation. General step-by-step overview of the Super Learner algorithm: Break up the sample evenly into V-folds (say V=10). For each of these 10 folds, remove that portion of the sample (kept out as validation sample) and the remaining will be used to fit learners (training sample). Fit each learner on the training sample (note, some learners will have their own internal cross-validation procedure or other methods to select tuning parameters). For each observation in the corresponding validation sample, predict the outcome using each of the learners, so if there are \\(p\\) learners, then there would be \\(p\\) predictions. Take out another validation sample and repeat until each of the V-sets of data are removed. Compare the cross-validated fit of the learners across all observations based on specified loss function (e.g., squared error, negative log-likelihood, …) by calculating the corresponding average loss (risk). Either: choose the learner with smallest risk and apply that learner to entire data set (resulting SL fit), do a weighted average of the learners to minimize the cross-validated risk (construct an ensemble of learners), by re-fitting the learners on the original data set, and use the weights above to get the SL fit. Note, this entire procedure can be itself cross-validated to get a consistent estimate of the future performance of the SL fit. How to pick a Super Learner library? A library is simply a collection of algorithms. The algorithms in the library should come from contextual knowledge and a large set of “default” algorithms. The algorithms may range from a simple linear regression model to multi-step algorithms involving screening covariates, penalizations, optimizing tuning parameters, etc. 4.1.1.2 Example: Super Learner In Prediction We observe a learning data set \\(X_i=(Y_i,W_i)\\), for \\(i=1, ..., n\\). Here, \\(Y_i\\) is the outcome of interest, and \\(W_i\\) is a p-dimensional set of covariates. Our objective is to estimate the function \\(\\psi_0(W) = E(Y|W)\\). This function can be expressed as the minimizer of the expected loss: \\(\\psi_0(W) = \\text{argmin}_{\\psi} E[L(X,\\psi(W))]\\). Here, the loss function is represented as \\(L\\) (e.g., squared error loss, \\(L: (Y-\\psi(W))^2)\\)). 4.1.1.3 Why use the Super Learner? For prediction, one can use the cross-validated risk to empirically determine the relative performance of SL and competing methods. When we have tested different algorithms on actual data and looked at the performance (e.g., MSE of prediction), never does one algorithm always win (see below). Below shows the results of such a study, comparing the fits of several different learners, including the SL algorithms. Super Learner performs asymptotically as well as best possible weighted combination. By including all competitors in the library of candidate estimators (glm, neural nets, SVMs, random forest, etc.), the Super Learner will asymptotically outperform any of its competitors- even if the set of competitors is allowed to grow polynomial in sample size. Motivates the name “Super Learner”: it provides a system of combining many estimators into an improved estimator. Review of the Super Learner Loss-function-based tool that uses V-fold cross-validation to obtain the best prediction of the relevant part of the likelihood that’s needed to evaluate target parameter. Requires expressing the estimand as the minimizer of an expected loss, and proposing a library of algorithms (“learners” in sl3 nomenclature) that we think might be consistent with the true data-generating distribution. The discrete super learner, or cross-validated selector, is the algorithm in the library that minimizes the V-fold cross-validated empirical risk. The super learner is a weighted average of the library of algorithms, where the weights are chosen to minimize the V-fold cross-validated empirical risk of the library. Restricting the weights (“metalearner” in sl3 nomenclature) to be positive and sum to one (convex combination) has been shown to improve upon the discrete super learner (Polley and van der Laan 2010; van der Laan, Polley, and Hubbard 2007). Proven to be asymptotically as accurate as the best possible prediction algorithm that is tested (van der Laan and Dudoit 2003; van der Vaart, Dudoit, and van der Laan 2006). This background material is described in greater detail in the accompanying tlverse handbook sl3 chapter. 4.2 sl3 “Microwave Dinner” Implementation We begin by illustrating the core functionality of the super learner algorithm as implemented in sl3. For those who are interested in the internals of sl3, see this sl3 introductory tutorial. The sl3 implementation consists of the following steps: Load the necessary libraries and data Define the machine learning task Make a super learner by creating library of base learners and a metalearner Train the super learner on the machine learning task Obtain predicted values International Stroke Trial Example Using the IST data, we are interested in predicting recurrent stroke DRSISC using the available covariate data. 0. Load the necessary libraries and data library(kableExtra) library(knitr) library(skimr) library(tidyverse) library(data.table) library(sl3) library(SuperLearner) library(origami) set.seed(7194) # load data set and take a peek ist_data &lt;- read.csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/ist_sample.csv&quot;) head(ist_data) %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1 RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE RXHEP REGION MISSING_RATRIAL_RASP3 MISSING_RHEP24 RXASP DRSISC 46 F F 85 N N N N Y N 150 N Y N N N N N N PACS N Europe and Central Asia 0 0 0 0 33 F M 71 Y Y Y Y N Y 180 Y Y Y Y Y N N N TACS L East Asia and Pacific 0 0 0 0 6 D M 88 N Y N N N N 140 Y Y Y C C C C C PACS N Europe and Central Asia 0 0 0 0 8 F F 68 Y N Y Y N N 118 Y Y N N N N N N LACS M Europe and Central Asia 0 0 0 0 13 F M 60 N N Y N N N 140 Y Y Y Y N N Y Y POCS N Europe and Central Asia 0 0 1 0 16 F F 71 Y N Y N N N 160 N Y N N N N N N PACS N Europe and Central Asia 0 0 1 0 1. Define the machine learning task To define the machine learning “task” (predict stroke DRSISC using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, id, offset). We are not interested in predicting missing outcomes. We set drop_missing_outcome = TRUE when we create the task. In the next chapter, we estimate this missingness mechanism and account for it in the estimation. # specify the outcome and covariates outcome &lt;- &quot;DRSISC&quot; covars &lt;- colnames(ist_data)[-which(names(ist_data) == outcome)] # create the sl3 task ist_task &lt;- make_sl3_Task( data = ist_data, covariates = covars, outcome = outcome, drop_missing_outcome = TRUE ) Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing outcome data detected: dropping outcomes. # examine the task ist_task A sl3 Task with 4990 obs and these nodes: $covariates [1] &quot;RDELAY&quot; &quot;RCONSC&quot; &quot;SEX&quot; [4] &quot;AGE&quot; &quot;RSLEEP&quot; &quot;RATRIAL&quot; [7] &quot;RCT&quot; &quot;RVISINF&quot; &quot;RHEP24&quot; [10] &quot;RASP3&quot; &quot;RSBP&quot; &quot;RDEF1&quot; [13] &quot;RDEF2&quot; &quot;RDEF3&quot; &quot;RDEF4&quot; [16] &quot;RDEF5&quot; &quot;RDEF6&quot; &quot;RDEF7&quot; [19] &quot;RDEF8&quot; &quot;STYPE&quot; &quot;RXHEP&quot; [22] &quot;REGION&quot; &quot;MISSING_RATRIAL_RASP3&quot; &quot;MISSING_RHEP24&quot; [25] &quot;RXASP&quot; $outcome [1] &quot;DRSISC&quot; $id NULL $weights NULL $offset NULL 2. Make a super learner Now that we have defined our machine learning problem with the task, we are ready to “make” the super learner. This requires specification of Base learning algorithms, to establish a library of learners that we think might be consistent with the true data-generating distribution. Metalearner, to ensemble the base learners. We might also incorporate Feature selection, to pass only a subset of the predictors to the algorithm. Hyperparameter specification, to tune base learners. Learners have properties that indicate what features they support. We may use sl3_list_properties() to get a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a binomial outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(c(&quot;binomial&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_caret&quot; [3] &quot;Lrnr_dbarts&quot; &quot;Lrnr_earth&quot; [5] &quot;Lrnr_gam&quot; &quot;Lrnr_gbm&quot; [7] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [9] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [11] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [13] &quot;Lrnr_hal9001&quot; &quot;Lrnr_mean&quot; [15] &quot;Lrnr_optim&quot; &quot;Lrnr_pkg_SuperLearner&quot; [17] &quot;Lrnr_pkg_SuperLearner_method&quot; &quot;Lrnr_pkg_SuperLearner_screener&quot; [19] &quot;Lrnr_polspline&quot; &quot;Lrnr_randomForest&quot; [21] &quot;Lrnr_ranger&quot; &quot;Lrnr_rpart&quot; [23] &quot;Lrnr_screener_corP&quot; &quot;Lrnr_screener_corRank&quot; [25] &quot;Lrnr_screener_randomForest&quot; &quot;Lrnr_solnp&quot; [27] &quot;Lrnr_stratified&quot; &quot;Lrnr_svm&quot; [29] &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them using the make_learner function. # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_glm &lt;- make_learner(Lrnr_glm) We can customize learner hyperparameters to incorporate a diversity of different settings. Documentation for the learners and their hyperparameters can be found in the sl3 Learners Reference. lrnr_ranger50 &lt;- make_learner(Lrnr_ranger, num.trees = 50) lrnr_hal_simple &lt;- make_learner(Lrnr_hal9001, max_degree = 2, n_folds = 2) lrnr_lasso &lt;- make_learner(Lrnr_glmnet) # alpha default is 1 lrnr_ridge &lt;- make_learner(Lrnr_glmnet, alpha = 0) lrnr_elasticnet &lt;- make_learner(Lrnr_glmnet, alpha = .5) We can also include learners from the SuperLearner R package. lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) Here is a fun trick to create customized learners over a grid of parameters. # I like to crock pot my super learners grid_params &lt;- list(cost = c(0.01, 0.1, 1, 10, 100, 1000), gamma = c(0.001, 0.01, 0.1, 1), kernel = c(&quot;polynomial&quot;, &quot;radial&quot;, &quot;sigmoid&quot;), degree = c(1, 2, 3)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) svm_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_svm$new, c(params_default, as.list(params_tune)))}) grid_params &lt;- list(max_depth = c(2, 4, 6, 8), eta = c(0.001, 0.01, 0.1, 0.2, 0.3), nrounds = c(20, 50)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) xgb_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))}) Did you see Lrnr_caret when we called sl3_list_learners(c(&quot;binomial&quot;))? All we need to specify is the algorithm to use, which is passed as method to caret::train(). The default method for parameter selection criterion with is set to “CV” instead of the caret::train() default boot. The summary metric to used to select the optimal model is RMSE for continuous outcomes and Accuracy for categorical and binomial outcomes. # I have no idea how to tune a neural net (or BART machine..) lrnr_caret_nnet &lt;- make_learner(Lrnr_caret, algorithm = &quot;nnet&quot;) lrnr_caret_bartMachine &lt;- make_learner(Lrnr_caret, algorithm = &quot;bartMachine&quot;, method = &quot;boot&quot;, metric = &quot;Accuracy&quot;, tuneLength = 10) In order to assemble the library of learners, we need to “stack” them together. A Stack is a special learner and it has the same interface as all other learners. What makes a stack special is that it combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. stack &lt;- make_learner(Stack, lrnr_glm, lrnr_mean, lrnr_lasso, lrnr_ridge, lrnr_elasticnet ) We can optionally select a subset of available covariates and pass only those variables to the modeling algorithm. Let’s consider screening covariates based on their randomForest variable importance ranking (ordered by mean decrease in accuracy) screen_rf &lt;- make_learner(Lrnr_screener_randomForest, nVar = 5, ntree = 100) # which covariates are selected on the full data? screen_rf$train(ist_task) [1] &quot;Lrnr_screener_randomForest_5_100&quot; $selected [1] &quot;RDELAY&quot; &quot;SEX&quot; &quot;AGE&quot; &quot;RSLEEP&quot; &quot;RSBP&quot; To “pipe” only the selected covariates to the modeling algorithm, we need to make a Pipeline, which is a just set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. screen_rf_pipeline &lt;- make_learner(Pipeline, screen_rf, stack) Now our learners will be preceded by a screening step. We also consider the original stack, just to compare how the feature selection methods perform in comparison to the methods without feature selection. Analogous to what we have seen before, we have to stack the pipeline and original stack together, so we may use them as base learners in our super learner. fancy_stack &lt;- make_learner(Stack, screen_rf_pipeline, stack) # we can visualize the stack dt_stack &lt;- delayed_learner_train(fancy_stack, ist_task) plot(dt_stack, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) We will use the default metalearner, which uses Lrnr_solnp() to provide fitting procedures for a pairing of loss function and metalearner function. The default metalearner chooses loss and metalearner pairing based on the outcome type. Note that any learner can be used as a metalearner. We have made a library/stack of base learners, so we are ready to make the super learner. The super learner algorithm fits a metalearner on the validation-set predictions. sl &lt;- make_learner(Lrnr_sl, learners = fancy_stack ) # we can visualize the super learner dt_sl &lt;- delayed_learner_train(sl, ist_task) plot(dt_sl, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) We can also use Lrnr_cv to build a super learner, cross-validate a stack of learners to compare performance of the learners in the stack, or cross-validate any single learner (see “Cross-validation” section of this sl3 introductory tutorial). Furthermore, we can Define New sl3 Learners which can be used in all the places you could otherwise use any other sl3 learners, including Pipelines, Stacks, and the Super Learner. 3. Train the super learner on the machine learning task Now we are ready to “train” our super learner on our sl3_task object, ist_task. sl_fit &lt;- sl$train(ist_task) 4. Obtain predicted values Now that we have fit the super learner, we are ready to obtain our predicted values, and we can also obtain a summary of the results. sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] 0.02307531 0.02822206 0.01917227 0.02306946 0.02092219 0.02683632 sl_fit$print() [1] &quot;SuperLearner:&quot; List of 2 $ : chr &quot;Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)&quot; $ : chr &quot;Stack&quot; [1] &quot;Lrnr_solnp_TRUE_TRUE_FALSE_1e-05&quot; $pars [1] 0.10000127 0.10000283 0.09999962 0.10000085 0.09999499 0.10001846 [7] 0.10000283 0.09999529 0.10000012 0.09998375 $convergence [1] 0 $values [1] 0.0230736 0.0230736 $lagrange [,1] [1,] 0.000182045 $hessian [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [1,] 1 0 0 0 0 0 0 0 0 0 [2,] 0 1 0 0 0 0 0 0 0 0 [3,] 0 0 1 0 0 0 0 0 0 0 [4,] 0 0 0 1 0 0 0 0 0 0 [5,] 0 0 0 0 1 0 0 0 0 0 [6,] 0 0 0 0 0 1 0 0 0 0 [7,] 0 0 0 0 0 0 1 0 0 0 [8,] 0 0 0 0 0 0 0 1 0 0 [9,] 0 0 0 0 0 0 0 0 1 0 [10,] 0 0 0 0 0 0 0 0 0 1 $ineqx0 NULL $nfuneval [1] 15 $outer.iter [1] 1 $elapsed Time difference of 0.03249311 secs $vscale [1] 0.0230736 0.0000100 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 $coefficients Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glm_TRUE 0.10000127 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_mean 0.10000283 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.09999962 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.10000085 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 0.09999499 Stack_Lrnr_glm_TRUE 0.10001846 Stack_Lrnr_mean 0.10000283 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.09999529 Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.10000012 Stack_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 0.09998375 $training_offset [1] FALSE $name [1] &quot;solnp&quot; [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner 1: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 4: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 5: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 6: Stack_Lrnr_glm_TRUE 7: Stack_Lrnr_mean 8: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 9: Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 10: Stack_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 11: SuperLearner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk 1: 0.10000127 0.02310653 0.002047872 0.005298033 0.01765364 0.03494974 2: 0.10000283 0.02309466 0.002050044 0.005317404 0.01774964 0.03496153 3: 0.09999962 0.02310366 0.002050655 0.005310963 0.01774964 0.03496153 4: 0.10000085 0.02309954 0.002050446 0.005313563 0.01774964 0.03496123 5: 0.09999499 0.02311787 0.002051626 0.005302995 0.01774964 0.03496153 6: 0.10001846 0.02336042 0.002031224 0.005202322 0.01753999 0.03491601 7: 0.10000283 0.02309466 0.002050044 0.005317404 0.01774964 0.03496153 8: 0.09999529 0.02313214 0.002046856 0.005284860 0.01770783 0.03485090 9: 0.10000012 0.02310411 0.002042884 0.005227175 0.01769421 0.03471470 10: 0.09998375 0.02317824 0.002049707 0.005265698 0.01770753 0.03486204 11: NA 0.02307360 0.002051115 0.005308319 0.01764294 0.03492837 4.3 Extensions 4.3.1 Cross-validated Super Learner We can cross-validate the super learner to see how well the super learner performs on unseen data, and obtain an estimate of the cross-validated risk of the super learner. This estimation procedure requires an “external” layer of cross-validation, also called nested cross-validation, which involves setting aside a separate holdout sample that we don’t use to fit the super learner. This external cross-validation procedure may also incorporate 10 folds, which is the default in sl3. However, we will incorporate 2 outer/external folds of cross-validation for computational efficiency. We also need to specify a loss function to evaluate super learner. Documentation for the available loss functions can be found in the sl3 Loss Function Reference. ist_task_new &lt;- make_sl3_Task( data = ist_data, covariates = covars, outcome = outcome, drop_missing_outcome = TRUE, folds = make_folds(n = sum(!is.na(ist_data$DRSISC)), fold_fun = folds_vfold, V = 2) ) CVsl &lt;- CV_lrnr_sl(sl_fit, ist_task_new, loss_squared_error) CVsl %&gt;% kable() %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) learner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glm_TRUE 0.0999914 0.0232048 0.0020484 0.0023337 0.0215546 0.0248550 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_mean 0.1000060 0.0230958 0.0020500 0.0021600 0.0215684 0.0246232 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.0999876 0.0231530 0.0020508 0.0022409 0.0215684 0.0247376 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.0999936 0.0231230 0.0020504 0.0021984 0.0215684 0.0246775 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 0.0999880 0.0231526 0.0020507 0.0022403 0.0215684 0.0247368 Stack_Lrnr_glm_TRUE 0.0999883 0.0235503 0.0020280 0.0022289 0.0219743 0.0251264 Stack_Lrnr_mean 0.1000060 0.0230958 0.0020500 0.0021600 0.0215684 0.0246232 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.1000127 0.0230849 0.0020459 0.0021755 0.0215466 0.0246232 Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.1000131 0.0230590 0.0020452 0.0021860 0.0215133 0.0246047 Stack_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 0.1000132 0.0230842 0.0020456 0.0021765 0.0215451 0.0246232 SuperLearner NA 0.0230833 0.0020537 0.0021633 0.0215536 0.0246130 4.3.2 Variable Importance Measures with sl3 The sl3 varimp function returns a table with variables listed in decreasing order of importance, in which the measure of importance is based on a risk difference between the learner fit with a permuted covariate and the learner fit with the true covariate, across all covariates. In this manner, the larger the risk difference, the more important the variable is in the prediction. ist_varimp &lt;- varimp(sl_fit, loss_squared_error) ist_varimp %&gt;% kable() %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) X risk_diff STYPE 8.58e-05 RDEF7 6.03e-05 RCT 1.59e-05 RCONSC 1.20e-05 RSBP 5.30e-06 RASP3 5.20e-06 REGION 5.10e-06 RDEF3 4.20e-06 RDEF6 2.90e-06 RDEF8 2.80e-06 RXASP 2.70e-06 RXHEP 1.90e-06 SEX 9.00e-07 AGE 7.00e-07 RDEF1 7.00e-07 RSLEEP 5.00e-07 MISSING_RHEP24 -1.00e-07 MISSING_RATRIAL_RASP3 -3.00e-07 RDEF4 -1.50e-06 RVISINF -1.60e-06 RDEF5 -4.50e-06 RATRIAL -5.70e-06 RDEF2 -6.10e-06 RDELAY -7.20e-06 RHEP24 -7.90e-06 4.4 Exercise 4.4.1 Predicting Myocardial Infarction with sl3 Follow the steps below to predict myocardial infarction (mi) using the available covariate data. We thank Prof. David Benkeser at Emory University for making the this Cardiovascular Health Study (CHS) data accessible. # load the data set db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) # take a quick peek head(chspred) %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;200px&quot;) waist alcoh hdl beta smoke ace ldl bmi aspirin gend age estrgn glu ins cysgfr dm fetuina whr hsed race logcystat logtrig logcrp logcre health logkcal sysbp mi 110.1642 0.0000 66.4974 0 0 1 114.2162 27.9975 0 0 73.5179 0 159.9314 70.3343 75.0078 1 0.1752 1.1690 1 1 -0.3420 5.4063 2.0126 -0.6739 0 4.3926 177.1345 0 89.9763 0.0000 50.0652 0 0 0 103.7766 20.8931 0 0 61.7723 0 153.3888 33.9695 82.7433 1 0.5717 0.9011 0 0 -0.0847 4.8592 3.2933 -0.5551 1 6.2071 136.3742 0 106.1941 8.4174 40.5059 0 0 0 165.7158 28.4554 1 1 72.9312 0 121.7145 -17.3017 74.6989 0 0.3517 1.1797 0 1 -0.4451 4.5088 0.3013 -0.0115 0 6.7320 135.1993 0 90.0566 0.0000 36.1750 0 0 0 45.2035 23.9608 0 0 79.1191 0 53.9691 11.7315 95.7823 0 0.5439 1.1360 0 0 -0.4807 5.1832 3.0243 -0.5751 1 7.3972 139.0182 0 78.6143 2.9790 71.0642 0 1 0 131.3121 10.9656 0 1 69.0179 0 94.3153 9.7112 72.7109 0 0.4916 1.1028 1 0 0.3121 4.2190 -0.7057 0.0053 1 8.2779 88.0470 0 91.6593 0.0000 59.4963 0 0 0 171.1872 29.1317 0 1 81.8346 0 212.9066 -28.2269 69.2184 1 0.4621 0.9529 1 0 -0.2872 5.1773 0.9705 0.2127 1 5.9942 69.5943 0 Create an sl3 task, setting myocardial infarction mi as the outcome and using all available covariate data. Make a library of seven relatively fast base learning algorithms (i.e., do not consider BART or HAL). Customize hyperparameters for one of your learners. Feel free to use learners from sl3 or SuperLearner. You may use the same base learning library that is presented above. Incorporate feature selection with the screener Lrnr_screener_corP. Fit the metalearning step with non-negative least squares, Lrnr_nnls. With the metalearner and base learners, make the super learner and train it on the task. Print your super learner fit by calling print() with $. Which learner is the discrete super learner? Cross-validate your super learner fit to see how well it performs on unseen data. Specify loss_squared_error as the loss function to evaluate the super learner. Like above, create a new task with 2 folds of external cross-validation for computational efficiency. Report the cross-validated mean risk of the discrete super learner and the super learner. 4.5 Summary The general ensemble learning approach of super learner can be applied to a diversity of estimation and prediction problems that can be defined by a loss function. Plug-in estimators of the estimand are desirable because a plug-in estimator respects both the local and global constraints of the statistical model. Asymptotically linear estimators are also advantageous, since they converge to the estimand at \\(\\frac{1}{\\sqrt{n}}\\) rate, and thereby permit formal statistical inference. If we plug in the estimator returned by super learner into the target parameter mapping, then we would end up with an estimator that has the same bias as what we plugged in. This estimator would not be asymptotically linear. Targeted maximum likelihood estimation (TMLE) is a general strategy that succeeds in constructing asymptotically linear plug-in estimators. In the chapters that follow, we focus on the targeted maximum likelihood estimator and the targeted minimum loss-based estimator, both referred to as TMLE. 4.5.1 Exercise Solutions Here is a potential solution to the (sl3 Exercise – Predicting Myocardial Infarction with sl3)(???). chspred_task &lt;- make_sl3_Task( data = chspred, covariates = head(colnames(chspred), -1), outcome = &quot;mi&quot; ) glm_learner &lt;- Lrnr_glm$new() lasso_learner &lt;- Lrnr_glmnet$new(alpha = 1) ridge_learner &lt;- Lrnr_glmnet$new(alpha = 0) enet_learner &lt;- Lrnr_glmnet$new(alpha = 0.5) curated_glm_learner &lt;- Lrnr_glm_fast$new(formula = &quot;mi ~ smoke + beta + waist&quot;) mean_learner &lt;- Lrnr_mean$new() # That is one mean learner! glm_fast_learner &lt;- Lrnr_glm_fast$new() ranger_learner &lt;- Lrnr_ranger$new() svm_learner &lt;- Lrnr_svm$new() xgb_learner &lt;- Lrnr_xgboost$new() screen_cor &lt;- make_learner(Lrnr_screener_corP) glm_pipeline &lt;- make_learner(Pipeline, screen_cor, glm_learner) stack &lt;- make_learner( Stack, glm_pipeline, glm_learner, lasso_learner, ridge_learner, enet_learner, curated_glm_learner, mean_learner, glm_fast_learner, ranger_learner, svm_learner, xgb_learner ) metalearner &lt;- make_learner(Lrnr_nnls) sl &lt;- Lrnr_sl$new( learners = stack, metalearner = metalearner ) sl_fit &lt;- sl$train(chspred_task) sl_fit$print() CVsl &lt;- CV_lrnr_sl(sl_fit, chspred_task, loss_squared_error) CVsl References "],
["the-tmle-framework.html", "Chapter 5 The TMLE Framework 5.1 Introduction 5.2 Learning Objectives 5.3 Easy-Bake Example: tmle3 for ATE 5.4 tmle3 Components 5.5 Fitting tmle3 with multiple parameters 5.6 Stratified Effect Estimates 5.7 Exercise 5.8 Summary", " Chapter 5 The TMLE Framework Based on the tmle3 R package. Updated: 2019-12-06 5.1 Introduction The first step in the estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (van der Laan, Polley, and Hubbard 2007), as described in the previous section. With the initial estimate of relevant parts of the data-generating distribution necessary to evaluate the target parameter, we are ready to construct the TMLE! 5.1.1 Substitution Estimators Beyond a fit of the prediction function, one might also want to estimate more targeted parameters specific to certain scientific questions. The approach is to plug into the estimand of interest estimates of the relevant distributions. Sometimes, we can use simple empirical distributions, but averaging some function over the observations (e.g., giving weight \\(1/n\\) for all observations). Other parts of the distribution, like conditional means or probabilities, the estimate will require some sort of smoothing due to the curse of dimensionality. We give one example using an example of the average treatment effect (see above): \\(\\Psi(P_0) = \\Psi(Q_0) = \\mathbb{E}_0 \\big[\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\big]\\), where \\(Q_0\\) represents both the distribution of \\(Y \\mid A,W\\) and distribution of \\(W\\). Let \\(\\bar{Q}_0(A,W) \\equiv \\mathbb{E}_0(Y \\mid A,W)\\) and \\(Q_{0,W}(w) = P_0 (W=w)\\), then \\[ \\Psi(Q_0) = \\sum_w \\{ \\bar{Q}_0(1,w)-\\bar{Q}_0(0,w)\\} Q_{0,W}(w) \\] The Substitution Estimator plugs in the empirical distribution (weight \\(1/n\\) for each observation) for \\(Q_{0,W}(W_i)\\), and some estimate of the regression of \\(Y\\) on \\((A,W)\\) (say SL fit): \\[ \\Psi(Q_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}_n(1,W_i)-\\bar{Q}_n(0,W_i)\\} \\] Thus, it becomes the average of the differences in predictions from the fit keeping the observed \\(W\\), but first replacing \\(A=1\\) and then the same but all \\(A=0\\). 5.1.2 TMLE Though using SL over an arbitrary parametric regression is an improvement, it’s not sufficient to have the properties of an estimator one needs for rigorous inference. Because the variance-bias trade-off in the SL is focused on the prediction model, it can, for instance, under-fit portions of the distributions that are critical for estimating the parameter of interest, \\(\\Psi(P_0)\\). TMLE keeps the benefits of substitution estimators (it is one), but augments the original estimates to correct for this issue and also results in an asymptotically linear (and thus normally-distributed) estimator with consistent Wald-style confidence intervals. Produces a well-defined, unbiased, efficient substitution estimator of target parameters of a data-generating distribution. Updates an initial (super learner) estimate of the relevant part of the data-generating distribution possibly using an estimate of a nuisance parameter (like the model of intervention given covariates). Removes asymptotic residual bias of initial estimator for the target parameter, if it uses a consistent estimator of \\(g_0\\). If initial estimator was consistent for the target parameter, the additional fitting of the data in the targeting step may remove finite sample bias, and preserves consistency property of the initial estimator. If the initial estimator and the estimator of \\(g_0\\) are both consistent, then it is also asymptotically efficient according to semi-parametric statistical model efficiency theory. Thus, every effort is made to achieve minimal bias and the asymptotic semi-parametric efficiency bound for the variance. There are different types of TMLE, sometimes for the same set of parameters, but below is an example of the algorithm for estimating the ATE. In this case, one can present the estimator as: \\[ \\Psi(Q^{\\star}_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}^{\\star}_n(1,W_i) - \\bar{Q}^{\\star}_n(0,W_i)\\} \\] where \\(\\bar{Q}^{\\star}_n(A,W)\\) is the TMLE augmented estimate. \\(f(\\bar{Q}^{\\star}_n(A,W)) = f(\\bar{Q}_n(A,W)) + \\epsilon_n \\cdot h_n(A,W)\\), where \\(f(\\cdot)\\) is the appropriate link function (e.g., logit), \\(\\epsilon_n\\) is an estimated coefficient and \\(h_n(A,W)\\) is a “clever covariate”. In this case, \\(h_n(A,W) = \\frac{A}{g_n(W)}-\\frac{1-A}{1-g_n(W)}\\), with \\(g_n(W) = \\mathbb{P}(A=1 \\mid W)\\) being the estimated (also by SL) propensity score, so the estimator depends both on initial SL fit of the outcome regression (\\(\\bar{Q}_0\\)) and an SL fit of the propensity score (\\(g_n\\)). There are further robust augmentations that are used in tlverse, such as an added layer of cross-validation to avoid over-fitting bias (CV-TMLE), and so called methods that can more robustly estimated several parameters simultaneously (e.g., the points on a survival curve). 5.1.3 Inference The estimators we discuss are asymptotically linear, meaning that the difference in the estimate \\(\\Psi(P_n)\\) and the true parameter (\\(\\Psi(P_0)\\)) can be represented in first order by a i.i.d. sum: \\[\\begin{equation}\\label{eqn:IC} \\Psi(P_n) - \\Psi(P_0) = \\frac{1}{n} \\sum_{i=1}^n IC(O_i; \\nu) + o_p(1/\\sqrt{n}) \\end{equation}\\] where \\(IC(O_i; \\nu)\\) (the influence curve or function) is a function of the data and possibly other nuisance parameters \\(\\nu\\). Importantly, such estimators have mean-zero Gaussian limiting distributions; thus, in the univariate case, one has that \\[\\begin{equation}\\label{eqn:limit_dist} \\sqrt{n}(\\Psi(P_n) - \\Psi(P_0)) \\xrightarrow[]{D}N(0,\\mathbb{V}IC(O_i;\\nu)), \\end{equation}\\] so that inference for the estimator of interest may be obtained in terms of the influence function. For this simple case, a 95% confidence interval may be derived as: \\[\\begin{equation}\\label{eqn:CI} \\Psi(P^{\\star}_n) \\pm z_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}, \\end{equation}\\] where \\(SE=\\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\\) and \\(\\hat{\\sigma}^2\\) is the sample variance of the estimated IC’s: \\(IC(O; \\hat{\\nu})\\). One can use the functional delta method to derive the influence curve if a parameter of interest may be written as a function of other asymptotically linear estimators. Thus, we can derive robust inference for parameters that are estimated by fitting complex, machine learning algorithms and these methods are computationally quick (do not rely on re-sampling based methods like the bootstrap). 5.2 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 5.3 Easy-Bake Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the IST example data introduced earlier and estimating an Average Treatment Effect (ATE). As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = \\mathbb{E}_0(Y(1)-Y(0)) = \\mathbb{E}_0\\left(\\mathbb{E}_0[Y \\mid A=1,W]-\\mathbb{E}_0[Y \\mid A=0,W] \\right)\\) This Easy-Bake implementation consists of the following steps: Load the necessary libraries and data Define the variable roles Create a “Spec” object Define the super learners Fit the TMLE Evaluate the TMLE estimates 0. Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(data.table) library(tmle3) library(sl3) ist_data &lt;- data.table(read.csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/ist_sample.csv&quot;)) 1. Define the variable roles We’ll use the common \\(W\\) (covariates), \\(A\\) (treatment/intervention), \\(Y\\) (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list( W = c( &quot;RXHEP&quot;, &quot;REGION&quot;, &quot;RDELAY&quot;, &quot;RCONSC&quot;, &quot;SEX&quot;, &quot;AGE&quot;, &quot;RSLEEP&quot;, &quot;RVISINF&quot;, &quot;RCT&quot;, &quot;RATRIAL&quot;, &quot;RASP3&quot;, &quot;MISSING_RATRIAL_RASP3&quot;, &quot;RHEP24&quot;, &quot;MISSING_RHEP24&quot;, &quot;RSBP&quot;, &quot;RDEF1&quot;, &quot;RDEF2&quot;, &quot;RDEF3&quot;, &quot;RDEF4&quot;, &quot;RDEF5&quot;, &quot;RDEF6&quot;, &quot;RDEF7&quot;, &quot;RDEF8&quot;, &quot;STYPE&quot; ), A = &quot;RXASP&quot;, Y = &quot;DRSISC&quot; ) Handling Missingness Currently, missingness in tlverse is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing treatment variables are excluded. We implement an IPCW-TMLE to more efficiently handle missingness in the outcome variables. These steps are implemented in the process_missing() function in tmle3, and are automatically handled in sl3. In this data, we already imputed missing covariate values which were present in RATRIAL, RASP3, RHEP24; and we created additional covariates indicating imputation MISSING_RATRIAL_RASP3, MISSING_RHEP24. The missingness was identical for RATRIAL and RASP3, so we only needed to create one covariate indicating imputation for these two variables. head(ist_data) RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1 1: 46 F F 85 N N N N Y N 150 N 2: 33 F M 71 Y Y Y Y N Y 180 Y 3: 6 D M 88 N Y N N N N 140 Y 4: 8 F F 68 Y N Y Y N N 118 Y 5: 13 F M 60 N N Y N N N 140 Y 6: 16 F F 71 Y N Y N N N 160 N RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE RXHEP 1: Y N N N N N N PACS N 2: Y Y Y Y N N N TACS L 3: Y Y C C C C C PACS N 4: Y N N N N N N LACS M 5: Y Y Y N N Y Y POCS N 6: Y N N N N N N PACS N REGION MISSING_RATRIAL_RASP3 MISSING_RHEP24 RXASP DRSISC 1: Europe and Central Asia 0 0 0 0 2: East Asia and Pacific 0 0 0 0 3: Europe and Central Asia 0 0 0 0 4: Europe and Central Asia 0 0 0 0 5: Europe and Central Asia 0 0 1 0 6: Europe and Central Asia 0 0 1 0 2. Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set of components into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE( treatment_level = 1, control_level = 0 ) 3. Define the Relevant Super Learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: \\(Q\\), \\(g\\), and \\(\\Delta\\). This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_lasso &lt;- make_learner(Lrnr_glmnet) lrnr_ridge &lt;- make_learner(Lrnr_glmnet, alpha = 0) lrnr_ranger &lt;- make_learner(Lrnr_ranger) grid_params &lt;- list(max_depth = c(2, 5, 8), eta = c(0.01, 0.1, 0.3)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) xgb_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))}) learners_Y &lt;- make_learner(Stack, unlist(list(xgb_learners, lrnr_ridge, lrnr_mean, lrnr_ranger, lrnr_lasso, lrnr_glm), recursive = TRUE)) # default metalearner appropriate to data types sl_Y &lt;- Lrnr_sl$new( learners = unlist(list(xgb_learners, lrnr_ridge, lrnr_mean, lrnr_ranger, lrnr_lasso, lrnr_glm), recursive = TRUE) ) sl_Delta &lt;- Lrnr_sl$new( learners = list(lrnr_mean, lrnr_glm, lrnr_lasso, lrnr_ridge) ) sl_A &lt;- Lrnr_sl$new( learners = list(lrnr_mean, lrnr_glm) ) learner_list &lt;- list(A = sl_A, delta_Y = sl_Delta, Y = sl_Y) Here, we use a super learner as defined in the previous sl3 section. In the future, we plan to include reasonable default learners. 4. Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, ist_data, node_list, learner_list) 5. Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] -0.001894602 -0.004648681 se lower upper psi_transformed lower_transformed 1: 0.004305187 -0.01308669 0.00378933 -0.004648681 -0.01308669 upper_transformed 1: 0.00378933 # in most cases the transformation that&#39;s applied to tmle3 estimates and # inference (psi_transformed) is nothing -- it comes up for estimands like ORs, # which are estimated on the log scale estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] -0.004648681 5.4 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 5.4.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NPSEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(ist_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: RXHEP, REGION, RDELAY, RCONSC, SEX, AGE, RSLEEP, RVISINF, RCT, RATRIAL, RASP3, MISSING_RATRIAL_RASP3, RHEP24, MISSING_RHEP24, RSBP, RDEF1, RDEF2, RDEF3, RDEF4, RDEF5, RDEF6, RDEF7, RDEF8, STYPE Parents: $A tmle3_Node: A Variables: RXASP Parents: W $Y tmle3_Node: Y Variables: DRSISC Parents: A, W $delta_Y tmle3_Node: delta_Y Variables: delta_Y Parents: A, W 5.4.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood( tmle_task, learner_list ) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit delta_Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NPMLE, and the conditional distributions of \\(A\\), \\(\\Delta\\), and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y delta_Y 1: 2e-04 0.4931439 0.02317890 0.9994764 2: 2e-04 0.5323151 0.02825866 0.9994643 3: 2e-04 0.4768836 0.01363309 0.9994558 4: 2e-04 0.5162446 0.02756512 0.9994699 5: 2e-04 0.5157559 0.01639482 0.9977771 --- 4996: 2e-04 0.4952072 0.01365717 0.9994684 4997: 2e-04 0.4930078 0.02359050 0.9984894 4998: 2e-04 0.4928027 0.01439682 0.9985203 4999: 2e-04 0.4790796 0.03792173 0.9991405 5000: 2e-04 0.4948674 0.01738388 0.9980632 5.4.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE) ) 5.4.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] 5.4.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3( tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater ) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] -0.002037851 -0.004717238 se lower upper psi_transformed lower_transformed 1: 0.004293116 -0.01313159 0.003697115 -0.004717238 -0.01313159 upper_transformed 1: 0.003697115 The result is equivalent to fitting using the tmle3 function as above. 5.5 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=0, delta_Y=1}] [[2]] Param_TSM: E[Y_{A=1, delta_Y=1}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 5.5.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param( Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[2]]) ) print(ate_param) Param_delta: E[Y_{A=1, delta_Y=1}] - E[Y_{A=0, delta_Y=1}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks. 5.5.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3( tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater ) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=0, delta_Y=1}] 0.023110120 0.025906026 2: TSM E[Y_{A=1, delta_Y=1}] 0.021072269 0.021183901 3: ATE E[Y_{A=1, delta_Y=1}] - E[Y_{A=0, delta_Y=1}] -0.002037851 -0.004722125 se lower upper psi_transformed lower_transformed 1: 0.003178264 0.01967674 0.032135309 0.025906026 0.01967674 2: 0.002891541 0.01551659 0.026851216 0.021183901 0.01551659 3: 0.004293326 -0.01313689 0.003692638 -0.004722125 -0.01313689 upper_transformed 1: 0.032135309 2: 0.026851216 3: 0.003692638 5.6 Stratified Effect Estimates TMLE can also be applied to estimate effects in in strata of a baseline covariate. The tmle_stratified spec makes it easy to extend an existing spec with stratification. For instance, we can estimate strata specific ATEs as follows: \\(ATE = \\mathbb{E}_0(Y(1)-Y(0) \\mid V=v ) = \\mathbb{E}_0\\left(\\mathbb{E}_0[Y \\mid A=1,W]-\\mathbb{E}_0[Y \\mid A=0,W] \\mid V=v \\right)\\) For example, we can stratify the above ATE spec to estimate the ATE in strata of country region: stratified_ate_spec &lt;- tmle_stratified(ate_spec, &quot;REGION&quot;) stratified_fit &lt;- tmle3(stratified_ate_spec, ist_data, node_list, learner_list) Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; Error in xgboost::xgb.DMatrix(Xmat) : REAL() can only be applied to a &#39;numeric&#39;, not a &#39;logical&#39; print(stratified_fit) A tmle3_Fit that took 1 step(s) type 1: ATE 2: stratified ATE 3: stratified ATE 4: stratified ATE 5: stratified ATE 6: stratified ATE 7: stratified ATE 8: stratified ATE param 1: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] 2: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=Europe and Central Asia 3: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=East Asia and Pacific 4: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=Middle East &amp; North Africa 5: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=Latin America &amp; Caribbean 6: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=South Asia 7: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=North America 8: ATE[Y_{A=2, delta_Y=1}-Y_{A=1, delta_Y=1}] | V=Sub-Saharan Africa init_est tmle_est se lower upper 1: -0.0022015483 -0.0045954553 0.004317047 -0.013056711 0.003865801 2: -0.0022316436 -0.0042473161 0.004633570 -0.013328947 0.004834314 3: -0.0023371825 0.0050747161 0.020964533 -0.036015013 0.046164445 4: -0.0003294139 0.0001945933 0.001637558 -0.003014962 0.003404149 5: -0.0025104994 -0.0264986320 0.022817253 -0.071219625 0.018222361 6: -0.0002519670 0.0025249227 0.002173750 -0.001735549 0.006785395 7: -0.0030792781 -0.0083046085 0.048741790 -0.103836762 0.087227545 8: -0.0038918309 -0.0963311222 0.110582496 -0.313068832 0.120406588 psi_transformed lower_transformed upper_transformed 1: -0.0045954553 -0.013056711 0.003865801 2: -0.0042473161 -0.013328947 0.004834314 3: 0.0050747161 -0.036015013 0.046164445 4: 0.0001945933 -0.003014962 0.003404149 5: -0.0264986320 -0.071219625 0.018222361 6: 0.0025249227 -0.001735549 0.006785395 7: -0.0083046085 -0.103836762 0.087227545 8: -0.0963311222 -0.313068832 0.120406588 This TMLE is consistent for both the marginal ATE as well as the ATEs in strata of \\(V\\). For continuous \\(V\\), this could be extended using a working Marginal Structural Model (MSM), although that has not yet been implemented in tmle3. 5.7 Exercise Follow the steps below to estimate an ATE using a simplified version of data from the Collaborative Perinatal Project (CPP), available in the sl3 package. We define a binary intervention variable, parity01 – an indicator of having one or more children before the current child and a binary outcome, haz01 – an indicator of having an above average height for age. # load the data set data(cpp) cpp &lt;- cpp[!is.na(cpp[, &quot;haz&quot;]), ] cpp$parity01 &lt;- as.numeric(cpp$parity &gt; 0) cpp[is.na(cpp)] &lt;- 0 cpp$haz01 &lt;- as.numeric(cpp$haz &gt; 0) Define the variable roles \\((W,A,Y)\\) by creating a list of these nodes. Include the following baseline covariates in \\(W\\): apgar1, apgar5, gagebrth, mage, meducyrs, sexn. Both \\(A\\) and \\(Y\\) are specified above. Define a tmle3_Spec object for the ATE, tmle_ATE(). Using the same base learning libraries defined above, specify sl3 base learners for estimation of \\(Q = E(Y|A,Y)\\) and \\(g=P(A|W)\\). Define the metalearner like below metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_binomial, learner_function = metalearner_logistic_binomial ) Define one super learner for estimating \\(Q\\) and another for estimating \\(g\\). Use the metalearner above for both \\(Q\\) and \\(g\\) super learners. Create a list of the two super learners defined in Step 5 and call this object learner_list. The list names should be A (defining the super learner for estimating \\(g\\)) and Y (defining the super learner for estimating \\(Q\\)). Fit the tmle with the tmle3 function by specifying (1) the tmle3_Spec, which we defined in Step 2; (2) the data; (3) the list of nodes, which we specified in Step 1; and (4) the list of super learners for estimating \\(g\\) and \\(Q\\), which we defined in Step 6. Note: Like before, you will need to make a data copy to deal with data.table weirdness (cpp2 &lt;- data.table::copy(cpp)) and use cpp2 as the data. Interpret the tmle3 fit both causally and statistically. 5.8 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use tmle3 is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. Digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate more modern parameters such as the effect under optimal treatments and shift interventions. References "],
["one-step-tmle-for-time-to-event-outcomes.html", "Chapter 6 One-Step TMLE for Time-to-Event Outcomes 6.1 Learning Objectives 6.2 Introduction 6.3 Using MOSS for One-Step TMLE for Time-to-Event Outcomes 6.4 Learning Objectives 6.5 Introduction to Optimal Individualized Interventions 6.6 Optimal ITR with a Binary Treatment 6.7 Optimal ITR with a Categorical Treatment 6.8 Extensions to Causal Effect of an OIT 6.9 Exercise 6.10 Summary", " Chapter 6 One-Step TMLE for Time-to-Event Outcomes Based on the MOSS R package by Wilson Cai and Mark van der Laan. Updated: 2019-12-06 6.1 Learning Objectives Format right-censored survival data for MOSS. Fit a SuperLearner initial estimate of the conditional survival function of failure, conditional survival function of censoring and the propensity scores (initial_sl_fit). Calculate the TMLE adjustment of the conditional survival fit (MOSS_hazard). Formulate a simultaneous confidence band for the estimated conditional survival across a range of time-points (compute_simultaneous_ci). 6.2 Introduction In this section, we explore the MOSS R package. This software performs ensemble machine learning with the SuperLearner R package and One-Step Targeted Maximum Likelihood Estimation (TMLE) to estimate counterfactual marginal survival functions and the Average Treatment Effect (ATE) on survival probabilities, while non-parametrically adjusting for measured confounding. This one-step TMLE can be executed via recursion in small local updates, and creates a doubly robust and semi-parametrically efficient estimator. Simultaneous confidence bands of the entire curve are also available for inference. 6.2.1 Existing Methods for Observational Survival Analysis To facilitate comparison with other estimation procedures, the following additional estimators are also included in the MOSS R package: Inverse Censoring Probability Weighted (IPCW) estimator, which re-weights the observed data by the inverse of the product of the propensity score and censoring probability before applying a standard estimation method (Rotnitzky and Robins 2014). Estimating Equation (EE) estimator, which improves IPCW by adding the sample mean of the efficient influence curve and is a locally efficient and double robust (Hubbard, Van Der Laan, and Robins 2000). TMLE works well to improve the statistical efficiency of EE Like EE, TMLE is also doubly robust and locally efficient. In contrast to these two methods, TMLE performs an adjustment on the estimate of the relevant part of the data-generating distribution before applying the parameter mapping and thus always respects the parameter space (probabilities falling inside [0,1]), a so-called substitution/plug-in estimator. As a result, is more robust to outliers and sparsity than non-substitution estimators. Motivating one-step TMLE: monotonic survival curve EE and TMLE utilize efficiency theory derived for univariate parameters, making estimation of the survival curve a collection of univariate survival probability estimators. This procedure can lead to a survival curve that is not monotonically decreasing. The one-step TMLE implemented in MOSS targets the survival curve as a whole and thus ensures monotonicity, while preserving the desirable performance of the point-wise TMLE (Cai and Laan 2019). 6.3 Using MOSS for One-Step TMLE for Time-to-Event Outcomes MOSS implementation consists of the following steps: Load the necessary libraries and data. Specify the right-censored survival data arguments. Estimate the (1) conditional survival function of failure event, (2) conditional survival function of censoring event, and (3) propensity score with the SuperLearner R package. Perform TMLE adjustment of the initial conditional survival fit. Compute standard error estimates for simultaneous inference. 0. Load necessary libraries and data library(MOSS) vet_data &lt;- read.csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/veteran.csv&quot;) head(vet_data) X trt celltype time status karno diagtime age prior 1 1 1 squamous 72 1 60 7 69 0 2 2 1 squamous 411 1 70 5 64 10 3 3 1 squamous 228 1 60 3 38 0 4 4 1 squamous 126 1 60 9 63 10 5 5 1 squamous 118 1 70 11 65 10 6 6 1 squamous 10 1 20 5 49 0 The variables in vet_data are * trt: treatment type (1 = standard, 2 = test), * celltype: histological type of the tumor, * time: time to death or censoring in days, * status: censoring status, * karno: Karnofsky performance score that describes overall patient status at the beginning of the study (100 = good), * diagtime: months from diagnosis to randomization, * age: age of patient in years, and * prior: prior therapy (0 = no, 10 = yes). 1. Specify right-censored survival data arguments The following variables need to be specified from the data so they can subsequently be used as required arguments for MOSS functions: W: dataframe of baseline covariates \\(W\\). A: binary treatment vector \\(A\\). T_tilde: time-to-event vector \\(\\tilde{T} = \\min(T, C)\\). Delta: censoring indicator vector \\(\\Delta = I(T \\leq C)\\). t_max: the maximum time to estimate the survival probabilities. We can specify these variables with our observed vet_data. T_tilde &lt;- vet_data$time Delta &lt;- vet_data$status A &lt;- vet_data$trt W &lt;- vet_data[, c(3, 6:9)] t_max &lt;- max(T_tilde) 2. Obtain initial estimates with SuperLearner R package We will use the initial_sl_fit() function to specify the data (as we defined it above) and the SuperLearner library for initial estimation of each of the following components of the likelihood: conditional survival function of failure event given treatment and confounders, conditional survival function for censoring event given treatment and confounders, and propensity score of treatment given confounders. We are forgetting one component of the likelihood that requires estimation: the joint distribution of confounders! In MOSS this estimation is done for us under the hood, and we do not use the SuperLearner. Do you recall why we do not use the SuperLearner to estimate the joint distribution of confounders nonparametrically? The conditional survival functions are estimated by first estimating the conditional hazard, and then transforming into the conditional survival function. For a thorough explanation of these procedure see Section 3 from (Cai and Laan 2019). Currently, MOSS requires the user to do this one-to-one tranformation from the conditional hazard to the conditional survival probabilities by calling the hazard_to_survival() method. We will address this later on. Back to initial_sl_fit() – we have the option to specify the following arguments in addition to the required data arguments. sl_failure: SuperLearner library for failure event hazard, default = c(“SL.glm”) sl_censoring: SuperLearner library for censoring event hazard, default = c(“SL.glm”) sl_treatment: SuperLearner library for propensity score, default = c(“SL.glm”) gtol: treshold for truncating propensity scores, default = 0.001) It is highly recommended that you specify a more complex library than the default. The SuperLearner library arguments take a vector of strings corresponding to learners available in the SuperLearner R package: https://github.com/ecpolley/SuperLearner/tree/master/R. We do not review the SuperLearner R package in these workshops, but a handy tutorial crafted a few years ago by our colleague Chris Kennedy is freely available: Guide to SuperLearner. # recall treatment was randomized SL.ranger.faster = function(...) { SL.ranger(..., num.trees = 50) } sl_lib_decent &lt;- c(&quot;SL.mean&quot;, &quot;SL.glm&quot;, &quot;SL.step.forward&quot;, &quot;SL.bayesglm&quot;, &quot;SL.ranger.faster&quot;, &quot;SL.gam&quot;) initial_fit &lt;- initial_sl_fit(T_tilde, Delta, A, W, t_max, sl_censoring = sl_lib_decent, sl_failure = sl_lib_decent) names(initial_fit) [1] &quot;density_failure_1&quot; &quot;density_failure_0&quot; &quot;density_censor_1&quot; [4] &quot;density_censor_0&quot; &quot;g1W&quot; The initial_fit object contains the fitted conditional densities for the failure events (density_failure_1 for test treatment group, density_failure_0 for standard treatment group), censoring events (density_censor_1 and density_censor_0 for test treatment and standard treatment groups, respectively), and propensity scores (a vector g1W). The density_failure_1 and density_failure_0 both need to go through the hazard_to_survival method which populates the survival attribute of the object. initial_fit$density_failure_1$hazard_to_survival() &lt;survival_curve&gt; Public: ci: function (A, T_tilde, Delta, density_failure, density_censor, clone: function (deep = FALSE) create_ggplot_df: function (W = NULL) display: function (type, W = NULL) hazard: 0.0105086868901744 0.00890512674560573 0.010332023348463 ... hazard_to_pdf: function () hazard_to_survival: function () initialize: function (t, hazard = NULL, survival = NULL, pdf = NULL) n: function () pdf: NULL pdf_to_hazard: function () pdf_to_survival: function () survival: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ... survival_to_hazard: function () survival_to_pdf: function () t: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... initial_fit$density_failure_0$hazard_to_survival() &lt;survival_curve&gt; Public: ci: function (A, T_tilde, Delta, density_failure, density_censor, clone: function (deep = FALSE) create_ggplot_df: function (W = NULL) display: function (type, W = NULL) hazard: 0.0105086868901744 0.00890512674560573 0.010332023348463 ... hazard_to_pdf: function () hazard_to_survival: function () initialize: function (t, hazard = NULL, survival = NULL, pdf = NULL) n: function () pdf: NULL pdf_to_hazard: function () pdf_to_survival: function () survival: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ... survival_to_hazard: function () survival_to_pdf: function () t: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... 3. Perform TMLE adjustment of the initial conditional survival estimate The one-step TMLE is carried out by many local least favorable submodels (LLFMs) (performed via logistic regressions) with small step sizes. The one-step TMLE updates in small steps locally along LLFM, ensuring that the direction of the update is optimal around the current probability density. This procedure permits updates to the conditional hazard for all points on the survival curve (or any high-dimensional parameter in general), so that the conditional hazard can be transformed into a monotone survival curve after the algorithm. At this point we are nearly ready to update the hazard using this constrained step size update. The only additional argument we need to define is k_grid: the vector of interested time points for estimation of the conditional survival probability. k_grid &lt;- 1:max(T_tilde) initial_fit$density_failure_1$t &lt;- k_grid initial_fit$density_failure_0$t &lt;- k_grid We perform the TMLE adjustment of the initial conditional survival estimate by first creating a MOSS_hazard or MOSS_hazard_ate object and then calling the iterate_onestep() method for this object. MOSS_hazard and MOSS_hazard_ate correspond to different estimators: MOSS_hazard: one-step TMLE of the treatment-specific survival curve, and MOSS_hazard_ate: one-step TMLE of ATE on survival probabilities One-step TMLE of the Treatment-Specific Survival # estimate survival curve for standard treatment group hazard_fit_standardA &lt;- MOSS_hazard$new( A, T_tilde, Delta, density_failure = initial_fit$density_failure_0, density_censor = initial_fit$density_censor_0, g1W = initial_fit$g1W, A_intervene = 1, k_grid ) psi_standardA &lt;- hazard_fit_standardA$iterate_onestep() # estimate survival curve for test treatment group hazard_fit_testA &lt;- MOSS_hazard$new( A, T_tilde, Delta, density_failure = initial_fit$density_failure_1, density_censor = initial_fit$density_censor_1, g1W = initial_fit$g1W, A_intervene = 2, k_grid ) psi_testA &lt;- hazard_fit_testA$iterate_onestep() One-step TMLE of ATE on Survival hazard_fit_ate &lt;- MOSS_hazard_ate$new( A, T_tilde, Delta, density_failure = initial_fit$density_failure_1, density_censor = initial_fit$density_censor_1, density_failure_0 = initial_fit$density_failure_0, density_censor_0 = initial_fit$density_censor_0, initial_fit$g1W ) psi_ate &lt;- hazard_fit_ate$iterate_onestep() summary(psi_ate) Min. 1st Qu. Median Mean 3rd Qu. Max. 0 0 0 0 0 0 4. Compute standard error estimates for simultaneous inference After creating a vector of survival curve estimates by defining a new survival_curve object, we will estimate the efficient influence curve using the TML-estimates generated in the previous step and then generate a simultaneous confidence band for the TML-estimates. A simultaneous confidence interval achieves the desired coverage across many points, unlike the traditional confidence interval which achieves the desired coverage for one point. Thus, the standard error for simultaneous inference is larger when demanding simultaneous coverage of the truth, and it directly follows that simultaneous confidence intervals are wider. Simultaneous inference is a multiple testing procedure which controls the family-wise error rate. A 95% simultaneous confidence band for the TML-estimates is constructed in the following manner: Retain the TML-estimates of the probability of surviving up to or past each time specified in k_grid that we generated in the previous step. Compute the influence curve matrix for all times specified in k_grid using these TMLEs, where each column is an a time in k_grid and each row corresponds to a subject. Calculate the correlation of the IC matrix. Randomly draw many values from a multivariate Normal(0,Sigma) distribution (e.g. z &lt;- rmvnorm(1e6, mean = rep(0, length(k_grid)), sigma = cor(IC_matrix)) ), where sigma corresponds to what was generated in step 3. Identify the row-wise maximum of the absolute value of each MVN value (e.g. z_abs &lt;- apply(z, 1, function(x) max(abs(x)))). Using these maximum absolute values, calculate the 95th quantile of z_abs, which is the standard error to use for simultaneous inference (e.g. z_95 &lt;- quantile(z_abs, .95)) Calculate the time-specific standard deviation of the influence functions (e.g. sd_IC_time1 &lt;- sd(IC_matrix[,1])*sqrt(n-1)/n) Calculate the time-specific simultaneous confidence intervals (e.g. lower_bound_time1 &lt;- est_time1 - z_95*sd_IC_time1) The simultaneous inference for the TML-estimates are constructed based on asymptotic linearity of the TMLE uniform in all points considered. Step 4 approximates the Guassian process, and step 5 calculates the supremum norm of this process. The 0.95 quantile of the supremum norm of the Guassian process calculated in step 6 (i.e. z_95) will converge as the sample size increases and as the values drawn from the MVN (i.e. 1e6 used in step 4) increase. See the manuscript accompanying the MOSS package for more details and references on constructing simultaneous inference (Cai and Laan 2019). # estimate and obtain inference for survival curve for standard treatment group survival_standardA &lt;- survival_curve$new(t = k_grid, survival = psi_standardA) survival_curve_standardA &lt;- as.vector(survival_standardA$survival) eic_standardA &lt;- eic$new( A = A, T_tilde = T_tilde, Delta = Delta, density_failure = hazard_fit_standardA$density_failure, density_censor = hazard_fit_standardA$density_censor, g1W = hazard_fit_standardA$g1W, psi = survival_curve_standardA, A_intervene = hazard_fit_standardA$A_intervene ) eic_matrix_standardA &lt;- eic_standardA$all_t(k_grid = k_grid) std_err_standardA &lt;- compute_simultaneous_ci(eic_matrix_standardA) upper_bound_standardA &lt;- survival_curve_standardA + (1.96*std_err_standardA) lower_bound_standardA &lt;- survival_curve_standardA - (1.96*std_err_standardA) plotdf_standardA &lt;- data.frame(time = k_grid, est = survival_curve_standardA, upper = upper_bound_standardA, lower = lower_bound_standardA, type = rep(&quot;standard&quot;, length(k_grid))) plot_standardA &lt;- ggplot(data = plotdf_standardA, aes(x = time, y = est)) + geom_line() + geom_ribbon(data = plotdf_standardA, aes(ymin = lower, ymax = upper), alpha = 0.5) + ggtitle(&quot;Treatment-Specific Survival Curves Among Standard Treatment Group in Veterans’ Administration Lung Cancer Trial&quot;) plot_standardA # estimate and obtain inference for survival curve for test treatment group survival_testA &lt;- survival_curve$new(t = k_grid, survival = psi_testA) survival_curve_testA &lt;- as.vector(survival_testA$survival) eic_testA &lt;- eic$new( A = A, T_tilde = T_tilde, Delta = Delta, density_failure = hazard_fit_testA$density_failure, density_censor = hazard_fit_testA$density_censor, g1W = hazard_fit_testA$g1W, psi = survival_curve_testA, A_intervene = hazard_fit_testA$A_intervene ) eic_matrix_testA &lt;- eic_testA$all_t(k_grid = k_grid) std_err_testA &lt;- compute_simultaneous_ci(eic_matrix_testA) upper_bound_testA &lt;- survival_curve_testA + (1.96*std_err_testA) lower_bound_testA &lt;- survival_curve_testA - (1.96*std_err_testA) plotdf_testA &lt;- data.frame(time = k_grid, est = survival_curve_testA, upper = upper_bound_testA, lower = lower_bound_testA, type = rep(&quot;test&quot;, length(k_grid))) plot_testA &lt;- ggplot(data = plotdf_testA, aes(x = time, y = est)) + geom_line() + geom_ribbon(data = plotdf_testA, aes(ymin = lower, ymax = upper), alpha = 0.5) + ggtitle(&quot;Treatment-Specific Survival Curves Among Test Treatment Group in Veterans’ Administration Lung Cancer Trial&quot;) plot_testA counseling# Optimal Individualized Treatment Regimes Based on the tmle3mopttx R package by Ivana Malenica, Jeremy Coyle, and Mark van der Laan. Updated: 2019-12-06 6.4 Learning Objectives By the end of this lesson you will be able to: Differentiate dynamic and optimal dynamic treatment interventions from static interventions. Explain the benefits and challenges associated with using optimal individualized treatment regimes in practice. Contrast the impact of implementing an optimal individualized treatment regime in the population with the impact of implementing static and dynamic treatment regimes in the population. Estimate causal effects under optimal individualized treatment regimes with the tmle3mopttx R package. Implement optimal individualized treatment rules based on sub-optimal rules, or “simple” rules, and recognize the practical benefit of these rules. Construct “realistic” optimal individualized treatment regimes that respect real data and subject-matter knowledge limitations on interventions by only considering interventions that are supported by the data. Measure variable importance as defined in terms of optimal individualized treatment interventions. 6.5 Introduction to Optimal Individualized Interventions Identifying which intervention will be effective for which patient based on lifestyle, genetic and environmental factors is a common goal in precision medicine. One opts to administer the intervention to individuals who will profit from it, instead of assigning treatment on a population level. This aim motivates a different type of intervention, as opposed to the static exposures we might be used to. In this chapter, we learn about dynamic (individualized) interventions that tailor the treatment decision based on the collected covariates. In the statistics community, such a treatment strategy is termed individualized treatment regimes (ITR), and the (counterfactual) population mean outcome under an ITR is the value of the ITR. Even more, suppose one wishes to maximize the population mean of an outcome, where for each individual we have access to some set of measured covariates. An ITR with the maximal value is referred to as an optimal ITR or the optimal individualized treatment. Consequently, the value of an optimal ITR is termed the optimal value, or the mean under the optimal individualized treatment. One opts to administer the intervention to individuals who will profit from it, instead of assigning treatment on a population level. But how do we know which intervention works for which patient? For example, one might seek to improve retention in HIV care. In a randomized clinical trial, several interventions show efficacy- including appointment reminders through text messages, small cash incentives for on time clinic visits, and peer health workers. Ideally, we want to improve effectiveness by assigning each patient the intervention they are most likely to benefit from, as well as improve efficiency by not allocating resources to individuals that do not need them, or would. Figure 6.1: Illustration of a Dynamic Treatment Regime in a Clinical Setting This aim motivates a different type of intervention, as opposed to the static exposures we might be used to. In this chapter, we examine multiple examples of optimal individualized treatment regimes and estimate the mean outcome under the ITR where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. In order to accomplish this, we present the tmle3mopttx R package, which features an implementation of a recently developed algorithm for computing targeted minimum loss-based estimates of a causal effect based on optimal ITR for categorical treatment. In particular, we will use tmle3mopttx to estimate optimal ITR and the corresponding population value, construct realistic optimal ITRs, and perform variable importance in terms of the mean under the optimal individualized treatment. 6.5.1 Data Structure and Notation Suppose we observe \\(n\\) independent and identically distributed observations of the form \\(O=(W,A,Y) \\sim P_0\\). \\(P_0 \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the fully nonparametric model. Denote \\(A \\in \\mathcal{A}\\) as categorical treatment, where \\(\\mathcal{A} \\equiv \\{a_1, \\cdots, a_{n_A} \\}\\) and \\(n_A = |\\mathcal{A}|\\), with \\(n_A\\) denoting the number of categories. Denote \\(Y\\) as the final outcome, and \\(W\\) a vector-valued collection of baseline covariates. The likelihood of the data admits a factorization, implied by the time ordering of \\(O\\). \\[\\begin{equation*}\\label{eqn:likelihood_factorization} p_0(O) = p_{Y,0}(Y|A,W) p_{A,0}(A|W) p_{W,0}(W) = q_{Y,0}(Y|A,W) q_{A,0}(A|W) q_{W,0}(W), \\end{equation*}\\] Consequently, we define \\(P_{Y,0}(Y|A,W)=Q_{Y,0}(Y|A,W)\\), \\(P_{A,0}(A|W)=g_0(A|W)\\) and \\(P_{W,0}(W)=Q_{W,0}(W)\\) as the corresponding conditional distributions of \\(Y\\), \\(A\\) and \\(W\\). We also define \\(\\bar{Q}_{Y,0}(A,W) \\equiv E_0[Y|A,W]\\). Finally, denote \\(V\\) as \\(V \\in W\\), defining a subset of the baseline covariates the optimal individualized rule depends on. 6.5.2 Defining the Causal Effect of an Optimal Individualized Intervention Consider dynamic treatment rules \\(V \\rightarrow d(V) \\in \\{a_1, \\cdots, a_{n_A} \\} \\times \\{1\\}\\), for assigning treatment \\(A\\) based on \\(V \\in W\\). Dynamic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(V)\\), and \\(Y_{d(V)}\\) is the corresponding counterfactual outcome under \\(d(V)\\). The goal of any causal analysis motivated by an optimal individualized intervention is to estimate a parameter defined as the counterfactual mean of the outcome with respect to the modified intervention distribution. Recall causal assumptions: Consistency: \\(Y^{d(v_i)}_i = Y_i\\) in the event \\(A_i = d(v_i)\\), for \\(i = 1, \\ldots, n\\). Stable unit value treatment assumption (SUTVA): \\(Y^{d(v_i)}_i\\) does not depend on \\(d(v_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference. Strong ignorability: \\(A \\perp \\!\\!\\! \\perp Y^{d(v)} \\mid W\\), for all \\(a \\in \\mathcal{A}\\). Positivity (or overlap): \\(P_0(\\min_{a \\in \\mathcal{A}} g_0(a|W) &gt; 0)=1\\). Here, we also assume non-exceptional law is in effect. We are primarily interested in the value of an individualized rule, \\[E_0[Y_{d(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d(V),W)].\\] The optimal rule is the rule with the maximal value: \\[d_{opt}(V) \\equiv \\text{argmax}_{d(V) \\in \\mathcal{D}} E_0[Y_{d(V)}]\\] where \\(\\mathcal{D}\\) represents the set of possible rules, \\(d\\), implied by \\(V\\). The target causal estimand of our analysis is: \\[\\psi_0 := E_0[Y_{d_{opt}(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d_{opt}(V),W)].\\] General, high-level idea: Learn the optimal ITR using the Super Learner. Estimate its value with the cross-validated Targeted Minimum Loss-based Estimator (CV-TMLE). 6.5.3 Why CV-TMLE? CV-TMLE is necessary as the non-cross-validated TMLE is biased upward for the mean outcome under the rule, and therefore overly optimistic. More generally however, using CV-TMLE allows us more freedom in estimation and therefore greater data adaptivity, without sacrificing inference! 6.6 Optimal ITR with a Binary Treatment How do we estimate the optimal individualized treatment regime? In the case of a binary treatment, a key quantity for optimal ITR is the blip function. Optimal ITR ideally assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. We define the blip function as: \\[\\bar{Q}_0(V)\\equiv E_0[Y_1-Y_0|V]\\equiv E_0[\\bar{Q}_{Y,0}(1,W) - \\bar{Q}_{Y,0}(0,W)|V],\\] or the average treatment effect within a stratum of \\(V\\). Optimal individualized rule can now be derived as \\(d_{opt}(V) = I(\\bar{Q}_{0}(V) &gt; 0)\\). Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner estimate of the blip function, we follow the below steps in order to obtain value of the ITR: Estimate \\(\\bar{Q}_{Y,0}(A,W)\\) and \\(g_0(A|W)\\) using sl3. We denote such estimates as \\(\\bar{Q}_{Y,n}(A,W)\\) and \\(g_n(A|W)\\). Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW) transform to our outcome, where we define: \\[D_{\\bar{Q}_Y,g,a}(O) \\equiv \\frac{I(A=a)}{g(A|W)} (Y-\\bar{Q}_Y(A,W)) + \\bar{Q}_Y(A=a,W)\\] Note that under the randomization and positivity assumptions we have that \\(E[D_{\\bar{Q}_Y,g,a}(O) | V] = E[Y_a |V].\\) We emphasize the double robust nature of the A-IPW transform: consistency of \\(E[Y_a |V]\\) will depend on correct estimation of either \\(\\bar{Q}_{Y,0}(A,W)\\) or \\(g_0(A|W)\\). As such, in a randomized trial, we are guaranteed a consistent estimate of \\(E[Y_a |V]\\) even if we get \\(\\bar{Q}_{Y,0}(A,W)\\) wrong! Using this transform, we can define the following contrast: \\[D_{\\bar{Q}_Y,g}(O) = D_{\\bar{Q}_Y,g,a=1}(O) - D_{\\bar{Q}_Y,g,a=0}(O)\\] We estimate the blip function, \\(\\bar{Q}_{0,a}(V)\\), by regressing \\(D_{\\bar{Q}_Y,g}(O)\\) on \\(V\\) using the specified sl3 library of learners and an appropriate loss function. Our estimated rule is \\(d(V) = \\text{argmax}_{a \\in \\mathcal{A}} \\bar{Q}_{0,a}(V)\\). We obtain inference for the mean outcome under the estimated optimal rule using CV-TMLE. 6.6.1 Evaluating the Causal Effect of an Optimal ITR with a Binary Treatment To start, let us load the packages we will use and set a seed for simulation: library(here) library(data.table) library(sl3) library(tmle3) library(tmle3mopttx) library(devtools) set.seed(111) 6.6.1.1 Data Simulation Our data generating distribution is of the following form: \\[W \\sim \\mathcal{N}(\\bf{0},I_{3 \\times 3})\\] \\[P(A=1|W) = \\frac{1}{1+\\exp^{(-0.8*W_1)}}\\] \\[P(Y=1|A,W) = 0.5\\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] + 0.5\\text{logit}^{-1}(W_2W_3)\\] data(&quot;data_bin&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.578\\) for this data-generating distribution. Next, we specify the role that each variable in the data set plays as the nodes in a DAG. # organize data and nodes for tmle3 data &lt;- data_bin node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) We now have an observed data structure (data), and a specification of the role that each variable in the data set plays as the nodes in a DAG. 6.6.1.2 Constructing Optimal Stacked Regressions with sl3 We generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. # Define sl3 library and metalearners: lrn_xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) lrn_xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) lrn_xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn_mean &lt;- Lrnr_mean$new() lrn_glm &lt;- Lrnr_glm_fast$new() ## Define the Q learner: Q_learner &lt;- Lrnr_sl$new( learners = list( lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm ), metalearner = Lrnr_nnls$new() ) ## Define the g learner: g_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_100, lrn_glm), metalearner = Lrnr_nnls$new() ) ## Define the B learner: b_learner &lt;- Lrnr_sl$new( learners = list( lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm ), metalearner = Lrnr_nnls$new() ) We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 6.6.1.3 Targeted Estimation of the Mean under the Optimal ITR Effect To start, we will initialize a specification for the TMLE of our parameter of interest simply by calling tmle3_mopttx_blip_revere. We specify the argument V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;) when initializing the tmle3_Spec object in order to communicate that we’re interested in learning a rule dependent on V covariates. We also need to specify the type of blip we will use in this estimation problem, and the list of learners used to estimate relevant parts of the likelihood and the blip function. In addition, we need to specify whether we want to maximize or minimize the mean outcome under the rule (maximize=TRUE). If complex=FALSE, tmle3mopttx will consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the suboptimal rules dependent on \\(V\\). If realistic=TRUE, only treatments supported by the data will be considered, therefore alleviating concerns regarding practical positivity issues. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.4289592 0.5701264 0.02749039 0.5162462 0.6240065 psi_transformed lower_transformed upper_transformed 1: 0.5701264 0.5162462 0.6240065 We can see that the confidence interval covers our true mean under the true optimal individualized treatment! 6.7 Optimal ITR with a Categorical Treatment QUESTION: Can we still use the blip function if the treatment is categorical? In this section, we consider how to evaluate the mean outcome under the optimal individualized treatment when \\(A\\) has more than two categories! We define pseudo-blips as vector valued entities where the output for a given \\(V\\) is a vector of length equal to the number of treatment categories, \\(n_A\\). As such, we define it as: \\[\\bar{Q}_0^{pblip}(V) = \\{\\bar{Q}_{0,a}^{pblip}(V): a \\in \\mathcal{A} \\}\\] We implement three different pseudo-blips in tmle3mopttx. Blip1 corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference: \\[\\bar{Q}_{0,a}^{pblip-ref}(V) \\equiv E_0(Y_a-Y_0|V)\\] Blip2 approach corresponds to defining the blip relative to the average of all categories: \\[\\bar{Q}_{0,a}^{pblip-avg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_a|V)\\] Blip3 reflects an extension of Blip2, where the average is now a weighted average: \\[\\bar{Q}_{0,a}^{pblip-wavg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_{a} P(A=a|V) |V)\\] 6.7.1 Evaluating the Causal Effect of an Optimal ITR with a Categorical Treatment While the procedure is analogous to the previously described binary treatment, we now need to pay attention to the type of blip we define in the estimation stage, as well as how we construct our learners. 6.7.1.1 Data Simulation First, we load the simulated data. Here, our data generating distribution was of the following form: \\[W \\sim \\mathcal{N}(\\bf{0},I_{4 \\times 4})\\] \\[P(A|W) = \\frac{1}{1+\\exp^{(-(0.05*I(A=1) * W_1+0.8*I(A=2) * W_1+0.8*I(A=3) * W_1))}}\\] \\[P(Y|A,W) = 0.5\\text{logit}^{-1}[15I(A=1)(W_1-0.5) - 3I(A=2)(2W_1+0.5) \\\\ + 3I(A=3)(3W_1-0.5)] +\\text{logit}^{-1}(W_2W_1)\\] We can just load the data available as part of the package as follows: data(&quot;data_cat_realistic&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.658\\), which is the quantity we aim to estimate. # organize data and nodes for tmle3 data &lt;- data_cat_realistic node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) 6.7.1.2 Constructing Optimal Stacked Regressions with sl3 QUESTION: With categorical treatment, what is the dimension of the blip now? How would we go about estimating it? # Initialize few of the learners: lrn_xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) lrn_xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) lrn_xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn_mean &lt;- Lrnr_mean$new() lrn_glm &lt;- Lrnr_glm_fast$new() ## Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: # specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial ) g_learner &lt;- make_learner(Lrnr_sl, list(lrn_xgboost_100, lrn_xgboost_500, lrn_mean), mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm) b_learner &lt;- create_mv_learners(learners = learners) We generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate \\(g_0(A|W)\\) for a categorical \\(A\\)- therefore we use the multinomial Super Learner option available within the sl3 package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate \\(g_0(A|W)\\) in sl3, we run the following: # See which learners support multi-class classification: sl3_list_learners(c(&quot;categorical&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_caret&quot; [3] &quot;Lrnr_dbarts&quot; &quot;Lrnr_gam&quot; [5] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [7] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [9] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot; [11] &quot;Lrnr_multivariate&quot; &quot;Lrnr_optim&quot; [13] &quot;Lrnr_polspline&quot; &quot;Lrnr_pooled_hazards&quot; [15] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [17] &quot;Lrnr_rpart&quot; &quot;Lrnr_screener_corP&quot; [19] &quot;Lrnr_screener_corRank&quot; &quot;Lrnr_screener_randomForest&quot; [21] &quot;Lrnr_solnp&quot; &quot;Lrnr_svm&quot; [23] &quot;Lrnr_xgboost&quot; # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 6.7.1.3 Targeted Estimation of the Mean under the Optimal ITR Effects # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.5388064 0.6087992 0.07433631 0.4631027 0.7544957 psi_transformed lower_transformed upper_transformed 1: 0.6087992 0.4631027 0.7544957 # How many individuals got assigned each treatment? table(tmle_spec$return_rule) 1 2 3 440 388 172 We can see that the confidence interval covers our true mean under the true optimal individualized treatment. NOTICE the distribution of the assigned treatment! We will need this shortly. 6.8 Extensions to Causal Effect of an OIT We consider two extensions to the procedure described for estimating the value of the ITR. The first one considers a setting where the user might be interested in a grid of possible suboptimal rules, corresponding to potentially limited knowledge of potential effect modifiers (Simpler Rules). The second extension concerns implementation of realistic optimal individual interventions where certain regimes might be preferred, but due to practical or global positivity restraints are not realistic to implement (Realistic Interventions). 6.8.1 Simpler Rules In order to not only consider the most ambitious fully \\(V\\)-optimal rule, we define \\(S\\)-optimal rules as the optimal rule that considers all possible subsets of \\(V\\) covariates, with card(\\(S\\)) \\(\\leq\\) card(\\(V\\)) and \\(\\emptyset \\in S\\). This allows us to consider sub-optimal rules that are easier to estimate and potentially provide more realistic rules- as such, we allow for statistical inference for the counterfactual mean outcome under the sub-optimal rule. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W4&quot;, &quot;W3&quot;, &quot;W2&quot;, &quot;W1&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = FALSE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=W3,W2,W1}] 0.5443612 0.5718773 0.06647258 0.4415935 0.7021612 psi_transformed lower_transformed upper_transformed 1: 0.5718773 0.4415935 0.7021612 Even though the user specified all baseline covariates as the basis for rule estimation, a simpler rule is sufficient to maximize the mean under the optimal individualized treatment! QUESTION: Why do you think the estimate is higher under the less complex rule? How does the set of covariates picked by tmle3mopttx compare to the baseline covariates the true rule depends on? 6.8.2 Realistic Optimal Individual Regimes tmle3mopttx also provides an option to estimate the mean under the realistic, or implementable, optimal individualized treatment. It is often the case that assigning particular regime might have the ability to fully maximize (or minimize) the desired outcome, but due to global or practical positivity constrains, such treatment can never be implemented in real life (or is highly unlikely). Specifying realistic=&quot;TRUE&quot;, we consider possibly suboptimal treatments that optimize the outcome in question while being supported by the data. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W4&quot;, &quot;W3&quot;, &quot;W2&quot;, &quot;W1&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = TRUE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.552654 0.6503015 0.02177991 0.6076136 0.6929893 psi_transformed lower_transformed upper_transformed 1: 0.6503015 0.6076136 0.6929893 # How many individuals got assigned each treatment? table(tmle_spec$return_rule) 2 3 507 493 QUESTION: Referring back to the data-generating distribution, why do you think the distribution of allocated treatment changed from the distribution that we had under the “non-realistic” rule? 6.8.3 Variable Importance Analysis In the previous sections we have seen how to obtain a contrast between the mean under the optimal individualized rule and the mean under the observed outcome for a single covariate. We are now ready to run the variable importance analysis for all of our observed covariates! In order to run tmle3mopttx variable importance measure, we need considered covariates to be categorical variables. For illustration purpose, we bin baseline covariates corresponding to the data-generating distribution described in the previous section: # bin baseline covariates to 3 categories: data$W1 &lt;- ifelse(data$W1 &lt; quantile(data$W1)[2], 1, ifelse(data$W1 &lt; quantile(data$W1)[3], 2, 3)) node_list &lt;- list( W = c(&quot;W3&quot;, &quot;W4&quot;, &quot;W2&quot;), A = c(&quot;W1&quot;, &quot;A&quot;), Y = &quot;Y&quot; ) Note that our node list now includes \\(W_1\\) as treatments as well! Don’t worry, we will still properly adjust for all baseline covariates when considering \\(A\\) as treatment. 6.8.3.1 Variable Importance using Targeted Estimation of the value of the ITR We will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle3_mopttx_vim. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_vim( V = c(&quot;W2&quot;), type = &quot;blip2&quot;, learners = learner_list, contrast = &quot;multiplicative&quot;, maximize = FALSE, method = &quot;SL&quot;, complex = TRUE, realistic = FALSE ) # fit the TML estimator vim_results &lt;- tmle3_vim(tmle_spec, data, node_list, learner_list, adjust_for_other_A = TRUE ) print(vim_results) type param init_est tmle_est se lower 1: RR RR(E[Y_{A=NULL}]/E[Y]) 0.003574293 0.09596303 0.03282267 0.03163178 2: RR RR(E[Y_{A=NULL}]/E[Y]) -0.024474352 -0.10266330 0.05128432 -0.20317872 upper psi_transformed lower_transformed upper_transformed A 1: 0.160294275 1.1007184 1.0321374 1.1738563 A 2: -0.002147868 0.9024308 0.8161324 0.9978544 W1 W Z_stat p_nz p_nz_corrected 1: W3,W4,W2,W1 2.923682 0.001729592 0.003459185 2: W3,W4,W2,A -2.001846 0.022650673 0.022650673 The final result of tmle3_vim with the tmle3mopttx spec is an ordered list of mean outcomes under the optimal individualized treatment for all categorical covariates in our dataset. 6.9 Exercise 6.9.1 Causal Effect of the Optimal ITR in the WASH Benefits Trial Finally, we cement everything we learned so far with a real data application. We will be using the WASH Benefits data, corresponding to the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in a rural Bangladesh trial. The main aim of the cluster-randomized controlled trial was to assess the impact of six intervention groups, including: Control Hand washing with soap Improved nutrition through counseling and provision of lipid-based nutrient supplements Combined water, sanitation, hand washing, and nutrition. Improved sanitation Combined water, sanitation, and hand washing Chlorinated drinking water Estimate the optimal ITR and the corresponding value under the optimal ITR for the main intervention in WASH Benefits data. The outcome of interest is the weight-for-height Z-score (whz), and the treatment is the six intervention groups aimed at improving living conditions. Define \\(V\\) as mother’s education (momedu), current living conditions (floor), and possession of material items including the refrigerator (asset_refrig). Why do you think these covariates are used as \\(V\\)? Should the outcome be minimized or maximized? Which blip type should be utilized? Construct an appropriate sl3 library for \\(A\\), \\(Y\\) and \\(B\\). Based on the \\(V\\) defined in the previous question, estimate the mean under the ITR for the main randomized intervention (tr) used in the WASH Benefits trial with weight-for-height Z-score as the outcome (whz). What is the estimated value of the optimal ITR? How does it change from the initial estimate? Which intervention is the most dominant and why? Using the same formulation in questions 1 and 2, estimate the realistic optimal ITR and the corresponding value of the realistic ITR. Did the results change? Which intervention is the most dominant under realistic rules? Why do you think that is? 6.10 Summary The mean outcome under the optimal individualized treatment is a counterfactual quantity of interest representing what the mean outcome would have been if everybody, contrary to the fact, received treatment that optimized their outcome. tmle3mopttx estimates the mean outcome under the optimal individualized treatment, where the candidate rules are restricted to only respond to a user-supplied subset of the baseline and intermediate covariates. Additionally, it provides options for realistic data-adaptive interventions. In essence, our target parameter answers the key aim of precision medicine: allocating the available treatment by tailoring it to the individual characteristics of the patient, with the goal of optimizing the final outcome. 6.10.1 Exercise Solutions To start, let’s load the data, convert all columns to be of class numeric, and take a quick look at it: washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) washb_data &lt;- washb_data[!is.na(momage), lapply(.SD, as.numeric)] head(washb_data, 3) As before, we specify the NPSEM via the node_list object. node_list &lt;- list( W = names(washb_data)[!(names(washb_data) %in% c(&quot;whz&quot;, &quot;tr&quot;))], A = &quot;tr&quot;, Y = &quot;whz&quot; ) We pick few potential effect modifiers, including mother’s education, current living conditions, and possession of material items including the refrigerator. We concentrate of these covariates as they might be indicative of the socio-economic status of individuals involved in the trial. We can explore the distribution of our \\(V\\), \\(A\\) and \\(Y\\): # V1, V2 and V3: table(washb_data$momedu) table(washb_data$floor) table(washb_data$asset_refrig) # A: table(washb_data$tr) # Y: summary(washb_data$whz) We specify a simply library for the outcome regression, propensity score and the blip function. Since our treatment is categorical, we need to define a multinomial learner for \\(A\\) and multivariate learner for \\(B\\). We will define the xgboost over a grid of parameters, and initialize a mean learner. # Initialize few of the learners: grid_params &lt;- list( nrounds = c(100, 500), eta = c(0.01, 0.1) ) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) xgb_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_xgboost$new, c(as.list(params_tune))) }) lrn_mean &lt;- Lrnr_mean$new() ## Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list( xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]], xgb_learners[[4]], lrn_mean ), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: # specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial ) g_learner &lt;- make_learner(Lrnr_sl, list(xgb_learners[[4]], lrn_mean), mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list( xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]], xgb_learners[[4]], lrn_mean ) b_learner &lt;- create_mv_learners(learners = learners) learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) As seen before, we initialize the tmle3_mopttx_blip_revere Spec for question 1. We want to maximize the outcome, the higher the weight-for-height Z-score the better for children subject to wasting and stunting. We will also use blip2 as the blip type, but note that we could have used blip1 as well since “Control” is a good reference category. ## Question 2: # Initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;momedu&quot;, &quot;floor&quot;, &quot;asset_refrig&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) # Fit the TML estimator. fit &lt;- tmle3(tmle_spec, data = washb_data, node_list, learner_list) fit # Which intervention is the most dominant? table(tmle_spec$return_rule) Using the same formulation as before, we estimate the realistic optimal ITR and the corresponding value of the realistic ITR: ## Question 3: # Initialize a tmle specification with &quot;realistic=TRUE&quot;: tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;momedu&quot;, &quot;floor&quot;, &quot;asset_refrig&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = TRUE ) # Fit the TML estimator. fit &lt;- tmle3(tmle_spec, data = washb_data, node_list, learner_list) fit table(tmle_spec$return_rule) References "],
["r6.html", "Chapter 7 A Primer on the R6 Class System 7.1 Classes, Fields, and Methods 7.2 Object Oriented Programming: Python and R", " Chapter 7 A Primer on the R6 Class System A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models. The tlverse is designed using basic OOP principles and the R6 OOP framework. While we’ve tried to make it easy to use the tlverse packages without worrying much about OOP, it is helpful to have some intuition about how the tlverse is structured. Here, we briefly outline some key concepts from OOP. Readers familiar with OOP basics are invited to skip this section. 7.1 Classes, Fields, and Methods The key concept of OOP is that of an object, a collection of data and functions that corresponds to some conceptual unit. Objects have two main types of elements: fields, which can be thought of as nouns, are information about an object, and methods, which can be thought of as verbs, are actions an object can perform. Objects are members of classes, which define what those specific fields and methods are. Classes can inherit elements from other classes (sometimes called base classes) – accordingly, classes that are similar, but not exactly the same, can share some parts of their definitions. Many different implementations of OOP exist, with variations in how these concepts are implemented and used. R has several different implementations, including S3, S4, reference classes, and R6. The tlverse uses the R6 implementation. In R6, methods and fields of a class object are accessed using the $ operator. For a more thorough introduction to R’s various OOP systems, see http://adv-r.had.co.nz/OO-essentials.html, from Hadley Wickham’s Advanced R (Wickham 2014). 7.2 Object Oriented Programming: Python and R OO concepts (classes with inherentence) were baked into Python from the first published version (version 0.9 in 1991). In contrast, R gets its OO “approach” from its predecessor, S, first released in 1976. For the first 15 years, S had no support for classes, then, suddenly, S got two OO frameworks bolted on in rapid succession: informal classes with S3 in 1991, and formal classes with S4 in 1998. This process continues, with new OO frameworks being periodically released, to try to improve the lackluster OO support in R, with reference classes (R5, 2010) and R6 (2014). Of these, R6 behaves most like Python classes (and also most like OOP focused languages like C++ and Java), including having method definitions be part of class definitions, and allowing objects to be modified by reference. References "],
["references.html", "References", " References "]
]
