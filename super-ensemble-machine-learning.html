<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Super (Ensemble Machine) Learning | Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the tlverse Software Ecosystem</title>
  <meta name="description" content="An open-source and fully-reproducible electronic set of software materials accompanying an invited half-day tutorial and 2-day short-course at the Deming Conference on Applied Statistics." />
  <meta name="generator" content="bookdown 0.16.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Super (Ensemble Machine) Learning | Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the tlverse Software Ecosystem" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/deming2019-workshop/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic set of software materials accompanying an invited half-day tutorial and 2-day short-course at the Deming Conference on Applied Statistics." />
  <meta name="github-repo" content="tlverse/deming2019-workshop" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Super (Ensemble Machine) Learning | Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the tlverse Software Ecosystem" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic set of software materials accompanying an invited half-day tutorial and 2-day short-course at the Deming Conference on Applied Statistics." />
  

<meta name="author" content="Rachael Phillips, Nima Hejazi, Jeremy Coyle, Ivana Malenica, Alan Hubbard, Mark van der Laan" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="data.html"/>
<link rel="next" href="one-step-tmle-for-time-to-event-outcomes.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.8/visNetwork.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Deming Conference 2019 Targeted Learning Workshop</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#important-links"><i class="fa fa-check"></i>Important links</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i>Abstract</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#half-day-tutorial-9a-12p-on-december-4-2019"><i class="fa fa-check"></i>Half-Day Tutorial – 9A-12P on December 4, 2019</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#day-short-course-8a-5p-on-december-5-6-2019"><i class="fa fa-check"></i>2-Day Short Course – 8A-5P on December 5-6, 2019</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contents"><i class="fa fa-check"></i>Contents</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-instructors-and-authors"><i class="fa fa-check"></i>About the instructors and authors</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mark-van-der-laan"><i class="fa fa-check"></i>Mark van der Laan</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rachael-phillips"><i class="fa fa-check"></i>Rachael Phillips</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jeremy-coyle"><i class="fa fa-check"></i>Jeremy Coyle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alan-hubbard"><i class="fa fa-check"></i>Alan Hubbard</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nima-hejazi"><i class="fa fa-check"></i>Nima Hejazi</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i>Ivana Malenica</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="1" data-path="tlverse.html"><a href="tlverse.html"><i class="fa fa-check"></i><b>1</b> Welcome to the <code>tlverse</code></a><ul>
<li class="chapter" data-level="1.1" data-path="tlverse.html"><a href="tlverse.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="tlverse.html"><a href="tlverse.html#what-is-the-tlverse"><i class="fa fa-check"></i><b>1.2</b> What is the <code>tlverse</code>?</a></li>
<li class="chapter" data-level="1.3" data-path="tlverse.html"><a href="tlverse.html#tlverse-components"><i class="fa fa-check"></i><b>1.3</b> <code>tlverse</code> components</a></li>
<li class="chapter" data-level="1.4" data-path="tlverse.html"><a href="tlverse.html#installtlverse"><i class="fa fa-check"></i><b>1.4</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> The Roadmap of Statistical Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#the-observed-data-and-statistical-model"><i class="fa fa-check"></i><b>2.1</b> The Observed Data and Statistical Model</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#the-causal-model"><i class="fa fa-check"></i><b>2.2</b> The Causal Model</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#the-parameter-of-interest"><i class="fa fa-check"></i><b>2.3</b> The Parameter of Interest</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#identifiability"><i class="fa fa-check"></i><b>2.4</b> Identifiability</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#estimation-targeted-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>2.5</b> Estimation: Targeted Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#inference"><i class="fa fa-check"></i><b>2.6</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="data.html"><a href="data.html#ist"><i class="fa fa-check"></i><b>3.1</b> International Stroke Trial Example Dataset</a></li>
<li class="chapter" data-level="3.2" data-path="data.html"><a href="data.html#wash"><i class="fa fa-check"></i><b>3.2</b> WASH Benefits Example Dataset</a></li>
<li class="chapter" data-level="3.3" data-path="data.html"><a href="data.html#vet"><i class="fa fa-check"></i><b>3.3</b> Veterans’ Administration Lung Cancer Trial Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html"><i class="fa fa-check"></i><b>4</b> Super (Ensemble Machine) Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#super-learning"><i class="fa fa-check"></i><b>4.1.1</b> Super Learning</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#review-of-the-super-learner"><i class="fa fa-check"></i>Review of the Super Learner</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#sl3-microwave-dinner-implementation"><i class="fa fa-check"></i><b>4.2</b> <code>sl3</code> “Microwave Dinner” Implementation</a><ul>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#wash-benefits-study-example"><i class="fa fa-check"></i>WASH Benefits Study Example</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#load-the-necessary-libraries-and-data"><i class="fa fa-check"></i>0. Load the necessary libraries and data</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#define-the-machine-learning-task"><i class="fa fa-check"></i>1. Define the machine learning task</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#make-a-super-learner"><i class="fa fa-check"></i>2. Make a super learner</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#train-the-super-learner-on-the-machine-learning-task"><i class="fa fa-check"></i>3. Train the super learner on the machine learning task</a></li>
<li class="chapter" data-level="" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#obtain-predicted-values"><i class="fa fa-check"></i>4. Obtain predicted values</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#extensions"><i class="fa fa-check"></i><b>4.3</b> Extensions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#cross-validated-super-learner"><i class="fa fa-check"></i><b>4.3.1</b> Cross-validated Super Learner</a></li>
<li class="chapter" data-level="4.3.2" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#variable-importance-measures-with-sl3"><i class="fa fa-check"></i><b>4.3.2</b> Variable Importance Measures with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#exercise"><i class="fa fa-check"></i><b>4.4</b> Exercise</a><ul>
<li class="chapter" data-level="4.4.1" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#sl3ex"><i class="fa fa-check"></i><b>4.4.1</b> Predicting Myocardial Infarction with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#summary"><i class="fa fa-check"></i><b>4.5</b> Summary</a><ul>
<li class="chapter" data-level="4.5.1" data-path="super-ensemble-machine-learning.html"><a href="super-ensemble-machine-learning.html#exercise-solutions"><i class="fa fa-check"></i><b>4.5.1</b> Exercise Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html"><i class="fa fa-check"></i><b>5</b> One-Step TMLE for Time-to-Event Outcomes</a><ul>
<li class="chapter" data-level="5.1" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#learning-objectives-1"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#introduction-1"><i class="fa fa-check"></i><b>5.2</b> Introduction</a><ul>
<li class="chapter" data-level="5.2.1" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#existing-methods-for-observational-survival-analysis"><i class="fa fa-check"></i><b>5.2.1</b> Existing Methods for Observational Survival Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#using-moss-for-one-step-tmle-for-time-to-event-outcomes"><i class="fa fa-check"></i><b>5.3</b> Using <code>MOSS</code> for One-Step TMLE for Time-to-Event Outcomes</a><ul>
<li class="chapter" data-level="" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#load-necessary-libraries-and-data"><i class="fa fa-check"></i>0. Load necessary libraries and data</a></li>
<li class="chapter" data-level="" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#specify-right-censored-survival-data-arguments"><i class="fa fa-check"></i>1. Specify right-censored survival data arguments</a></li>
<li><a href="one-step-tmle-for-time-to-event-outcomes.html#obtain-initial-estimates-with-superlearner-r-package">2. Obtain initial estimates with <code>SuperLearner</code> <code>R</code> package</a></li>
<li class="chapter" data-level="" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#perform-tmle-adjustment-of-the-initial-conditional-survival-estimate"><i class="fa fa-check"></i>3. Perform TMLE adjustment of the initial conditional survival estimate</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="one-step-tmle-for-time-to-event-outcomes.html"><a href="one-step-tmle-for-time-to-event-outcomes.html#compute-standard-error-estimates-for-simultaneous-inference"><i class="fa fa-check"></i>4. Compute standard error estimates for simultaneous inference</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>6</b> A Primer on the <code>R6</code> Class System</a><ul>
<li class="chapter" data-level="6.1" data-path="r6.html"><a href="r6.html#classes-fields-and-methods"><i class="fa fa-check"></i><b>6.1</b> Classes, Fields, and Methods</a></li>
<li class="chapter" data-level="6.2" data-path="r6.html"><a href="r6.html#object-oriented-programming-python-and-r"><i class="fa fa-check"></i><b>6.2</b> Object Oriented Programming: <code>Python</code> and <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Targeted (Machine) Learning for Real-World Data Science and Causal Inference with the <code>tlverse</code> Software Ecosystem</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="super-ensemble-machine-learning" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Super (Ensemble Machine) Learning</h1>
<p>Based on the <a href="https://github.com/tlverse/sl3"><code>sl3</code> <code>R</code> package</a> by <em>Jeremy
Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin</em>.</p>
<p>Updated: 2019-12-04</p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>Once the statistical estimation problem is defined, as described in the
<a href="intro.html#intro">The Targeted Learning Roadmap</a>, we are ready to construct the TMLE:
an asymptotically efficient substitution estimator of this target quantity.</p>
<p>The first step in the estimation procedure is an initial estimate of the
data-generating distribution, or the relevant part of this distribution that is
needed to evaluate the target parameter. For this initial estimation, we use the
super learner <span class="citation">(van der Laan, Polley, and Hubbard <a href="#ref-vdl2007super">2007</a>)</span>, an important step for creating a robust
estimator.</p>
<div id="super-learning" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Super Learning</h3>
<ul>
<li>A common task in statistical data analysis is estimator selection
(e.g., for prediction).</li>
<li>There is no universally optimal machine learning algorithm for density
estimation or prediction.</li>
<li>For some data, one needs learners that can model a complex function.</li>
<li>For others, possibly as a result of noise or insufficient sample size, a
simple, parametric model might fit best.</li>
<li>Super Learner, an ensemble learner, solves this issue, by allowing a
combination of learners from the simplest (intercept-only) to most complex
(neural nets, random forests, SVM, etc).</li>
<li>It works by using cross-validation in a manner which guarantees that the
resulting fit will be as good as possible, given the learners provided.</li>
<li>Note: even a combination of poor learners can sometimes result in good fit.
It is very important to have good candidates in our library, possibly
incorporating known knowledge about the system in question.</li>
</ul>
<div id="general-overview-of-the-algorithm" class="section level4">
<h4><span class="header-section-number">4.1.1.1</span> General Overview of the Algorithm</h4>
<p><strong>What is cross-validation and how does it work?</strong></p>
<ul>
<li>There are many different cross-validation schemes, designed to accommodate different
study designs and data structures.</li>
<li>The figure below shows an example of 10-fold cross-validation.</li>
</ul>
<embed src="img/misc/vs.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />
<p><strong>General step-by-step overview of the Super Learner algorithm:</strong></p>
<ul>
<li>Break up the sample evenly into V-folds (say V=10).</li>
<li>For each of these 10 folds, remove that portion of the sample (kept out as
validation sample) and the remaining will be used to fit learners (training
sample).</li>
<li>Fit each learner on the training sample (note, some learners will have their
own internal cross-validation procedure or other methods to select tuning
parameters).</li>
<li>For each observation in the corresponding validation sample, predict the outcome
using each of the learners, so if there are <span class="math inline">\(p\)</span> learners, then there would be
<span class="math inline">\(p\)</span> predictions.</li>
<li>Take out another validation sample and repeat until each of the V-sets of data
are removed.</li>
<li>Compare the cross-validated fit of the learners across all observations based
on specified loss function (e.g., squared error, negative log-likelihood, …)
by calculating the corresponding average loss (risk).</li>
<li><p>Either:</p>
<ul>
<li>choose the learner with smallest risk and apply that learner to entire data
set (resulting SL fit),</li>
<li><p>do a weighted average of the learners to minimize the cross-validated risk
(construct an ensemble of learners), by</p>
<ul>
<li>re-fitting the learners on the original data set, and</li>
<li>use the weights above to get the SL fit.</li>
</ul></li>
</ul></li>
</ul>
<p>Note, this entire procedure can be itself cross-validated to get a consistent
estimate of the future performance of the SL fit.</p>
<embed src="img/misc/SLKaiserNew.pdf" width="   extwidth" style="display: block; margin: auto;" type="application/pdf" />
<p><strong>How to pick a Super Learner library?</strong></p>
<ul>
<li>A library is simply a collection of algorithms.</li>
<li>The algorithms in the library should come from contextual knowledge and a large
set of “default” algorithms.</li>
<li>The algorithms may range from a simple linear regression model to multi-step
algorithms involving screening covariates, penalizations, optimizing tuning
parameters, etc.</li>
</ul>
</div>
<div id="example-super-learner-in-prediction" class="section level4">
<h4><span class="header-section-number">4.1.1.2</span> Example: Super Learner In Prediction</h4>
<ul>
<li>We observe a learning data set <span class="math inline">\(X_i=(Y_i,W_i)\)</span>, for <span class="math inline">\(i=1, ..., n\)</span>.</li>
<li>Here, <span class="math inline">\(Y_i\)</span> is the outcome of interest, and <span class="math inline">\(W_i\)</span> is a p-dimensional
set of covariates.</li>
<li>Our objective is to estimate the function <span class="math inline">\(\psi_0(W) = E(Y|W)\)</span>.</li>
<li>This function can be expressed as the minimizer of the expected loss:
<span class="math inline">\(\psi_0(W) = \text{argmin}_{\psi} E[L(X,\psi(W))]\)</span>.</li>
<li>Here, the loss function is represented as <span class="math inline">\(L\)</span> (e.g., squared error loss,
<span class="math inline">\(L: (Y-\psi(W))^2)\)</span>).</li>
</ul>
</div>
<div id="why-use-the-super-learner" class="section level4">
<h4><span class="header-section-number">4.1.1.3</span> Why use the Super Learner?</h4>
<ul>
<li>For prediction, one can use the cross-validated risk to empirically determine
the relative performance of SL and competing methods.</li>
<li>When we have tested different algorithms on actual
data and looked at the performance (e.g., MSE of prediction), never does one
algorithm always win (see below).</li>
<li>Below shows the results of such a study, comparing the fits of several different learners,
including the SL algorithms.</li>
</ul>
<embed src="img/misc/ericSL.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />
<ul>
<li>Super Learner performs asymptotically as well as best possible weighted
combination.</li>
<li>By including all competitors in the library of candidate estimators (glm, neural nets,
SVMs, random forest, etc.), the Super Learner will asymptotically outperform
any of its competitors- even if the set of competitors is allowed to grow polynomial
in sample size.</li>
<li>Motivates the name “Super Learner”: it provides a system of combining many estimators
into an improved estimator.</li>
</ul>
</div>
</div>
<div id="review-of-the-super-learner" class="section level3 unnumbered">
<h3>Review of the Super Learner</h3>
<ul>
<li><p>Loss-function-based tool that uses V-fold cross-validation to obtain the best
prediction of the relevant part of the likelihood that’s needed to evaluate
target parameter.</p></li>
<li><p>Requires expressing the estimand as the minimizer of an expected loss, and
proposing a library of algorithms (“learners” in <code>sl3</code> nomenclature) that we
think might be consistent with the true data-generating distribution.</p></li>
<li><p>The <em>discrete super learner</em>, or cross-validated selector, is the algorithm in
the library that minimizes the V-fold cross-validated empirical risk.</p></li>
<li><p>The <em>super learner</em> is a weighted average of the library of
algorithms, where the weights are chosen to minimize the V-fold
cross-validated empirical risk of the library. Restricting the weights
(“metalearner” in <code>sl3</code> nomenclature) to be positive and sum to one (convex
combination) has been shown to improve upon the discrete super learner
<span class="citation">(Polley and van der Laan <a href="#ref-polley2010super">2010</a>; van der Laan, Polley, and Hubbard <a href="#ref-vdl2007super">2007</a>)</span>.</p></li>
<li><p>Proven to be asymptotically as accurate as the best possible prediction
algorithm that is tested <span class="citation">(van der Laan and Dudoit <a href="#ref-vdl2003unified">2003</a>; van der Vaart, Dudoit, and van der Laan <a href="#ref-van2006oracle">2006</a>)</span>.</p></li>
<li><p>This background material is described in greater detail in the accompanying
<code>tlverse</code> handbook <a href="https://tlverse.org/tlverse-handbook/ensemble-machine-learning.html"><code>sl3</code>
chapter</a>.</p></li>
</ul>
</div>
</div>
<div id="sl3-microwave-dinner-implementation" class="section level2">
<h2><span class="header-section-number">4.2</span> <code>sl3</code> “Microwave Dinner” Implementation</h2>
<p>We begin by illustrating the core functionality of the super learner algorithm
as implemented in <code>sl3</code>. For those who are interested in the internals
of <code>sl3</code>, see this <a href="https://tlverse.org/sl3/articles/intro_sl3.html"><code>sl3</code> introductory
tutorial</a>.</p>
<p>The <code>sl3</code> implementation consists of the following steps:</p>
<ol start="0" style="list-style-type: decimal">
<li>Load the necessary libraries and data</li>
<li>Define the machine learning task</li>
<li>Make a super learner by creating library of base learners and a metalearner</li>
<li>Train the super learner on the machine learning task</li>
<li>Obtain predicted values</li>
</ol>
<div id="wash-benefits-study-example" class="section level3 unnumbered">
<h3>WASH Benefits Study Example</h3>
<p>Using the IST data, we are interested in predicting recurrent stroke <code>DRSISC</code>
using the available covariate data.</p>
</div>
<div id="load-the-necessary-libraries-and-data" class="section level3 unnumbered">
<h3>0. Load the necessary libraries and data</h3>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">library</span>(kableExtra)</a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="kw">library</span>(knitr)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="kw">library</span>(skimr)</a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="kw">library</span>(data.table)</a>
<a class="sourceLine" id="cb12-6" data-line-number="6"><span class="kw">library</span>(sl3)</a>
<a class="sourceLine" id="cb12-7" data-line-number="7"><span class="kw">library</span>(SuperLearner)</a>
<a class="sourceLine" id="cb12-8" data-line-number="8"><span class="kw">library</span>(origami)</a>
<a class="sourceLine" id="cb12-9" data-line-number="9"><span class="kw">set.seed</span>(<span class="dv">7194</span>)</a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="co"># load data set and take a peek</span></a>
<a class="sourceLine" id="cb12-11" data-line-number="11">ist_data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/ist_sample.csv&quot;</span>)</a>
<a class="sourceLine" id="cb12-12" data-line-number="12"></a>
<a class="sourceLine" id="cb12-13" data-line-number="13"><span class="kw">head</span>(ist_data) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb12-14" data-line-number="14"><span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb12-15" data-line-number="15"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T, <span class="dt">font_size =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb12-16" data-line-number="16"><span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;250px&quot;</span>)</a></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:250px; overflow-x: scroll; width:100%; ">
<table class="table" style="font-size: 10px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDELAY
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RCONSC
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
SEX
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
AGE
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RSLEEP
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RATRIAL
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RCT
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RVISINF
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RHEP24
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RASP3
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RSBP
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF1
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF2
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF3
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF4
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF5
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF6
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF7
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RDEF8
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
STYPE
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RXHEP
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
REGION
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
MISSING_RATRIAL_RASP3
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
MISSING_RHEP24
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
RXASP
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
DRSISC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
46
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
150
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
PACS
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Europe and Central Asia
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
33
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
71
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:right;">
180
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
TACS
</td>
<td style="text-align:left;">
L
</td>
<td style="text-align:left;">
East Asia and Pacific
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
D
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
140
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
PACS
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Europe and Central Asia
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
68
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
118
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
LACS
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:left;">
Europe and Central Asia
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
13
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
140
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
POCS
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Europe and Central Asia
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
16
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
71
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
160
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Y
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
PACS
</td>
<td style="text-align:left;">
N
</td>
<td style="text-align:left;">
Europe and Central Asia
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="define-the-machine-learning-task" class="section level3 unnumbered">
<h3>1. Define the machine learning task</h3>
<p>To define the machine learning <strong>“task”</strong> (predict stroke <code>DRSISC</code> using the
available covariate data), we need to create an <code>sl3_Task</code> object.</p>
<p>The <code>sl3_Task</code> keeps track of the roles the variables play in the
machine learning problem, the data, and any metadata (e.g., observational-level
weights, id, offset).</p>
<p>We are not interested in predicting missing outcomes. We set
<code>drop_missing_outcome = TRUE</code> when we create the task. In the next chapter, we
estimate this missingness mechanism and account for it in the estimation.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="co"># specify the outcome and covariates</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2">outcome &lt;-<span class="st"> &quot;DRSISC&quot;</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">covars &lt;-<span class="st"> </span><span class="kw">colnames</span>(ist_data)[<span class="op">-</span><span class="kw">which</span>(<span class="kw">names</span>(ist_data) <span class="op">==</span><span class="st"> </span>outcome)]</a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="co"># create the sl3 task</span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5">ist_task &lt;-<span class="st"> </span><span class="kw">make_sl3_Task</span>(</a>
<a class="sourceLine" id="cb13-6" data-line-number="6">  <span class="dt">data =</span> ist_data,</a>
<a class="sourceLine" id="cb13-7" data-line-number="7">  <span class="dt">covariates =</span> covars,</a>
<a class="sourceLine" id="cb13-8" data-line-number="8">  <span class="dt">outcome =</span> outcome, </a>
<a class="sourceLine" id="cb13-9" data-line-number="9">  <span class="dt">drop_missing_outcome =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb13-10" data-line-number="10">)</a>
<a class="sourceLine" id="cb13-11" data-line-number="11"><span class="co"># examine the task</span></a>
<a class="sourceLine" id="cb13-12" data-line-number="12">ist_task</a></code></pre></div>
<pre><code>A sl3 Task with 4990 obs and these nodes:
$covariates
 [1] &quot;RDELAY&quot;                &quot;RCONSC&quot;                &quot;SEX&quot;                  
 [4] &quot;AGE&quot;                   &quot;RSLEEP&quot;                &quot;RATRIAL&quot;              
 [7] &quot;RCT&quot;                   &quot;RVISINF&quot;               &quot;RHEP24&quot;               
[10] &quot;RASP3&quot;                 &quot;RSBP&quot;                  &quot;RDEF1&quot;                
[13] &quot;RDEF2&quot;                 &quot;RDEF3&quot;                 &quot;RDEF4&quot;                
[16] &quot;RDEF5&quot;                 &quot;RDEF6&quot;                 &quot;RDEF7&quot;                
[19] &quot;RDEF8&quot;                 &quot;STYPE&quot;                 &quot;RXHEP&quot;                
[22] &quot;REGION&quot;                &quot;MISSING_RATRIAL_RASP3&quot; &quot;MISSING_RHEP24&quot;       
[25] &quot;RXASP&quot;                

$outcome
[1] &quot;DRSISC&quot;

$id
NULL

$weights
NULL

$offset
NULL</code></pre>
</div>
<div id="make-a-super-learner" class="section level3 unnumbered">
<h3>2. Make a super learner</h3>
<p>Now that we have defined our machine learning problem with the task, we are
ready to <strong>“make”</strong> the super learner. This requires specification of</p>
<ul>
<li>Base learning algorithms, to establish a library of learners that we think
might be consistent with the true data-generating distribution.</li>
<li>Metalearner, to ensemble the base learners.</li>
</ul>
<p>We might also incorporate</p>
<ul>
<li>Feature selection, to pass only a subset of the predictors to the algorithm.</li>
<li>Hyperparameter specification, to tune base learners.</li>
</ul>
<p>Learners have properties that indicate what features they support. We may use
<code>sl3_list_properties()</code> to get a list of all properties supported by at least
one learner.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">sl3_list_properties</span>()</a></code></pre></div>
<pre><code> [1] &quot;binomial&quot;             &quot;categorical&quot;          &quot;continuous&quot;          
 [4] &quot;cv&quot;                   &quot;density&quot;              &quot;ids&quot;                 
 [7] &quot;multivariate_outcome&quot; &quot;offset&quot;               &quot;preprocessing&quot;       
[10] &quot;timeseries&quot;           &quot;weights&quot;              &quot;wrapper&quot;             </code></pre>
<p>Since we have a binomial outcome, we may identify the learners that support
this outcome type with <code>sl3_list_learners()</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">sl3_list_learners</span>(<span class="kw">c</span>(<span class="st">&quot;binomial&quot;</span>))</a></code></pre></div>
<pre><code> [1] &quot;Lrnr_bartMachine&quot;               &quot;Lrnr_caret&quot;                    
 [3] &quot;Lrnr_dbarts&quot;                    &quot;Lrnr_earth&quot;                    
 [5] &quot;Lrnr_gam&quot;                       &quot;Lrnr_gbm&quot;                      
 [7] &quot;Lrnr_glm&quot;                       &quot;Lrnr_glm_fast&quot;                 
 [9] &quot;Lrnr_glmnet&quot;                    &quot;Lrnr_grf&quot;                      
[11] &quot;Lrnr_h2o_glm&quot;                   &quot;Lrnr_h2o_grid&quot;                 
[13] &quot;Lrnr_hal9001&quot;                   &quot;Lrnr_mean&quot;                     
[15] &quot;Lrnr_optim&quot;                     &quot;Lrnr_pkg_SuperLearner&quot;         
[17] &quot;Lrnr_pkg_SuperLearner_method&quot;   &quot;Lrnr_pkg_SuperLearner_screener&quot;
[19] &quot;Lrnr_polspline&quot;                 &quot;Lrnr_randomForest&quot;             
[21] &quot;Lrnr_ranger&quot;                    &quot;Lrnr_rpart&quot;                    
[23] &quot;Lrnr_screener_corP&quot;             &quot;Lrnr_screener_corRank&quot;         
[25] &quot;Lrnr_screener_randomForest&quot;     &quot;Lrnr_solnp&quot;                    
[27] &quot;Lrnr_stratified&quot;                &quot;Lrnr_svm&quot;                      
[29] &quot;Lrnr_xgboost&quot;                  </code></pre>
<p>Now that we have an idea of some learners, we can construct them using the
<code>make_learner</code> function.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co"># choose base learners</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">lrnr_mean &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_mean)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3">lrnr_glm &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glm)</a>
<a class="sourceLine" id="cb19-4" data-line-number="4">lrnr_gam &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_gam)</a></code></pre></div>
<p>We can customize learner hyperparameters to incorporate a diversity of different
settings. Documentation for the learners and their hyperparameters can be found
in the <a href="https://tlverse.org/sl3/reference/index.html#section-sl-learners"><code>sl3</code> Learners
Reference</a>.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">lrnr_ranger50 &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_ranger, <span class="dt">num.trees =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2">lrnr_hal_simple &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_hal9001, <span class="dt">max_degree =</span> <span class="dv">2</span>, <span class="dt">n_folds =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb20-3" data-line-number="3">lrnr_lasso &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glmnet) <span class="co"># alpha default is 1</span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">lrnr_ridge &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glmnet, <span class="dt">alpha =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">lrnr_elasticnet &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glmnet, <span class="dt">alpha =</span> <span class="fl">.5</span>)</a></code></pre></div>
<p>We can also include learners from the <code>SuperLearner</code> <code>R</code> package.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">lrnr_bayesglm &lt;-<span class="st"> </span>Lrnr_pkg_SuperLearner<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;SL.bayesglm&quot;</span>)</a></code></pre></div>
<p>Here is a fun trick to create customized learners over a grid of parameters.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="co"># I like to crock pot my super learners</span></a>
<a class="sourceLine" id="cb22-2" data-line-number="2">grid_params &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">cost =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>),</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">                    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">                    <span class="dt">kernel =</span> <span class="kw">c</span>(<span class="st">&quot;polynomial&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>),</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">                    <span class="dt">degree =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</a>
<a class="sourceLine" id="cb22-6" data-line-number="6">grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(grid_params, <span class="dt">KEEP.OUT.ATTRS =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb22-7" data-line-number="7">params_default &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">nthread =</span> <span class="kw">getOption</span>(<span class="st">&quot;sl.cores.learners&quot;</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb22-8" data-line-number="8">svm_learners &lt;-<span class="st"> </span><span class="kw">apply</span>(grid, <span class="dt">MARGIN =</span> <span class="dv">1</span>, <span class="cf">function</span>(params_tune) {</a>
<a class="sourceLine" id="cb22-9" data-line-number="9">  <span class="kw">do.call</span>(Lrnr_svm<span class="op">$</span>new, <span class="kw">c</span>(params_default, <span class="kw">as.list</span>(params_tune)))})</a>
<a class="sourceLine" id="cb22-10" data-line-number="10"></a>
<a class="sourceLine" id="cb22-11" data-line-number="11">grid_params &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb22-12" data-line-number="12">                    <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>),</a>
<a class="sourceLine" id="cb22-13" data-line-number="13">                    <span class="dt">nrounds =</span> <span class="kw">c</span>(<span class="dv">20</span>, <span class="dv">50</span>))</a>
<a class="sourceLine" id="cb22-14" data-line-number="14">grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(grid_params, <span class="dt">KEEP.OUT.ATTRS =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb22-15" data-line-number="15">params_default &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">nthread =</span> <span class="kw">getOption</span>(<span class="st">&quot;sl.cores.learners&quot;</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb22-16" data-line-number="16">xgb_learners &lt;-<span class="st"> </span><span class="kw">apply</span>(grid, <span class="dt">MARGIN =</span> <span class="dv">1</span>, <span class="cf">function</span>(params_tune) {</a>
<a class="sourceLine" id="cb22-17" data-line-number="17">  <span class="kw">do.call</span>(Lrnr_xgboost<span class="op">$</span>new, <span class="kw">c</span>(params_default, <span class="kw">as.list</span>(params_tune)))})</a></code></pre></div>
<p>Did you see <code>Lrnr_caret</code> when we called <code>sl3_list_learners(c(&quot;binomial&quot;))</code>?
All we need to specify is the algorithm to use, which is passed as <code>method</code> to
<code>caret::train()</code>. The default method for parameter selection criterion with
is set to “CV” instead of the <code>caret::train()</code> default <code>boot</code>. The summary
metric to used to select the optimal model is <code>RMSE</code> for continuous outcomes
and <code>Accuracy</code> for categorical and binomial outcomes.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co"># I have no idea how to tune a neural net (or BART machine..)</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2">lrnr_caret_nnet &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_caret, <span class="dt">algorithm =</span> <span class="st">&quot;nnet&quot;</span>)</a>
<a class="sourceLine" id="cb23-3" data-line-number="3">lrnr_caret_bartMachine &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_caret, <span class="dt">algorithm =</span> <span class="st">&quot;bartMachine&quot;</span>, </a>
<a class="sourceLine" id="cb23-4" data-line-number="4">                                       <span class="dt">method =</span> <span class="st">&quot;boot&quot;</span>, <span class="dt">metric =</span> <span class="st">&quot;Accuracy&quot;</span>,</a>
<a class="sourceLine" id="cb23-5" data-line-number="5">                                       <span class="dt">tuneLength =</span> <span class="dv">10</span>)</a></code></pre></div>
<p>In order to assemble the library of learners, we need to <strong>“stack”</strong> them
together.</p>
<p>A <code>Stack</code> is a special learner and it has the same interface as all
other learners. What makes a stack special is that it combines multiple learners
by training them simultaneously, so that their predictions can be either
combined or compared.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">stack &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Stack, </a>
<a class="sourceLine" id="cb24-2" data-line-number="2">  lrnr_glm, lrnr_mean, lrnr_lasso, lrnr_gam, </a>
<a class="sourceLine" id="cb24-3" data-line-number="3">  lrnr_bayesglm, lrnr_ridge, lrnr_elasticnet</a>
<a class="sourceLine" id="cb24-4" data-line-number="4">)</a></code></pre></div>
<p>We can optionally select a subset of available covariates and pass only
those variables to the modeling algorithm.</p>
<p>Let’s consider screening covariates based on their <code>randomForest</code> variable
importance ranking (ordered by mean decrease in accuracy)</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">screen_rf &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_screener_randomForest, <span class="dt">nVar =</span> <span class="dv">5</span>, <span class="dt">ntree =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2"><span class="co"># which covariates are selected on the full data?</span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3">screen_rf<span class="op">$</span><span class="kw">train</span>(ist_task)</a></code></pre></div>
<pre><code>[1] &quot;Lrnr_screener_randomForest_5_100&quot;
$selected
[1] &quot;RDELAY&quot; &quot;SEX&quot;    &quot;AGE&quot;    &quot;RSLEEP&quot; &quot;RSBP&quot;  </code></pre>
<p>To <strong>“pipe”</strong> only the selected covariates to the modeling algorithm, we need to
make a <code>Pipeline</code>, which is a just set of learners to be fit sequentially, where
the fit from one learner is used to define the task for the next learner.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">screen_rf_pipeline &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Pipeline, screen_rf, stack)</a></code></pre></div>
<p>Now our learners will be preceded by a screening step.</p>
<p>We also consider the original <code>stack</code>, just to compare how the feature selection
methods perform in comparison to the methods without feature selection.</p>
<p>Analogous to what we have seen before, we have to stack the pipeline and
original <code>stack</code> together, so we may use them as base learners in our super
learner.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">fancy_stack &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Stack, screen_rf_pipeline, stack)</a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="co"># we can visualize the stack</span></a>
<a class="sourceLine" id="cb28-3" data-line-number="3">dt_stack &lt;-<span class="st"> </span><span class="kw">delayed_learner_train</span>(fancy_stack, ist_task)</a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="kw">plot</span>(dt_stack, <span class="dt">color =</span> <span class="ot">FALSE</span>, <span class="dt">height =</span> <span class="st">&quot;400px&quot;</span>, <span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>)</a></code></pre></div>
<div id="htmlwidget-3726e379aa680fa31a91" style="width:100%;height:400px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-3726e379aa680fa31a91">{"x":{"nodes":{"id":["4e88c938-1698-11ea-9677-42010a1e0345","4e88bbfa-1698-11ea-9677-42010a1e0345","4e881d62-1698-11ea-9677-42010a1e0345","4e880f84-1698-11ea-9677-42010a1e0345","4e86d04c-1698-11ea-9677-42010a1e0345","4e87f058-1698-11ea-9677-42010a1e0345","4e86ed20-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e871c0a-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e873956-1698-11ea-9677-42010a1e0345","4e8755da-1698-11ea-9677-42010a1e0345","4e877510-1698-11ea-9677-42010a1e0345","4e879158-1698-11ea-9677-42010a1e0345","4e87aea4-1698-11ea-9677-42010a1e0345","4e87cc90-1698-11ea-9677-42010a1e0345","4e88adea-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e883234-1698-11ea-9677-42010a1e0345","4e884238-1698-11ea-9677-42010a1e0345","4e88516a-1698-11ea-9677-42010a1e0345","4e8860ce-1698-11ea-9677-42010a1e0345","4e887096-1698-11ea-9677-42010a1e0345","4e887fc8-1698-11ea-9677-42010a1e0345","4e888f0e-1698-11ea-9677-42010a1e0345"],"label":["Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE"],"level":[1,2,3,4,10,5,9,6,7,8,7,7,7,7,7,7,3,4,5,5,5,5,5,5,5],"sequential":[true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false],"state":["waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready"],"group":["none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none"]},"edges":{"from":["4e86d04c-1698-11ea-9677-42010a1e0345","4e86d04c-1698-11ea-9677-42010a1e0345","4e86ed20-1698-11ea-9677-42010a1e0345","4e86ed20-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e871c0a-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e873956-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e8755da-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e877510-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e879158-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e87aea4-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e87cc90-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e87f058-1698-11ea-9677-42010a1e0345","4e880f84-1698-11ea-9677-42010a1e0345","4e881d62-1698-11ea-9677-42010a1e0345","4e883234-1698-11ea-9677-42010a1e0345","4e884238-1698-11ea-9677-42010a1e0345","4e88516a-1698-11ea-9677-42010a1e0345","4e8860ce-1698-11ea-9677-42010a1e0345","4e887096-1698-11ea-9677-42010a1e0345","4e887fc8-1698-11ea-9677-42010a1e0345","4e888f0e-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e88adea-1698-11ea-9677-42010a1e0345","4e88bbfa-1698-11ea-9677-42010a1e0345"],"to":["4e880f84-1698-11ea-9677-42010a1e0345","4e86ed20-1698-11ea-9677-42010a1e0345","4e87f058-1698-11ea-9677-42010a1e0345","4e86fe14-1698-11ea-9677-42010a1e0345","4e871c0a-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e873956-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e8755da-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e877510-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e879158-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e87aea4-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e87cc90-1698-11ea-9677-42010a1e0345","4e87e0a4-1698-11ea-9677-42010a1e0345","4e87f058-1698-11ea-9677-42010a1e0345","4e880f84-1698-11ea-9677-42010a1e0345","4e881d62-1698-11ea-9677-42010a1e0345","4e88bbfa-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e889eb8-1698-11ea-9677-42010a1e0345","4e88adea-1698-11ea-9677-42010a1e0345","4e88bbfa-1698-11ea-9677-42010a1e0345","4e88c938-1698-11ea-9677-42010a1e0345"],"label":["","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":"to"},"layout":{"hierarchical":{"enabled":true,"levelSeparation":500,"nodeSpacing":200,"direction":"RL"}},"groups":{"useDefaultGroups":true,"none":{"color":{"border":"black","background":"white"}}}},"groups":["none"],"width":"100%","height":"400px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>We will use the <a href="https://github.com/tlverse/sl3/blob/master/R/default_metalearner.R">default
metalearner</a>,
which uses <a href="https://github.com/tlverse/sl3/blob/master/R/Lrnr_solnp.R"><code>Lrnr_solnp()</code></a>
to provide fitting procedures for a pairing of <a href="https://github.com/tlverse/sl3/blob/master/R/loss_functions.R">loss
function</a> and
<a href="https://github.com/tlverse/sl3/blob/master/R/metalearners.R">metalearner
function</a>. The
default metalearner chooses loss and metalearner pairing based on the outcome
type. Note that any learner can be used as a metalearner.</p>
<p>We have made a library/stack of base learners, so we are ready to make the super
learner. The super learner algorithm fits a metalearner on the validation-set
predictions.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">sl &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl,</a>
<a class="sourceLine" id="cb29-2" data-line-number="2">  <span class="dt">learners =</span> fancy_stack</a>
<a class="sourceLine" id="cb29-3" data-line-number="3">)</a>
<a class="sourceLine" id="cb29-4" data-line-number="4"><span class="co"># we can visualize the super learner</span></a>
<a class="sourceLine" id="cb29-5" data-line-number="5">dt_sl &lt;-<span class="st"> </span><span class="kw">delayed_learner_train</span>(sl, ist_task)</a>
<a class="sourceLine" id="cb29-6" data-line-number="6"><span class="kw">plot</span>(dt_sl, <span class="dt">color =</span> <span class="ot">FALSE</span>, <span class="dt">height =</span> <span class="st">&quot;400px&quot;</span>, <span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>)</a></code></pre></div>
<div id="htmlwidget-a4cb3cabd45eb4c03ea9" style="width:100%;height:400px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-a4cb3cabd45eb4c03ea9">{"x":{"nodes":{"id":["4ee2d14e-1698-11ea-9677-42010a1e0345","4ee2c03c-1698-11ea-9677-42010a1e0345","4ee286f8-1698-11ea-9677-42010a1e0345","4ee2794c-1698-11ea-9677-42010a1e0345","4eb5631c-1698-11ea-9677-42010a1e0345","4eb5548a-1698-11ea-9677-42010a1e0345","4eb4b98a-1698-11ea-9677-42010a1e0345","4eb4ace2-1698-11ea-9677-42010a1e0345","4eb38ba0-1698-11ea-9677-42010a1e0345","4eb49176-1698-11ea-9677-42010a1e0345","4eb399d8-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb3c5d4-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb3e2a8-1698-11ea-9677-42010a1e0345","4eb402c4-1698-11ea-9677-42010a1e0345","4eb41fc0-1698-11ea-9677-42010a1e0345","4eb43be0-1698-11ea-9677-42010a1e0345","4eb457ba-1698-11ea-9677-42010a1e0345","4eb47394-1698-11ea-9677-42010a1e0345","4eb547a6-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb4ce7a-1698-11ea-9677-42010a1e0345","4eb4dd5c-1698-11ea-9677-42010a1e0345","4eb4eca2-1698-11ea-9677-42010a1e0345","4eb4fbac-1698-11ea-9677-42010a1e0345","4eb50a52-1698-11ea-9677-42010a1e0345","4eb5197a-1698-11ea-9677-42010a1e0345","4eb52aa0-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ebaba4c-1698-11ea-9677-42010a1e0345","4ebaac8c-1698-11ea-9677-42010a1e0345","4eba0bd8-1698-11ea-9677-42010a1e0345","4eb9fbde-1698-11ea-9677-42010a1e0345","4eb8dbaa-1698-11ea-9677-42010a1e0345","4eb9e0a4-1698-11ea-9677-42010a1e0345","4eb8eaaa-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb916ba-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb93348-1698-11ea-9677-42010a1e0345","4eb94ebe-1698-11ea-9677-42010a1e0345","4eb96ea8-1698-11ea-9677-42010a1e0345","4eb98c6c-1698-11ea-9677-42010a1e0345","4eb9a8d2-1698-11ea-9677-42010a1e0345","4eb9c42a-1698-11ea-9677-42010a1e0345","4eba9e22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba22d0-1698-11ea-9677-42010a1e0345","4eba3252-1698-11ea-9677-42010a1e0345","4eba41fc-1698-11ea-9677-42010a1e0345","4eba514c-1698-11ea-9677-42010a1e0345","4eba6006-1698-11ea-9677-42010a1e0345","4eba7294-1698-11ea-9677-42010a1e0345","4eba8220-1698-11ea-9677-42010a1e0345","4eca9c5a-1698-11ea-9677-42010a1e0345","4eca8b8e-1698-11ea-9677-42010a1e0345","4ec9d194-1698-11ea-9677-42010a1e0345","4ec9c168-1698-11ea-9677-42010a1e0345","4ec86de0-1698-11ea-9677-42010a1e0345","4ec9a07a-1698-11ea-9677-42010a1e0345","4ec87c2c-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec8aecc-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec8d0c8-1698-11ea-9677-42010a1e0345","4ec8f2a6-1698-11ea-9677-42010a1e0345","4ec91420-1698-11ea-9677-42010a1e0345","4ec93612-1698-11ea-9677-42010a1e0345","4ec95bb0-1698-11ea-9677-42010a1e0345","4ec97dde-1698-11ea-9677-42010a1e0345","4eca7900-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4ec9eaa8-1698-11ea-9677-42010a1e0345","4ec9fd54-1698-11ea-9677-42010a1e0345","4eca0fe2-1698-11ea-9677-42010a1e0345","4eca2220-1698-11ea-9677-42010a1e0345","4eca33c8-1698-11ea-9677-42010a1e0345","4eca464c-1698-11ea-9677-42010a1e0345","4eca57ea-1698-11ea-9677-42010a1e0345","4ecd6b56-1698-11ea-9677-42010a1e0345","4ecd5bd4-1698-11ea-9677-42010a1e0345","4ecca5b8-1698-11ea-9677-42010a1e0345","4ecc9618-1698-11ea-9677-42010a1e0345","4ecb4420-1698-11ea-9677-42010a1e0345","4ecc752a-1698-11ea-9677-42010a1e0345","4ecb5096-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecb8232-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecba38e-1698-11ea-9677-42010a1e0345","4ecbc990-1698-11ea-9677-42010a1e0345","4ecbeba0-1698-11ea-9677-42010a1e0345","4ecc0d06-1698-11ea-9677-42010a1e0345","4ecc2eb2-1698-11ea-9677-42010a1e0345","4ecc4fd2-1698-11ea-9677-42010a1e0345","4ecd4b4e-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4eccbde6-1698-11ea-9677-42010a1e0345","4ecccf98-1698-11ea-9677-42010a1e0345","4ecce1c2-1698-11ea-9677-42010a1e0345","4eccf464-1698-11ea-9677-42010a1e0345","4ecd06de-1698-11ea-9677-42010a1e0345","4ecd18b8-1698-11ea-9677-42010a1e0345","4ecd2ad8-1698-11ea-9677-42010a1e0345","4ed0483a-1698-11ea-9677-42010a1e0345","4ed038cc-1698-11ea-9677-42010a1e0345","4ecf7bc6-1698-11ea-9677-42010a1e0345","4ecf69b0-1698-11ea-9677-42010a1e0345","4ece140c-1698-11ea-9677-42010a1e0345","4ecf466a-1698-11ea-9677-42010a1e0345","4ece20be-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ece52f0-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ece7492-1698-11ea-9677-42010a1e0345","4ece97b0-1698-11ea-9677-42010a1e0345","4eceb9e8-1698-11ea-9677-42010a1e0345","4ecede96-1698-11ea-9677-42010a1e0345","4ecf0038-1698-11ea-9677-42010a1e0345","4ecf21d0-1698-11ea-9677-42010a1e0345","4ed02832-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ecf9520-1698-11ea-9677-42010a1e0345","4ecfa84e-1698-11ea-9677-42010a1e0345","4ecfbaaa-1698-11ea-9677-42010a1e0345","4ecfcd88-1698-11ea-9677-42010a1e0345","4ecfdf8a-1698-11ea-9677-42010a1e0345","4ecff2ae-1698-11ea-9677-42010a1e0345","4ed006ae-1698-11ea-9677-42010a1e0345","4ed3206e-1698-11ea-9677-42010a1e0345","4ed30f7a-1698-11ea-9677-42010a1e0345","4ed2531e-1698-11ea-9677-42010a1e0345","4ed24360-1698-11ea-9677-42010a1e0345","4ed0f190-1698-11ea-9677-42010a1e0345","4ed2224a-1698-11ea-9677-42010a1e0345","4ed0ffb4-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed130ec-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed155b8-1698-11ea-9677-42010a1e0345","4ed1770a-1698-11ea-9677-42010a1e0345","4ed19a6e-1698-11ea-9677-42010a1e0345","4ed1bc10-1698-11ea-9677-42010a1e0345","4ed1de70-1698-11ea-9677-42010a1e0345","4ed1ffa4-1698-11ea-9677-42010a1e0345","4ed2fdfa-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed26c46-1698-11ea-9677-42010a1e0345","4ed28140-1698-11ea-9677-42010a1e0345","4ed2945a-1698-11ea-9677-42010a1e0345","4ed2a67a-1698-11ea-9677-42010a1e0345","4ed2b868-1698-11ea-9677-42010a1e0345","4ed2ca74-1698-11ea-9677-42010a1e0345","4ed2dc76-1698-11ea-9677-42010a1e0345","4ed5f88e-1698-11ea-9677-42010a1e0345","4ed5e8da-1698-11ea-9677-42010a1e0345","4ed52c92-1698-11ea-9677-42010a1e0345","4ed51cc0-1698-11ea-9677-42010a1e0345","4ed3ca3c-1698-11ea-9677-42010a1e0345","4ed4fc36-1698-11ea-9677-42010a1e0345","4ed3d734-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed40a42-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed42d10-1698-11ea-9677-42010a1e0345","4ed44fe8-1698-11ea-9677-42010a1e0345","4ed471bc-1698-11ea-9677-42010a1e0345","4ed4939a-1698-11ea-9677-42010a1e0345","4ed4b582-1698-11ea-9677-42010a1e0345","4ed4d6ac-1698-11ea-9677-42010a1e0345","4ed5d8ea-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5457e-1698-11ea-9677-42010a1e0345","4ed55780-1698-11ea-9677-42010a1e0345","4ed569c8-1698-11ea-9677-42010a1e0345","4ed57b7a-1698-11ea-9677-42010a1e0345","4ed58f0c-1698-11ea-9677-42010a1e0345","4ed5a3f2-1698-11ea-9677-42010a1e0345","4ed5b7ac-1698-11ea-9677-42010a1e0345","4ed8cf6e-1698-11ea-9677-42010a1e0345","4ed8bfce-1698-11ea-9677-42010a1e0345","4ed8084a-1698-11ea-9677-42010a1e0345","4ed7f7ba-1698-11ea-9677-42010a1e0345","4ed6a1ee-1698-11ea-9677-42010a1e0345","4ed7d514-1698-11ea-9677-42010a1e0345","4ed6aedc-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed6e30c-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed705d0-1698-11ea-9677-42010a1e0345","4ed728d0-1698-11ea-9677-42010a1e0345","4ed74ac2-1698-11ea-9677-42010a1e0345","4ed76fde-1698-11ea-9677-42010a1e0345","4ed791d0-1698-11ea-9677-42010a1e0345","4ed7b2d2-1698-11ea-9677-42010a1e0345","4ed8afb6-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed8206e-1698-11ea-9677-42010a1e0345","4ed832f2-1698-11ea-9677-42010a1e0345","4ed84440-1698-11ea-9677-42010a1e0345","4ed85692-1698-11ea-9677-42010a1e0345","4ed867cc-1698-11ea-9677-42010a1e0345","4ed879f6-1698-11ea-9677-42010a1e0345","4ed88d2e-1698-11ea-9677-42010a1e0345","4edb9ab4-1698-11ea-9677-42010a1e0345","4edb8a56-1698-11ea-9677-42010a1e0345","4edad26e-1698-11ea-9677-42010a1e0345","4edac30a-1698-11ea-9677-42010a1e0345","4ed9748c-1698-11ea-9677-42010a1e0345","4edaa2bc-1698-11ea-9677-42010a1e0345","4ed98102-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4ed9b208-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4ed9d6e8-1698-11ea-9677-42010a1e0345","4ed9f970-1698-11ea-9677-42010a1e0345","4eda1aa4-1698-11ea-9677-42010a1e0345","4eda3ce6-1698-11ea-9677-42010a1e0345","4eda5e2e-1698-11ea-9677-42010a1e0345","4eda812e-1698-11ea-9677-42010a1e0345","4edb7a02-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edaea92-1698-11ea-9677-42010a1e0345","4edafde8-1698-11ea-9677-42010a1e0345","4edb10ee-1698-11ea-9677-42010a1e0345","4edb2304-1698-11ea-9677-42010a1e0345","4edb3542-1698-11ea-9677-42010a1e0345","4edb46d6-1698-11ea-9677-42010a1e0345","4edb5950-1698-11ea-9677-42010a1e0345","4ede6546-1698-11ea-9677-42010a1e0345","4ede54fc-1698-11ea-9677-42010a1e0345","4edda002-1698-11ea-9677-42010a1e0345","4edd9044-1698-11ea-9677-42010a1e0345","4edc413a-1698-11ea-9677-42010a1e0345","4edd6ed4-1698-11ea-9677-42010a1e0345","4edc4e32-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edc7e7a-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edc9fd6-1698-11ea-9677-42010a1e0345","4edcc182-1698-11ea-9677-42010a1e0345","4edce4dc-1698-11ea-9677-42010a1e0345","4edd0818-1698-11ea-9677-42010a1e0345","4edd2924-1698-11ea-9677-42010a1e0345","4edd4b7a-1698-11ea-9677-42010a1e0345","4ede455c-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4eddb81c-1698-11ea-9677-42010a1e0345","4eddca28-1698-11ea-9677-42010a1e0345","4edddbf8-1698-11ea-9677-42010a1e0345","4edded64-1698-11ea-9677-42010a1e0345","4eddff8e-1698-11ea-9677-42010a1e0345","4ede126c-1698-11ea-9677-42010a1e0345","4ede24aa-1698-11ea-9677-42010a1e0345","4ee25b38-1698-11ea-9677-42010a1e0345","4ee24c24-1698-11ea-9677-42010a1e0345","4ee1ae54-1698-11ea-9677-42010a1e0345","4ee1a0e4-1698-11ea-9677-42010a1e0345","4edf0cb2-1698-11ea-9677-42010a1e0345","4ee18262-1698-11ea-9677-42010a1e0345","4edf1928-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4edf4bdc-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edf6dba-1698-11ea-9677-42010a1e0345","4edf8f16-1698-11ea-9677-42010a1e0345","4edfb068-1698-11ea-9677-42010a1e0345","4edfd23c-1698-11ea-9677-42010a1e0345","4ee14284-1698-11ea-9677-42010a1e0345","4ee16070-1698-11ea-9677-42010a1e0345","4ee23ebe-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee1c6c8-1698-11ea-9677-42010a1e0345","4ee1d67c-1698-11ea-9677-42010a1e0345","4ee1e5a4-1698-11ea-9677-42010a1e0345","4ee1f544-1698-11ea-9677-42010a1e0345","4ee2043a-1698-11ea-9677-42010a1e0345","4ee21380-1698-11ea-9677-42010a1e0345","4ee2223a-1698-11ea-9677-42010a1e0345","4ee29544-1698-11ea-9677-42010a1e0345","4ee2b088-1698-11ea-9677-42010a1e0345"],"label":["CV_","bundle","CV_Stack","bundle","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","bundle","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Pipeline(Lrnr_screener_randomForest_5_100->Stack)","bundle","Lrnr_screener_randomForest_5_100","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_gam_NULL_NULL_GCV.Cp","Lrnr_pkg_SuperLearner_SL.bayesglm","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","chain","Lrnr_solnp_TRUE_TRUE_FALSE_1e-05"],"level":[1,2,5,6,7,8,9,10,16,11,15,12,13,14,13,13,13,13,13,13,9,10,11,11,11,11,11,11,11,7,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,8,9,10,11,17,12,16,13,14,15,14,14,14,14,14,14,10,11,12,12,12,12,12,12,12,4,3],"sequential":[true,true,true,true,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,false,true,false],"state":["waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","ready","waiting","waiting"],"group":["none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none"]},"edges":{"from":["4eb38ba0-1698-11ea-9677-42010a1e0345","4eb38ba0-1698-11ea-9677-42010a1e0345","4eb399d8-1698-11ea-9677-42010a1e0345","4eb399d8-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb3c5d4-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb3e2a8-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb402c4-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb41fc0-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb43be0-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb457ba-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb47394-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb49176-1698-11ea-9677-42010a1e0345","4eb4ace2-1698-11ea-9677-42010a1e0345","4eb4b98a-1698-11ea-9677-42010a1e0345","4eb4ce7a-1698-11ea-9677-42010a1e0345","4eb4dd5c-1698-11ea-9677-42010a1e0345","4eb4eca2-1698-11ea-9677-42010a1e0345","4eb4fbac-1698-11ea-9677-42010a1e0345","4eb50a52-1698-11ea-9677-42010a1e0345","4eb5197a-1698-11ea-9677-42010a1e0345","4eb52aa0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb547a6-1698-11ea-9677-42010a1e0345","4eb5548a-1698-11ea-9677-42010a1e0345","4eb5631c-1698-11ea-9677-42010a1e0345","4eb8dbaa-1698-11ea-9677-42010a1e0345","4eb8dbaa-1698-11ea-9677-42010a1e0345","4eb8eaaa-1698-11ea-9677-42010a1e0345","4eb8eaaa-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb916ba-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb93348-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb94ebe-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb96ea8-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb98c6c-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb9a8d2-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb9c42a-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb9e0a4-1698-11ea-9677-42010a1e0345","4eb9fbde-1698-11ea-9677-42010a1e0345","4eba0bd8-1698-11ea-9677-42010a1e0345","4eba22d0-1698-11ea-9677-42010a1e0345","4eba3252-1698-11ea-9677-42010a1e0345","4eba41fc-1698-11ea-9677-42010a1e0345","4eba514c-1698-11ea-9677-42010a1e0345","4eba6006-1698-11ea-9677-42010a1e0345","4eba7294-1698-11ea-9677-42010a1e0345","4eba8220-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba9e22-1698-11ea-9677-42010a1e0345","4ebaac8c-1698-11ea-9677-42010a1e0345","4ebaba4c-1698-11ea-9677-42010a1e0345","4ec86de0-1698-11ea-9677-42010a1e0345","4ec86de0-1698-11ea-9677-42010a1e0345","4ec87c2c-1698-11ea-9677-42010a1e0345","4ec87c2c-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec8aecc-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec8d0c8-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec8f2a6-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec91420-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec93612-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec95bb0-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec97dde-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec9a07a-1698-11ea-9677-42010a1e0345","4ec9c168-1698-11ea-9677-42010a1e0345","4ec9d194-1698-11ea-9677-42010a1e0345","4ec9eaa8-1698-11ea-9677-42010a1e0345","4ec9fd54-1698-11ea-9677-42010a1e0345","4eca0fe2-1698-11ea-9677-42010a1e0345","4eca2220-1698-11ea-9677-42010a1e0345","4eca33c8-1698-11ea-9677-42010a1e0345","4eca464c-1698-11ea-9677-42010a1e0345","4eca57ea-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca7900-1698-11ea-9677-42010a1e0345","4eca8b8e-1698-11ea-9677-42010a1e0345","4eca9c5a-1698-11ea-9677-42010a1e0345","4ecb4420-1698-11ea-9677-42010a1e0345","4ecb4420-1698-11ea-9677-42010a1e0345","4ecb5096-1698-11ea-9677-42010a1e0345","4ecb5096-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecb8232-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecba38e-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecbc990-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecbeba0-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecc0d06-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecc2eb2-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecc4fd2-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecc752a-1698-11ea-9677-42010a1e0345","4ecc9618-1698-11ea-9677-42010a1e0345","4ecca5b8-1698-11ea-9677-42010a1e0345","4eccbde6-1698-11ea-9677-42010a1e0345","4ecccf98-1698-11ea-9677-42010a1e0345","4ecce1c2-1698-11ea-9677-42010a1e0345","4eccf464-1698-11ea-9677-42010a1e0345","4ecd06de-1698-11ea-9677-42010a1e0345","4ecd18b8-1698-11ea-9677-42010a1e0345","4ecd2ad8-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd4b4e-1698-11ea-9677-42010a1e0345","4ecd5bd4-1698-11ea-9677-42010a1e0345","4ecd6b56-1698-11ea-9677-42010a1e0345","4ece140c-1698-11ea-9677-42010a1e0345","4ece140c-1698-11ea-9677-42010a1e0345","4ece20be-1698-11ea-9677-42010a1e0345","4ece20be-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ece52f0-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ece7492-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ece97b0-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4eceb9e8-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ecede96-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ecf0038-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ecf21d0-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ecf466a-1698-11ea-9677-42010a1e0345","4ecf69b0-1698-11ea-9677-42010a1e0345","4ecf7bc6-1698-11ea-9677-42010a1e0345","4ecf9520-1698-11ea-9677-42010a1e0345","4ecfa84e-1698-11ea-9677-42010a1e0345","4ecfbaaa-1698-11ea-9677-42010a1e0345","4ecfcd88-1698-11ea-9677-42010a1e0345","4ecfdf8a-1698-11ea-9677-42010a1e0345","4ecff2ae-1698-11ea-9677-42010a1e0345","4ed006ae-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed02832-1698-11ea-9677-42010a1e0345","4ed038cc-1698-11ea-9677-42010a1e0345","4ed0483a-1698-11ea-9677-42010a1e0345","4ed0f190-1698-11ea-9677-42010a1e0345","4ed0f190-1698-11ea-9677-42010a1e0345","4ed0ffb4-1698-11ea-9677-42010a1e0345","4ed0ffb4-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed130ec-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed155b8-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed1770a-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed19a6e-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed1bc10-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed1de70-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed1ffa4-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed2224a-1698-11ea-9677-42010a1e0345","4ed24360-1698-11ea-9677-42010a1e0345","4ed2531e-1698-11ea-9677-42010a1e0345","4ed26c46-1698-11ea-9677-42010a1e0345","4ed28140-1698-11ea-9677-42010a1e0345","4ed2945a-1698-11ea-9677-42010a1e0345","4ed2a67a-1698-11ea-9677-42010a1e0345","4ed2b868-1698-11ea-9677-42010a1e0345","4ed2ca74-1698-11ea-9677-42010a1e0345","4ed2dc76-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2fdfa-1698-11ea-9677-42010a1e0345","4ed30f7a-1698-11ea-9677-42010a1e0345","4ed3206e-1698-11ea-9677-42010a1e0345","4ed3ca3c-1698-11ea-9677-42010a1e0345","4ed3ca3c-1698-11ea-9677-42010a1e0345","4ed3d734-1698-11ea-9677-42010a1e0345","4ed3d734-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed40a42-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed42d10-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed44fe8-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed471bc-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed4939a-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed4b582-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed4d6ac-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed4fc36-1698-11ea-9677-42010a1e0345","4ed51cc0-1698-11ea-9677-42010a1e0345","4ed52c92-1698-11ea-9677-42010a1e0345","4ed5457e-1698-11ea-9677-42010a1e0345","4ed55780-1698-11ea-9677-42010a1e0345","4ed569c8-1698-11ea-9677-42010a1e0345","4ed57b7a-1698-11ea-9677-42010a1e0345","4ed58f0c-1698-11ea-9677-42010a1e0345","4ed5a3f2-1698-11ea-9677-42010a1e0345","4ed5b7ac-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5d8ea-1698-11ea-9677-42010a1e0345","4ed5e8da-1698-11ea-9677-42010a1e0345","4ed5f88e-1698-11ea-9677-42010a1e0345","4ed6a1ee-1698-11ea-9677-42010a1e0345","4ed6a1ee-1698-11ea-9677-42010a1e0345","4ed6aedc-1698-11ea-9677-42010a1e0345","4ed6aedc-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed6e30c-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed705d0-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed728d0-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed74ac2-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed76fde-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed791d0-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed7b2d2-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed7d514-1698-11ea-9677-42010a1e0345","4ed7f7ba-1698-11ea-9677-42010a1e0345","4ed8084a-1698-11ea-9677-42010a1e0345","4ed8206e-1698-11ea-9677-42010a1e0345","4ed832f2-1698-11ea-9677-42010a1e0345","4ed84440-1698-11ea-9677-42010a1e0345","4ed85692-1698-11ea-9677-42010a1e0345","4ed867cc-1698-11ea-9677-42010a1e0345","4ed879f6-1698-11ea-9677-42010a1e0345","4ed88d2e-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed8afb6-1698-11ea-9677-42010a1e0345","4ed8bfce-1698-11ea-9677-42010a1e0345","4ed8cf6e-1698-11ea-9677-42010a1e0345","4ed9748c-1698-11ea-9677-42010a1e0345","4ed9748c-1698-11ea-9677-42010a1e0345","4ed98102-1698-11ea-9677-42010a1e0345","4ed98102-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4ed9b208-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4ed9d6e8-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4ed9f970-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4eda1aa4-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4eda3ce6-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4eda5e2e-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4eda812e-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4edaa2bc-1698-11ea-9677-42010a1e0345","4edac30a-1698-11ea-9677-42010a1e0345","4edad26e-1698-11ea-9677-42010a1e0345","4edaea92-1698-11ea-9677-42010a1e0345","4edafde8-1698-11ea-9677-42010a1e0345","4edb10ee-1698-11ea-9677-42010a1e0345","4edb2304-1698-11ea-9677-42010a1e0345","4edb3542-1698-11ea-9677-42010a1e0345","4edb46d6-1698-11ea-9677-42010a1e0345","4edb5950-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb7a02-1698-11ea-9677-42010a1e0345","4edb8a56-1698-11ea-9677-42010a1e0345","4edb9ab4-1698-11ea-9677-42010a1e0345","4edc413a-1698-11ea-9677-42010a1e0345","4edc413a-1698-11ea-9677-42010a1e0345","4edc4e32-1698-11ea-9677-42010a1e0345","4edc4e32-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edc7e7a-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edc9fd6-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edcc182-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edce4dc-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edd0818-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edd2924-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edd4b7a-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edd6ed4-1698-11ea-9677-42010a1e0345","4edd9044-1698-11ea-9677-42010a1e0345","4edda002-1698-11ea-9677-42010a1e0345","4eddb81c-1698-11ea-9677-42010a1e0345","4eddca28-1698-11ea-9677-42010a1e0345","4edddbf8-1698-11ea-9677-42010a1e0345","4edded64-1698-11ea-9677-42010a1e0345","4eddff8e-1698-11ea-9677-42010a1e0345","4ede126c-1698-11ea-9677-42010a1e0345","4ede24aa-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede455c-1698-11ea-9677-42010a1e0345","4ede54fc-1698-11ea-9677-42010a1e0345","4ede6546-1698-11ea-9677-42010a1e0345","4edf0cb2-1698-11ea-9677-42010a1e0345","4edf0cb2-1698-11ea-9677-42010a1e0345","4edf1928-1698-11ea-9677-42010a1e0345","4edf1928-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edf4bdc-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edf6dba-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edf8f16-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edfb068-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edfd23c-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4ee14284-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4ee16070-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4ee18262-1698-11ea-9677-42010a1e0345","4ee1a0e4-1698-11ea-9677-42010a1e0345","4ee1ae54-1698-11ea-9677-42010a1e0345","4ee1c6c8-1698-11ea-9677-42010a1e0345","4ee1d67c-1698-11ea-9677-42010a1e0345","4ee1e5a4-1698-11ea-9677-42010a1e0345","4ee1f544-1698-11ea-9677-42010a1e0345","4ee2043a-1698-11ea-9677-42010a1e0345","4ee21380-1698-11ea-9677-42010a1e0345","4ee2223a-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee23ebe-1698-11ea-9677-42010a1e0345","4ee24c24-1698-11ea-9677-42010a1e0345","4ee25b38-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ee2794c-1698-11ea-9677-42010a1e0345","4ee286f8-1698-11ea-9677-42010a1e0345","4ee286f8-1698-11ea-9677-42010a1e0345","4ee29544-1698-11ea-9677-42010a1e0345","4ee29544-1698-11ea-9677-42010a1e0345","4ee2b088-1698-11ea-9677-42010a1e0345","4ee2c03c-1698-11ea-9677-42010a1e0345"],"to":["4eb4ace2-1698-11ea-9677-42010a1e0345","4eb399d8-1698-11ea-9677-42010a1e0345","4eb49176-1698-11ea-9677-42010a1e0345","4eb3a914-1698-11ea-9677-42010a1e0345","4eb3c5d4-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb3e2a8-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb402c4-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb41fc0-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb43be0-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb457ba-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb47394-1698-11ea-9677-42010a1e0345","4eb4812c-1698-11ea-9677-42010a1e0345","4eb49176-1698-11ea-9677-42010a1e0345","4eb4ace2-1698-11ea-9677-42010a1e0345","4eb4b98a-1698-11ea-9677-42010a1e0345","4eb5548a-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb538b0-1698-11ea-9677-42010a1e0345","4eb547a6-1698-11ea-9677-42010a1e0345","4eb5548a-1698-11ea-9677-42010a1e0345","4eb5631c-1698-11ea-9677-42010a1e0345","4ee2794c-1698-11ea-9677-42010a1e0345","4eb9fbde-1698-11ea-9677-42010a1e0345","4eb8eaaa-1698-11ea-9677-42010a1e0345","4eb9e0a4-1698-11ea-9677-42010a1e0345","4eb8f9aa-1698-11ea-9677-42010a1e0345","4eb916ba-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb93348-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb94ebe-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb96ea8-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb98c6c-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb9a8d2-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb9c42a-1698-11ea-9677-42010a1e0345","4eb9d1f4-1698-11ea-9677-42010a1e0345","4eb9e0a4-1698-11ea-9677-42010a1e0345","4eb9fbde-1698-11ea-9677-42010a1e0345","4eba0bd8-1698-11ea-9677-42010a1e0345","4ebaac8c-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba8f22-1698-11ea-9677-42010a1e0345","4eba9e22-1698-11ea-9677-42010a1e0345","4ebaac8c-1698-11ea-9677-42010a1e0345","4ebaba4c-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ec9c168-1698-11ea-9677-42010a1e0345","4ec87c2c-1698-11ea-9677-42010a1e0345","4ec9a07a-1698-11ea-9677-42010a1e0345","4ec88be0-1698-11ea-9677-42010a1e0345","4ec8aecc-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec8d0c8-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec8f2a6-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec91420-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec93612-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec95bb0-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec97dde-1698-11ea-9677-42010a1e0345","4ec98e78-1698-11ea-9677-42010a1e0345","4ec9a07a-1698-11ea-9677-42010a1e0345","4ec9c168-1698-11ea-9677-42010a1e0345","4ec9d194-1698-11ea-9677-42010a1e0345","4eca8b8e-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca6708-1698-11ea-9677-42010a1e0345","4eca7900-1698-11ea-9677-42010a1e0345","4eca8b8e-1698-11ea-9677-42010a1e0345","4eca9c5a-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ecc9618-1698-11ea-9677-42010a1e0345","4ecb5096-1698-11ea-9677-42010a1e0345","4ecc752a-1698-11ea-9677-42010a1e0345","4ecb609a-1698-11ea-9677-42010a1e0345","4ecb8232-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecba38e-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecbc990-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecbeba0-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecc0d06-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecc2eb2-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecc4fd2-1698-11ea-9677-42010a1e0345","4ecc622e-1698-11ea-9677-42010a1e0345","4ecc752a-1698-11ea-9677-42010a1e0345","4ecc9618-1698-11ea-9677-42010a1e0345","4ecca5b8-1698-11ea-9677-42010a1e0345","4ecd5bd4-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd3a28-1698-11ea-9677-42010a1e0345","4ecd4b4e-1698-11ea-9677-42010a1e0345","4ecd5bd4-1698-11ea-9677-42010a1e0345","4ecd6b56-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ecf69b0-1698-11ea-9677-42010a1e0345","4ece20be-1698-11ea-9677-42010a1e0345","4ecf466a-1698-11ea-9677-42010a1e0345","4ece30ea-1698-11ea-9677-42010a1e0345","4ece52f0-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ece7492-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ece97b0-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4eceb9e8-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ecede96-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ecf0038-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ecf21d0-1698-11ea-9677-42010a1e0345","4ecf33d2-1698-11ea-9677-42010a1e0345","4ecf466a-1698-11ea-9677-42010a1e0345","4ecf69b0-1698-11ea-9677-42010a1e0345","4ecf7bc6-1698-11ea-9677-42010a1e0345","4ed038cc-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed0170c-1698-11ea-9677-42010a1e0345","4ed02832-1698-11ea-9677-42010a1e0345","4ed038cc-1698-11ea-9677-42010a1e0345","4ed0483a-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ed24360-1698-11ea-9677-42010a1e0345","4ed0ffb4-1698-11ea-9677-42010a1e0345","4ed2224a-1698-11ea-9677-42010a1e0345","4ed10f90-1698-11ea-9677-42010a1e0345","4ed130ec-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed155b8-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed1770a-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed19a6e-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed1bc10-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed1de70-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed1ffa4-1698-11ea-9677-42010a1e0345","4ed21048-1698-11ea-9677-42010a1e0345","4ed2224a-1698-11ea-9677-42010a1e0345","4ed24360-1698-11ea-9677-42010a1e0345","4ed2531e-1698-11ea-9677-42010a1e0345","4ed30f7a-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2ebbc-1698-11ea-9677-42010a1e0345","4ed2fdfa-1698-11ea-9677-42010a1e0345","4ed30f7a-1698-11ea-9677-42010a1e0345","4ed3206e-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ed51cc0-1698-11ea-9677-42010a1e0345","4ed3d734-1698-11ea-9677-42010a1e0345","4ed4fc36-1698-11ea-9677-42010a1e0345","4ed3e83c-1698-11ea-9677-42010a1e0345","4ed40a42-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed42d10-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed44fe8-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed471bc-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed4939a-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed4b582-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed4d6ac-1698-11ea-9677-42010a1e0345","4ed4e962-1698-11ea-9677-42010a1e0345","4ed4fc36-1698-11ea-9677-42010a1e0345","4ed51cc0-1698-11ea-9677-42010a1e0345","4ed52c92-1698-11ea-9677-42010a1e0345","4ed5e8da-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5c71a-1698-11ea-9677-42010a1e0345","4ed5d8ea-1698-11ea-9677-42010a1e0345","4ed5e8da-1698-11ea-9677-42010a1e0345","4ed5f88e-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ed7f7ba-1698-11ea-9677-42010a1e0345","4ed6aedc-1698-11ea-9677-42010a1e0345","4ed7d514-1698-11ea-9677-42010a1e0345","4ed6c0c0-1698-11ea-9677-42010a1e0345","4ed6e30c-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed705d0-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed728d0-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed74ac2-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed76fde-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed791d0-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed7b2d2-1698-11ea-9677-42010a1e0345","4ed7c358-1698-11ea-9677-42010a1e0345","4ed7d514-1698-11ea-9677-42010a1e0345","4ed7f7ba-1698-11ea-9677-42010a1e0345","4ed8084a-1698-11ea-9677-42010a1e0345","4ed8bfce-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed89d82-1698-11ea-9677-42010a1e0345","4ed8afb6-1698-11ea-9677-42010a1e0345","4ed8bfce-1698-11ea-9677-42010a1e0345","4ed8cf6e-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4edac30a-1698-11ea-9677-42010a1e0345","4ed98102-1698-11ea-9677-42010a1e0345","4edaa2bc-1698-11ea-9677-42010a1e0345","4ed990de-1698-11ea-9677-42010a1e0345","4ed9b208-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4ed9d6e8-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4ed9f970-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4eda1aa4-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4eda3ce6-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4eda5e2e-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4eda812e-1698-11ea-9677-42010a1e0345","4eda90e2-1698-11ea-9677-42010a1e0345","4edaa2bc-1698-11ea-9677-42010a1e0345","4edac30a-1698-11ea-9677-42010a1e0345","4edad26e-1698-11ea-9677-42010a1e0345","4edb8a56-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb6896-1698-11ea-9677-42010a1e0345","4edb7a02-1698-11ea-9677-42010a1e0345","4edb8a56-1698-11ea-9677-42010a1e0345","4edb9ab4-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4edd9044-1698-11ea-9677-42010a1e0345","4edc4e32-1698-11ea-9677-42010a1e0345","4edd6ed4-1698-11ea-9677-42010a1e0345","4edc5d3c-1698-11ea-9677-42010a1e0345","4edc7e7a-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edc9fd6-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edcc182-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edce4dc-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edd0818-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edd2924-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edd4b7a-1698-11ea-9677-42010a1e0345","4edd5bce-1698-11ea-9677-42010a1e0345","4edd6ed4-1698-11ea-9677-42010a1e0345","4edd9044-1698-11ea-9677-42010a1e0345","4edda002-1698-11ea-9677-42010a1e0345","4ede54fc-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede3382-1698-11ea-9677-42010a1e0345","4ede455c-1698-11ea-9677-42010a1e0345","4ede54fc-1698-11ea-9677-42010a1e0345","4ede6546-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ee1a0e4-1698-11ea-9677-42010a1e0345","4edf1928-1698-11ea-9677-42010a1e0345","4ee18262-1698-11ea-9677-42010a1e0345","4edf2864-1698-11ea-9677-42010a1e0345","4edf4bdc-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4edf6dba-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4edf8f16-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4edfb068-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4edfd23c-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4ee14284-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4ee16070-1698-11ea-9677-42010a1e0345","4ee16e58-1698-11ea-9677-42010a1e0345","4ee18262-1698-11ea-9677-42010a1e0345","4ee1a0e4-1698-11ea-9677-42010a1e0345","4ee1ae54-1698-11ea-9677-42010a1e0345","4ee24c24-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee22f00-1698-11ea-9677-42010a1e0345","4ee23ebe-1698-11ea-9677-42010a1e0345","4ee24c24-1698-11ea-9677-42010a1e0345","4ee25b38-1698-11ea-9677-42010a1e0345","4ee26a06-1698-11ea-9677-42010a1e0345","4ee2794c-1698-11ea-9677-42010a1e0345","4ee286f8-1698-11ea-9677-42010a1e0345","4ee2c03c-1698-11ea-9677-42010a1e0345","4ee29544-1698-11ea-9677-42010a1e0345","4ee2c03c-1698-11ea-9677-42010a1e0345","4ee2b088-1698-11ea-9677-42010a1e0345","4ee2c03c-1698-11ea-9677-42010a1e0345","4ee2d14e-1698-11ea-9677-42010a1e0345"],"label":["","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":"to"},"layout":{"hierarchical":{"enabled":true,"levelSeparation":500,"nodeSpacing":200,"direction":"RL"}},"groups":{"useDefaultGroups":true,"none":{"color":{"border":"black","background":"white"}}}},"groups":["none"],"width":"100%","height":"400px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>We can also use <code>Lrnr_cv</code> to build a super learner, cross-validate a stack of
learners to compare performance of the learners in the stack, or cross-validate
any single learner (see “Cross-validation” section of this <a href="https://tlverse.org/sl3/articles/intro_sl3.html"><code>sl3</code>
introductory tutorial</a>).</p>
<p>Furthermore, we can <a href="https://tlverse.org/sl3/articles/custom_lrnrs.html">Define New <code>sl3</code>
Learners</a> which can be used
in all the places you could otherwise use any other <code>sl3</code> learners, including
<code>Pipelines</code>, <code>Stacks</code>, and the Super Learner.</p>
</div>
<div id="train-the-super-learner-on-the-machine-learning-task" class="section level3 unnumbered">
<h3>3. Train the super learner on the machine learning task</h3>
<p>Now we are ready to <strong>“train”</strong> our super learner on our <code>sl3_task</code> object,
<code>ist_task</code>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">sl_fit &lt;-<span class="st"> </span>sl<span class="op">$</span><span class="kw">train</span>(ist_task)</a></code></pre></div>
</div>
<div id="obtain-predicted-values" class="section level3 unnumbered">
<h3>4. Obtain predicted values</h3>
<p>Now that we have fit the super learner, we are ready to obtain our predicted
values, and we can also obtain a summary of the results.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">sl_preds &lt;-<span class="st"> </span>sl_fit<span class="op">$</span><span class="kw">predict</span>()</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">head</span>(sl_preds)</a></code></pre></div>
<pre><code>[1] 0.02255673 0.02988401 0.01769811 0.02196067 0.02000673 0.02866819</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">sl_fit<span class="op">$</span><span class="kw">print</span>()</a></code></pre></div>
<pre><code>[1] &quot;SuperLearner:&quot;
List of 2
 $ : chr &quot;Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)&quot;
 $ : chr &quot;Stack&quot;
[1] &quot;Lrnr_solnp_TRUE_TRUE_FALSE_1e-05&quot;
$pars
 [1] 0.083141326 0.083293982 0.083046297 0.000127445 0.083174819 0.083188516
 [7] 0.082949003 0.083641637 0.083293982 0.082999949 0.000127445 0.085359071
[13] 0.083837427 0.081819100

$convergence
[1] 0

$values
[1] 0.02333591 0.02306707 0.02306699

$lagrange
             [,1]
[1,] 0.0002180135

$hessian
               [,1]         [,2]          [,3]        [,4]          [,5]
 [1,]  0.9991624559  0.005654598  0.0016334035  0.10923498 -0.0004210358
 [2,]  0.0056545981  1.010870264  0.0076928144  0.12905200  0.0059810905
 [3,]  0.0016334035  0.007692814  1.0039481858  0.11551926  0.0020208500
 [4,]  0.1092349846  0.129052003  0.1155192598  0.70765101  0.1107002996
 [5,] -0.0004210358  0.005981090  0.0020208500  0.11070030  0.9999889013
 [6,]  0.0036310961  0.009264752  0.0058074262  0.12239933  0.0039876156
 [7,]  0.0002805788  0.006628599  0.0026891666  0.11085248  0.0006889972
 [8,]  0.0058533391  0.010891833  0.0078552395  0.13263717  0.0061636682
 [9,]  0.0056545981  0.010870264  0.0076928144  0.12905200  0.0059810905
[10,] -0.0103162537 -0.001988173 -0.0072179195  0.08096812 -0.0097710437
[11,]  0.1092349846  0.129052003  0.1155192598 -0.29234899  0.1107002996
[12,]  0.0212214898  0.022780070  0.0221266053  0.19058981  0.0212736958
[13,] -0.0015396653  0.004845137  0.0009388269  0.11293048 -0.0011374724
[14,] -0.0269161076 -0.015050714 -0.0226672888  0.02380840 -0.0261139739
              [,6]          [,7]         [,8]         [,9]        [,10]
 [1,]  0.003631096  0.0002805788  0.005853339  0.005654598 -0.010316254
 [2,]  0.009264752  0.0066285987  0.010891833  0.010870264 -0.001988173
 [3,]  0.005807426  0.0026891666  0.007855239  0.007692814 -0.007217920
 [4,]  0.122399335  0.1108524801  0.132637170  0.129052003  0.080968121
 [5,]  0.003987616  0.0006889972  0.006163668  0.005981090 -0.009771044
 [6,]  1.007521008  0.0046471754  0.009353318  0.009264752 -0.004610971
 [7,]  0.004647175  1.0013631743  0.006841223  0.006628599 -0.008983719
 [8,]  0.009353318  0.0068412233  1.010834203  0.010891833 -0.001547231
 [9,]  0.009264752  0.0066285987  0.010891833  1.010870264 -0.001988173
[10,] -0.004610971 -0.0089837186 -0.001547231 -0.001988173  0.977561797
[11,]  0.122399335  0.1108524801  0.132637170  0.129052003  0.080968121
[12,]  0.022412496  0.0219347136  0.022028544  0.022780070  0.018782337
[13,]  0.002873429 -0.0003710092  0.004918337  0.004845137 -0.010887161
[14,] -0.018850269 -0.0252536114 -0.013996496 -0.015050714 -0.044100044
            [,11]      [,12]         [,13]       [,14]
 [1,]  0.10923498 0.02122149 -0.0015396653 -0.02691611
 [2,]  0.12905200 0.02278007  0.0048451366 -0.01505071
 [3,]  0.11551926 0.02212661  0.0009388269 -0.02266729
 [4,] -0.29234899 0.19058981  0.1129304803  0.02380840
 [5,]  0.11070030 0.02127370 -0.0011374724 -0.02611397
 [6,]  0.12239933 0.02241250  0.0028734289 -0.01885027
 [7,]  0.11085248 0.02193471 -0.0003710092 -0.02525361
 [8,]  0.13263717 0.02202854  0.0049183372 -0.01399650
 [9,]  0.12905200 0.02278007  0.0048451366 -0.01505071
[10,]  0.08096812 0.01878234 -0.0108871606 -0.04410004
[11,]  0.70765101 0.19058981  0.1129304803  0.02380840
[12,]  0.19058981 1.02301140  0.0196093183  0.01640270
[13,]  0.11293048 0.01960932  0.9975453525 -0.02696367
[14,]  0.02380840 0.01640270 -0.0269636741  0.92418537

$ineqx0
NULL

$nfuneval
[1] 463

$outer.iter
[1] 2

$elapsed
Time difference of 2.107188 secs

$vscale
 [1] 0.02306707 0.00001000 1.00000000 1.00000000 1.00000000 1.00000000
 [7] 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000
[13] 1.00000000 1.00000000 1.00000000 1.00000000

$coefficients
                            Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glm_TRUE 
                                                                                0.083141326 
                                Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_mean 
                                                                                0.083293982 
  Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 
                                                                                0.083046297 
                Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_gam_NULL_NULL_GCV.Cp 
                                                                                0.000127445 
        Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm 
                                                                                0.083174819 
  Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 
                                                                                0.083188516 
Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 
                                                                                0.082949003 
                                                                        Stack_Lrnr_glm_TRUE 
                                                                                0.083641637 
                                                                            Stack_Lrnr_mean 
                                                                                0.083293982 
                                              Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 
                                                                                0.082999949 
                                                            Stack_Lrnr_gam_NULL_NULL_GCV.Cp 
                                                                                0.000127445 
                                                    Stack_Lrnr_pkg_SuperLearner_SL.bayesglm 
                                                                                0.085359071 
                                              Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 
                                                                                0.083837427 
                                            Stack_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE 
                                                                                0.081819100 

$training_offset
[1] FALSE

$name
[1] &quot;solnp&quot;

[1] &quot;Cross-validated risk (MSE, squared error loss):&quot;
                                                                                        learner
 1:                             Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glm_TRUE
 2:                                 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_mean
 3:   Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
 4:                 Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_gam_NULL_NULL_GCV.Cp
 5:         Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm
 6:   Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE
 7: Pipeline(Lrnr_screener_randomForest_5_100-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE
 8:                                                                         Stack_Lrnr_glm_TRUE
 9:                                                                             Stack_Lrnr_mean
10:                                               Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
11:                                                             Stack_Lrnr_gam_NULL_NULL_GCV.Cp
12:                                                     Stack_Lrnr_pkg_SuperLearner_SL.bayesglm
13:                                               Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE
14:                                             Stack_Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE
15:                                                                                SuperLearner
    coefficients   mean_risk     SE_risk      fold_SD fold_min_risk
 1:  0.083141326  0.02311469 0.002048137  0.005310525    0.01765364
 2:  0.083293982  0.02309466 0.002050044  0.005317404    0.01774964
 3:  0.083046297  0.02310340 0.002050695  0.005311145    0.01774964
 4:  0.000127445 14.35526681 0.033710625  0.344205051   13.98888617
 5:  0.083174819  0.02311125 0.002048057  0.005312244    0.01765465
 6:  0.083188516  0.02309830 0.002050279  0.005314534    0.01774964
 7:  0.082949003  0.02310701 0.002050928  0.005320580    0.01774964
 8:  0.083641637  0.02336042 0.002031224  0.005202322    0.01753999
 9:  0.083293982  0.02309466 0.002050044  0.005317404    0.01774964
10:  0.082999949  0.02314943 0.002045817  0.005229334    0.01770783
11:  0.000127445 77.70481722 4.016142630 14.117849013   49.33521054
12:  0.085359071  0.02326082 0.002029412  0.005189117    0.01746325
13:  0.083837427  0.02309437 0.002043277  0.005252469    0.01762466
14:  0.081819100  0.02319261 0.002049347  0.005268956    0.01771318
15:           NA  0.02306699 0.002050651  0.005308596    0.01759799
    fold_max_risk
 1:    0.03494974
 2:    0.03496153
 3:    0.03496153
 4:   15.10700493
 5:    0.03494920
 6:    0.03496120
 7:    0.03496153
 8:    0.03491601
 9:    0.03496153
10:    0.03471005
11:   94.04885520
12:    0.03474547
13:    0.03474668
14:    0.03492392
15:    0.03490970</code></pre>
</div>
</div>
<div id="extensions" class="section level2">
<h2><span class="header-section-number">4.3</span> Extensions</h2>
<div id="cross-validated-super-learner" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Cross-validated Super Learner</h3>
<p>We can cross-validate the super learner to see how well the super learner
performs on unseen data, and obtain an estimate of the cross-validated risk of
the super learner.</p>
<p>This estimation procedure requires an “external” layer of cross-validation,
also called nested cross-validation, which involves setting aside a separate
holdout sample that we don’t use to fit the super learner. This
external cross-validation procedure may also incorporate 10 folds, which is the
default in <code>sl3</code>. However, we will incorporate 2 outer/external folds of
cross-validation for computational efficiency.</p>
<p>We also need to specify a loss function to evaluate super learner.
Documentation for the available loss functions can be found in the <a href="https://tlverse.org/sl3/reference/loss_functions.html"><code>sl3</code> Loss
Function Reference</a>.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">ist_task_new &lt;-<span class="st"> </span><span class="kw">make_sl3_Task</span>(</a>
<a class="sourceLine" id="cb35-2" data-line-number="2">  <span class="dt">data =</span> ist_data,</a>
<a class="sourceLine" id="cb35-3" data-line-number="3">  <span class="dt">covariates =</span> covars,</a>
<a class="sourceLine" id="cb35-4" data-line-number="4">  <span class="dt">outcome =</span> outcome,</a>
<a class="sourceLine" id="cb35-5" data-line-number="5">  <span class="dt">folds =</span> <span class="kw">make_folds</span>(ist_data, <span class="dt">fold_fun =</span> folds_vfold, <span class="dt">V =</span> <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb35-6" data-line-number="6">  <span class="dt">drop_missing_outcome =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb35-7" data-line-number="7">)</a>
<a class="sourceLine" id="cb35-8" data-line-number="8">CVsl &lt;-<span class="st"> </span><span class="kw">CV_lrnr_sl</span>(sl_fit, ist_task, loss_loglik_binomial)</a>
<a class="sourceLine" id="cb35-9" data-line-number="9">CVsl</a></code></pre></div>
</div>
<div id="variable-importance-measures-with-sl3" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Variable Importance Measures with <code>sl3</code></h3>
<p>The <code>sl3</code> <code>varimp</code> function returns a table with variables listed in decreasing
order of importance, in which the measure of importance is based on a risk
difference between the learner fit with a permuted covariate and the learner
fit with the true covariate, across all covariates.</p>
<p>In this manner, the larger the risk difference, the more important the variable
is in the prediction.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1">ist_varimp &lt;-<span class="st"> </span><span class="kw">varimp</span>(sl_fit, loss_loglik_binomial)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2">ist_varimp <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb36-3" data-line-number="3"><span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb36-4" data-line-number="4"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T, <span class="dt">font_size =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;250px&quot;</span>)</a></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:250px; overflow-x: scroll; width:100%; ">
<table class="table" style="font-size: 10px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
X
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
risk_diff
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RDELAY
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RCONSC
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
SEX
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
AGE
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RSLEEP
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RATRIAL
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RCT
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RVISINF
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RHEP24
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RASP3
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RSBP
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF1
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF2
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF3
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF4
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF5
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF6
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF7
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RDEF8
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
STYPE
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RXHEP
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
REGION
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
MISSING_RATRIAL_RASP3
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
MISSING_RHEP24
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
RXASP
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="exercise" class="section level2">
<h2><span class="header-section-number">4.4</span> Exercise</h2>
<div id="sl3ex" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Predicting Myocardial Infarction with <code>sl3</code></h3>
<p>Follow the steps below to predict myocardial infarction (<code>mi</code>) using the
available covariate data. We thank Prof. David Benkeser at Emory University for
making the this Cardiovascular Health Study (CHS) data accessible.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="co"># load the data set</span></a>
<a class="sourceLine" id="cb37-2" data-line-number="2">db_data &lt;-</a>
<a class="sourceLine" id="cb37-3" data-line-number="3"><span class="st">  </span><span class="kw">url</span>(<span class="st">&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;</span>)</a>
<a class="sourceLine" id="cb37-4" data-line-number="4">chspred &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> db_data, <span class="dt">col_names =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb37-5" data-line-number="5"><span class="co"># take a quick peek</span></a>
<a class="sourceLine" id="cb37-6" data-line-number="6"><span class="kw">head</span>(chspred) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb37-7" data-line-number="7"><span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb37-8" data-line-number="8"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T, <span class="dt">font_size =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb37-9" data-line-number="9"><span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;200px&quot;</span>)</a></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:200px; overflow-x: scroll; width:100%; ">
<table class="table" style="font-size: 10px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
waist
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
alcoh
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hdl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
beta
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
smoke
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ace
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ldl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
bmi
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aspirin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
gend
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
age
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
estrgn
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
glu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ins
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
cysgfr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
dm
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fetuina
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hsed
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
race
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcystat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logtrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcrp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcre
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
health
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logkcal
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sysbp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
mi
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
110.1642
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
66.4974
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
114.2162
</td>
<td style="text-align:right;">
27.9975
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
73.5179
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
159.9314
</td>
<td style="text-align:right;">
70.3343
</td>
<td style="text-align:right;">
75.0078
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1752
</td>
<td style="text-align:right;">
1.1690
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.3420
</td>
<td style="text-align:right;">
5.4063
</td>
<td style="text-align:right;">
2.0126
</td>
<td style="text-align:right;">
-0.6739
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4.3926
</td>
<td style="text-align:right;">
177.1345
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
89.9763
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
50.0652
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
103.7766
</td>
<td style="text-align:right;">
20.8931
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
61.7723
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
153.3888
</td>
<td style="text-align:right;">
33.9695
</td>
<td style="text-align:right;">
82.7433
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.5717
</td>
<td style="text-align:right;">
0.9011
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.0847
</td>
<td style="text-align:right;">
4.8592
</td>
<td style="text-align:right;">
3.2933
</td>
<td style="text-align:right;">
-0.5551
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
6.2071
</td>
<td style="text-align:right;">
136.3742
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
106.1941
</td>
<td style="text-align:right;">
8.4174
</td>
<td style="text-align:right;">
40.5059
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
165.7158
</td>
<td style="text-align:right;">
28.4554
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
72.9312
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
121.7145
</td>
<td style="text-align:right;">
-17.3017
</td>
<td style="text-align:right;">
74.6989
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3517
</td>
<td style="text-align:right;">
1.1797
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.4451
</td>
<td style="text-align:right;">
4.5088
</td>
<td style="text-align:right;">
0.3013
</td>
<td style="text-align:right;">
-0.0115
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
6.7320
</td>
<td style="text-align:right;">
135.1993
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
90.0566
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
36.1750
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
45.2035
</td>
<td style="text-align:right;">
23.9608
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
79.1191
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
53.9691
</td>
<td style="text-align:right;">
11.7315
</td>
<td style="text-align:right;">
95.7823
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.5439
</td>
<td style="text-align:right;">
1.1360
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.4807
</td>
<td style="text-align:right;">
5.1832
</td>
<td style="text-align:right;">
3.0243
</td>
<td style="text-align:right;">
-0.5751
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
7.3972
</td>
<td style="text-align:right;">
139.0182
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
78.6143
</td>
<td style="text-align:right;">
2.9790
</td>
<td style="text-align:right;">
71.0642
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
131.3121
</td>
<td style="text-align:right;">
10.9656
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
69.0179
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
94.3153
</td>
<td style="text-align:right;">
9.7112
</td>
<td style="text-align:right;">
72.7109
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.4916
</td>
<td style="text-align:right;">
1.1028
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3121
</td>
<td style="text-align:right;">
4.2190
</td>
<td style="text-align:right;">
-0.7057
</td>
<td style="text-align:right;">
0.0053
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
8.2779
</td>
<td style="text-align:right;">
88.0470
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
91.6593
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
59.4963
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
171.1872
</td>
<td style="text-align:right;">
29.1317
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
81.8346
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
212.9066
</td>
<td style="text-align:right;">
-28.2269
</td>
<td style="text-align:right;">
69.2184
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.4621
</td>
<td style="text-align:right;">
0.9529
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.2872
</td>
<td style="text-align:right;">
5.1773
</td>
<td style="text-align:right;">
0.9705
</td>
<td style="text-align:right;">
0.2127
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.9942
</td>
<td style="text-align:right;">
69.5943
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<ol style="list-style-type: decimal">
<li>Create an <code>sl3</code> task, setting myocardial infarction <code>mi</code> as the outcome and
using all available covariate data.</li>
<li>Make a library of seven relatively fast base learning algorithms (i.e., do
not consider BART or HAL). Customize hyperparameters for one of your
learners. Feel free to use learners from <code>sl3</code> or <code>SuperLearner</code>. You may
use the same base learning library that is presented above.</li>
<li>Incorporate feature selection with the <code>SuperLearner</code> screener <code>screen.corP</code>.</li>
<li>Fit the metalearning step with non-negative least squares, <code>Lrnr_nnls</code>.</li>
<li>With the metalearner and base learners, make the super learner and train it
on the task.</li>
<li>Print your super learner fit by calling <code>print()</code> with <code>$</code>. Which learner
is the discrete super learner?</li>
<li>Cross-validate your super learner fit to see how well it performs on unseen
data. Specify <code>loss_squared_error</code> as the loss function to evaluate the
super learner. Like above, create a new task with 2 folds of external
cross-validation for computational efficiency. Report the cross-validated
mean risk of the discrete super learner and the super learner.</li>
</ol>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">4.5</span> Summary</h2>
<ul>
<li><p>The general ensemble learning approach of super learner can be applied to a
diversity of estimation and prediction problems that can be defined by a loss
function.</p></li>
<li><p>Plug-in estimators of the estimand are desirable because a plug-in estimator
respects both the local and global constraints of the statistical model.</p></li>
<li><p>Asymptotically linear estimators are also advantageous, since they converge to
the estimand at <span class="math inline">\(\frac{1}{\sqrt{n}}\)</span> rate, and thereby permit formal
statistical inference.</p></li>
<li><p>If we plug in the estimator returned by super learner into the target
parameter mapping, then we would end up with an estimator that has the same
bias as what we plugged in. This estimator would not be asymptotically linear.</p></li>
<li><p>Targeted maximum likelihood estimation (TMLE) is a general strategy that
succeeds in constructing asymptotically linear plug-in estimators.</p></li>
<li><p>In the chapters that follow, we focus on the targeted maximum likelihood
estimator and the targeted minimum loss-based estimator, both referred to as
TMLE.</p></li>
</ul>
<div id="exercise-solutions" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Exercise Solutions</h3>
<p>Here is a potential solution to the (<code>sl3</code> Exercise – Predicting Myocardial
Infarction with <code>sl3</code>)<span class="citation">(<span class="citeproc-not-found" data-reference-id="sl3ex"><strong>???</strong></span>)</span>.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">chspred_task &lt;-<span class="st"> </span><span class="kw">make_sl3_Task</span>(</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">  <span class="dt">data =</span> chspred,</a>
<a class="sourceLine" id="cb38-3" data-line-number="3">  <span class="dt">covariates =</span> <span class="kw">head</span>(<span class="kw">colnames</span>(chspred), <span class="dv">-1</span>),</a>
<a class="sourceLine" id="cb38-4" data-line-number="4">  <span class="dt">outcome =</span> <span class="st">&quot;mi&quot;</span></a>
<a class="sourceLine" id="cb38-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb38-6" data-line-number="6">glm_learner &lt;-<span class="st"> </span>Lrnr_glm<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb38-7" data-line-number="7">lasso_learner &lt;-<span class="st"> </span>Lrnr_glmnet<span class="op">$</span><span class="kw">new</span>(<span class="dt">alpha =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb38-8" data-line-number="8">ridge_learner &lt;-<span class="st"> </span>Lrnr_glmnet<span class="op">$</span><span class="kw">new</span>(<span class="dt">alpha =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb38-9" data-line-number="9">enet_learner &lt;-<span class="st"> </span>Lrnr_glmnet<span class="op">$</span><span class="kw">new</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb38-10" data-line-number="10">curated_glm_learner &lt;-<span class="st"> </span>Lrnr_glm_fast<span class="op">$</span><span class="kw">new</span>(<span class="dt">formula =</span> <span class="st">&quot;mi ~ smoke + beta + waist&quot;</span>)</a>
<a class="sourceLine" id="cb38-11" data-line-number="11">mean_learner &lt;-<span class="st"> </span>Lrnr_mean<span class="op">$</span><span class="kw">new</span>() <span class="co"># That is one mean learner!</span></a>
<a class="sourceLine" id="cb38-12" data-line-number="12">glm_fast_learner &lt;-<span class="st"> </span>Lrnr_glm_fast<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb38-13" data-line-number="13">ranger_learner &lt;-<span class="st"> </span>Lrnr_ranger<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb38-14" data-line-number="14">svm_learner &lt;-<span class="st"> </span>Lrnr_svm<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb38-15" data-line-number="15">xgb_learner &lt;-<span class="st"> </span>Lrnr_xgboost<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb38-16" data-line-number="16">screen_cor &lt;-<span class="st"> </span>Lrnr_pkg_SuperLearner_screener<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;screen.corP&quot;</span>)</a>
<a class="sourceLine" id="cb38-17" data-line-number="17">glm_pipeline &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Pipeline, screen_cor, glm_learner)</a>
<a class="sourceLine" id="cb38-18" data-line-number="18">stack &lt;-<span class="st"> </span><span class="kw">make_learner</span>(</a>
<a class="sourceLine" id="cb38-19" data-line-number="19">  Stack,</a>
<a class="sourceLine" id="cb38-20" data-line-number="20">  glm_pipeline, glm_learner,</a>
<a class="sourceLine" id="cb38-21" data-line-number="21">  lasso_learner, ridge_learner, enet_learner,</a>
<a class="sourceLine" id="cb38-22" data-line-number="22">  curated_glm_learner, mean_learner, glm_fast_learner,</a>
<a class="sourceLine" id="cb38-23" data-line-number="23">  ranger_learner, svm_learner, xgb_learner</a>
<a class="sourceLine" id="cb38-24" data-line-number="24">)</a>
<a class="sourceLine" id="cb38-25" data-line-number="25">metalearner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_nnls)</a>
<a class="sourceLine" id="cb38-26" data-line-number="26">sl &lt;-<span class="st"> </span>Lrnr_sl<span class="op">$</span><span class="kw">new</span>(</a>
<a class="sourceLine" id="cb38-27" data-line-number="27">  <span class="dt">learners =</span> stack,</a>
<a class="sourceLine" id="cb38-28" data-line-number="28">  <span class="dt">metalearner =</span> metalearner</a>
<a class="sourceLine" id="cb38-29" data-line-number="29">)</a>
<a class="sourceLine" id="cb38-30" data-line-number="30">sl_fit &lt;-<span class="st"> </span>sl<span class="op">$</span><span class="kw">train</span>(task)</a>
<a class="sourceLine" id="cb38-31" data-line-number="31">sl_fit<span class="op">$</span><span class="kw">print</span>()</a>
<a class="sourceLine" id="cb38-32" data-line-number="32">CVsl &lt;-<span class="st"> </span><span class="kw">CV_lrnr_sl</span>(sl_fit, chspred_task, loss_squared_error)</a>
<a class="sourceLine" id="cb38-33" data-line-number="33">CVsl</a></code></pre></div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-polley2010super">
<p>Polley, Eric C, and Mark J van der Laan. 2010. “Super Learner in Prediction.” bepress.</p>
</div>
<div id="ref-vdl2003unified">
<p>van der Laan, Mark J, and Sandrine Dudoit. 2003. “Unified Cross-Validation Methodology for Selection Among Estimators and a General Cross-Validated Adaptive Epsilon-Net Estimator: Finite Sample Oracle Inequalities and Examples.” bepress.</p>
</div>
<div id="ref-vdl2007super">
<p>van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-van2006oracle">
<p>van der Vaart, Aad W, Sandrine Dudoit, and Mark J van der Laan. 2006. “Oracle Inequalities for Multi-Fold Cross Validation.” <em>Statistics &amp; Decisions</em> 24 (3). Oldenbourg Wissenschaftsverlag: 351–71.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="one-step-tmle-for-time-to-event-outcomes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/deming2019-workshop/edit/master/05-sl3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
